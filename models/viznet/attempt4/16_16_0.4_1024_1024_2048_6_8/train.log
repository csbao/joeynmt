2020-08-11 04:31:06,815 Hello! This is Joey-NMT.
2020-08-11 04:31:08,151 Total params: 96384000
2020-08-11 04:31:08,153 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 04:31:12,162 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 04:31:12,162 cfg.data.level                     : bpe
2020-08-11 04:31:12,163 cfg.data.lowercase                 : False
2020-08-11 04:31:12,163 cfg.data.max_sent_length           : 100
2020-08-11 04:31:12,163 cfg.data.src                       : en
2020-08-11 04:31:12,163 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 04:31:12,163 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 04:31:12,163 cfg.data.trg                       : de
2020-08-11 04:31:12,163 cfg.model.bias_initializer         : zeros
2020-08-11 04:31:12,163 cfg.model.decoder.dropout          : 0.1
2020-08-11 04:31:12,163 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 04:31:12,163 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 04:31:12,163 cfg.model.decoder.embeddings.scale : True
2020-08-11 04:31:12,163 cfg.model.decoder.ff_size          : 512
2020-08-11 04:31:12,163 cfg.model.decoder.freeze           : False
2020-08-11 04:31:12,163 cfg.model.decoder.hidden_size      : 1024
2020-08-11 04:31:12,163 cfg.model.decoder.num_heads        : 16
2020-08-11 04:31:12,163 cfg.model.decoder.num_layers       : 6
2020-08-11 04:31:12,163 cfg.model.decoder.type             : transformer
2020-08-11 04:31:12,163 cfg.model.embed_init_gain          : 1.0
2020-08-11 04:31:12,163 cfg.model.embed_initializer        : xavier
2020-08-11 04:31:12,163 cfg.model.encoder.dropout          : 0.4
2020-08-11 04:31:12,163 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 04:31:12,164 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 04:31:12,164 cfg.model.encoder.embeddings.scale : True
2020-08-11 04:31:12,164 cfg.model.encoder.ff_size          : 512
2020-08-11 04:31:12,164 cfg.model.encoder.freeze           : False
2020-08-11 04:31:12,164 cfg.model.encoder.hidden_size      : 1024
2020-08-11 04:31:12,164 cfg.model.encoder.multi_encoder    : False
2020-08-11 04:31:12,164 cfg.model.encoder.num_heads        : 16
2020-08-11 04:31:12,164 cfg.model.encoder.num_layers       : 6
2020-08-11 04:31:12,164 cfg.model.encoder.type             : transformer
2020-08-11 04:31:12,164 cfg.model.init_gain                : 1.0
2020-08-11 04:31:12,164 cfg.model.initializer              : xavier
2020-08-11 04:31:12,164 cfg.model.tied_embeddings          : False
2020-08-11 04:31:12,164 cfg.model.tied_softmax             : True
2020-08-11 04:31:12,164 cfg.name                           : transformer
2020-08-11 04:31:12,164 cfg.testing.alpha                  : 1.0
2020-08-11 04:31:12,164 cfg.testing.beam_size              : 5
2020-08-11 04:31:12,164 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 04:31:12,164 cfg.training.batch_multiplier      : 1
2020-08-11 04:31:12,164 cfg.training.batch_size            : 2048
2020-08-11 04:31:12,164 cfg.training.batch_type            : token
2020-08-11 04:31:12,164 cfg.training.decrease_factor       : 0.7
2020-08-11 04:31:12,164 cfg.training.early_stopping_metric : ppl
2020-08-11 04:31:12,164 cfg.training.epochs                : 20
2020-08-11 04:31:12,165 cfg.training.eval_metric           : bleu
2020-08-11 04:31:12,165 cfg.training.keep_last_ckpts       : 3
2020-08-11 04:31:12,165 cfg.training.label_smoothing       : 0.1
2020-08-11 04:31:12,165 cfg.training.learning_rate         : 0.0002
2020-08-11 04:31:12,165 cfg.training.learning_rate_min     : 1e-08
2020-08-11 04:31:12,165 cfg.training.logging_freq          : 100
2020-08-11 04:31:12,165 cfg.training.loss                  : crossentropy
2020-08-11 04:31:12,165 cfg.training.max_output_length     : 100
2020-08-11 04:31:12,165 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.4_1024_1024_2048_6_8
2020-08-11 04:31:12,165 cfg.training.normalization         : tokens
2020-08-11 04:31:12,165 cfg.training.optimizer             : adam
2020-08-11 04:31:12,165 cfg.training.overwrite             : True
2020-08-11 04:31:12,165 cfg.training.patience              : 8
2020-08-11 04:31:12,165 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 04:31:12,165 cfg.training.random_seed           : 42
2020-08-11 04:31:12,165 cfg.training.scheduling            : plateau
2020-08-11 04:31:12,165 cfg.training.shuffle               : True
2020-08-11 04:31:12,165 cfg.training.use_cuda              : True
2020-08-11 04:31:12,165 cfg.training.validation_freq       : 200
2020-08-11 04:31:12,165 cfg.training.weight_decay          : 0.0
2020-08-11 04:31:12,165 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 04:31:12,166 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 04:31:12,166 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 04:31:12,166 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 04:31:12,166 Number of Src words (types): 3468
2020-08-11 04:31:12,167 Number of Trg words (types): 4487
2020-08-11 04:31:12,167 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 04:31:12,171 EPOCH 1
2020-08-11 04:31:23,752 Epoch   1: total training loss 275.10
2020-08-11 04:31:23,752 EPOCH 2
2020-08-11 04:31:34,438 Epoch   2 Step:      100 Batch Loss:     5.910881 Tokens per Sec:     5485, Lr: 0.000200
2020-08-11 04:31:35,409 Epoch   2: total training loss 236.75
2020-08-11 04:31:35,409 EPOCH 3
2020-08-11 04:31:46,876 Epoch   3: total training loss 214.11
2020-08-11 04:31:46,877 EPOCH 4
2020-08-11 04:31:56,849 Epoch   4 Step:      200 Batch Loss:     4.288789 Tokens per Sec:     5598, Lr: 0.000200
2020-08-11 04:32:59,577 Hooray! New best validation result [ppl]!
2020-08-11 04:32:59,577 Saving new checkpoint.
2020-08-11 04:33:04,435 Example #0
2020-08-11 04:33:04,435 	Raw source:     ['hello', '.']
2020-08-11 04:33:04,435 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:33:04,435 	Source:     hello .
2020-08-11 04:33:04,435 	Reference:  hallo ,
2020-08-11 04:33:04,435 	Hypothesis: hallo .
2020-08-11 04:33:04,436 Example #1
2020-08-11 04:33:04,436 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:33:04,436 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:33:04,436 	Source:     hi , how can i help you ?
2020-08-11 04:33:04,436 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:33:04,436 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:33:04,436 Example #2
2020-08-11 04:33:04,436 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:33:04,436 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar']
2020-08-11 04:33:04,436 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:33:04,436 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:33:04,436 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar
2020-08-11 04:33:04,436 Example #3
2020-08-11 04:33:04,436 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:33:04,436 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', '?']
2020-08-11 04:33:04,436 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:33:04,436 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:33:04,436 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von ?
2020-08-11 04:33:04,437 Validation result (greedy) at epoch   4, step      200: bleu:   2.48, loss: 23910.4180, ppl:  41.9300, duration: 67.5868s
2020-08-11 04:33:06,074 Epoch   4: total training loss 181.66
2020-08-11 04:33:06,074 EPOCH 5
2020-08-11 04:33:17,670 Epoch   5: total training loss 164.33
2020-08-11 04:33:17,671 EPOCH 6
2020-08-11 04:33:27,064 Epoch   6 Step:      300 Batch Loss:     1.848303 Tokens per Sec:     5594, Lr: 0.000200
2020-08-11 04:33:29,270 Epoch   6: total training loss 137.85
2020-08-11 04:33:29,271 EPOCH 7
2020-08-11 04:33:40,803 Epoch   7: total training loss 128.23
2020-08-11 04:33:40,803 EPOCH 8
2020-08-11 04:33:49,287 Epoch   8 Step:      400 Batch Loss:     2.072894 Tokens per Sec:     5659, Lr: 0.000200
2020-08-11 04:34:52,034 Hooray! New best validation result [ppl]!
2020-08-11 04:34:52,034 Saving new checkpoint.
2020-08-11 04:34:56,888 Example #0
2020-08-11 04:34:56,889 	Raw source:     ['hello', '.']
2020-08-11 04:34:56,889 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:34:56,889 	Source:     hello .
2020-08-11 04:34:56,889 	Reference:  hallo ,
2020-08-11 04:34:56,889 	Hypothesis: hallo .
2020-08-11 04:34:56,889 Example #1
2020-08-11 04:34:56,889 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:34:56,889 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:34:56,889 	Source:     hi , how can i help you ?
2020-08-11 04:34:56,889 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:34:56,889 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:34:56,889 Example #2
2020-08-11 04:34:56,889 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:34:56,889 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:34:56,889 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:34:56,889 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:34:56,889 	Hypothesis: hallo , ich bin in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 04:34:56,889 Example #3
2020-08-11 04:34:56,890 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:34:56,890 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'essen', '?']
2020-08-11 04:34:56,890 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:34:56,890 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:34:56,890 	Hypothesis: ok , welche art von essen ?
2020-08-11 04:34:56,890 Validation result (greedy) at epoch   8, step      400: bleu:   8.16, loss: 18438.3867, ppl:  17.8321, duration: 67.6024s
2020-08-11 04:34:59,857 Epoch   8: total training loss 108.66
2020-08-11 04:34:59,857 EPOCH 9
2020-08-11 04:35:11,424 Epoch   9: total training loss 98.03
2020-08-11 04:35:11,425 EPOCH 10
2020-08-11 04:35:19,115 Epoch  10 Step:      500 Batch Loss:     2.130236 Tokens per Sec:     5711, Lr: 0.000200
2020-08-11 04:35:22,995 Epoch  10: total training loss 96.18
2020-08-11 04:35:22,995 EPOCH 11
2020-08-11 04:35:34,523 Epoch  11: total training loss 83.44
2020-08-11 04:35:34,523 EPOCH 12
2020-08-11 04:35:41,120 Epoch  12 Step:      600 Batch Loss:     1.457490 Tokens per Sec:     5627, Lr: 0.000200
2020-08-11 04:36:43,866 Hooray! New best validation result [ppl]!
2020-08-11 04:36:43,866 Saving new checkpoint.
2020-08-11 04:36:48,696 Example #0
2020-08-11 04:36:48,696 	Raw source:     ['hello', '.']
2020-08-11 04:36:48,696 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:36:48,696 	Source:     hello .
2020-08-11 04:36:48,696 	Reference:  hallo ,
2020-08-11 04:36:48,696 	Hypothesis: hallo .
2020-08-11 04:36:48,696 Example #1
2020-08-11 04:36:48,696 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:36:48,696 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:36:48,696 	Source:     hi , how can i help you ?
2020-08-11 04:36:48,696 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:36:48,696 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:36:48,696 Example #2
2020-08-11 04:36:48,696 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:36:48,696 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:36:48,696 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:36:48,696 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:36:48,697 	Hypothesis: hallo , ich suche in san francisco , kalifornien , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien .
2020-08-11 04:36:48,697 Example #3
2020-08-11 04:36:48,697 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:36:48,697 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:36:48,697 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:36:48,697 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:36:48,697 	Hypothesis: ok , welche art von restaurant suchen sie ?
2020-08-11 04:36:48,697 Validation result (greedy) at epoch  12, step      600: bleu:  12.52, loss: 17377.8691, ppl:  15.1090, duration: 67.5766s
2020-08-11 04:36:53,741 Epoch  12: total training loss 73.87
2020-08-11 04:36:53,742 EPOCH 13
2020-08-11 04:37:05,299 Epoch  13: total training loss 61.19
2020-08-11 04:37:05,299 EPOCH 14
2020-08-11 04:37:11,412 Epoch  14 Step:      700 Batch Loss:     1.154684 Tokens per Sec:     5514, Lr: 0.000200
2020-08-11 04:37:16,898 Epoch  14: total training loss 54.29
2020-08-11 04:37:16,898 EPOCH 15
2020-08-11 04:37:28,536 Epoch  15: total training loss 47.85
2020-08-11 04:37:28,536 EPOCH 16
2020-08-11 04:37:33,697 Epoch  16 Step:      800 Batch Loss:     0.737235 Tokens per Sec:     5549, Lr: 0.000200
2020-08-11 04:38:36,425 Hooray! New best validation result [ppl]!
2020-08-11 04:38:36,425 Saving new checkpoint.
2020-08-11 04:38:41,289 Example #0
2020-08-11 04:38:41,290 	Raw source:     ['hello', '.']
2020-08-11 04:38:41,290 	Raw hypothesis: ['hallo']
2020-08-11 04:38:41,290 	Source:     hello .
2020-08-11 04:38:41,290 	Reference:  hallo ,
2020-08-11 04:38:41,290 	Hypothesis: hallo
2020-08-11 04:38:41,290 Example #1
2020-08-11 04:38:41,290 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:38:41,290 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:38:41,290 	Source:     hi , how can i help you ?
2020-08-11 04:38:41,290 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:38:41,290 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:38:41,290 Example #2
2020-08-11 04:38:41,290 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:38:41,290 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:38:41,290 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:38:41,290 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:38:41,290 	Hypothesis: hallo , ich suche in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien .
2020-08-11 04:38:41,290 Example #3
2020-08-11 04:38:41,290 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:38:41,290 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:38:41,290 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:38:41,290 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:38:41,291 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:38:41,291 Validation result (greedy) at epoch  16, step      800: bleu:  15.07, loss: 16573.4922, ppl:  13.3245, duration: 67.5932s
2020-08-11 04:38:47,722 Epoch  16: total training loss 41.49
2020-08-11 04:38:47,723 EPOCH 17
2020-08-11 04:38:59,229 Epoch  17: total training loss 36.75
2020-08-11 04:38:59,229 EPOCH 18
2020-08-11 04:39:03,425 Epoch  18 Step:      900 Batch Loss:     0.472494 Tokens per Sec:     5572, Lr: 0.000200
2020-08-11 04:39:10,925 Epoch  18: total training loss 33.95
2020-08-11 04:39:10,925 EPOCH 19
2020-08-11 04:39:22,424 Epoch  19: total training loss 30.30
2020-08-11 04:39:22,424 EPOCH 20
2020-08-11 04:39:25,619 Epoch  20 Step:     1000 Batch Loss:     0.194336 Tokens per Sec:     5619, Lr: 0.000200
2020-08-11 04:40:10,266 Hooray! New best validation result [ppl]!
2020-08-11 04:40:10,267 Saving new checkpoint.
2020-08-11 04:40:15,239 Example #0
2020-08-11 04:40:15,239 	Raw source:     ['hello', '.']
2020-08-11 04:40:15,239 	Raw hypothesis: ['hallo']
2020-08-11 04:40:15,239 	Source:     hello .
2020-08-11 04:40:15,239 	Reference:  hallo ,
2020-08-11 04:40:15,239 	Hypothesis: hallo
2020-08-11 04:40:15,240 Example #1
2020-08-11 04:40:15,240 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:40:15,240 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:40:15,240 	Source:     hi , how can i help you ?
2020-08-11 04:40:15,240 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:40:15,240 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:40:15,240 Example #2
2020-08-11 04:40:15,240 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:40:15,240 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 04:40:15,240 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:40:15,240 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:40:15,240 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 04:40:15,240 Example #3
2020-08-11 04:40:15,240 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:40:15,240 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:40:15,240 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:40:15,240 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:40:15,240 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:40:15,240 Validation result (greedy) at epoch  20, step     1000: bleu:  25.19, loss: 16482.9160, ppl:  13.1373, duration: 49.6209s
2020-08-11 04:40:23,738 Epoch  20: total training loss 26.87
2020-08-11 04:40:23,739 Training ended after  20 epochs.
2020-08-11 04:40:23,739 Best validation result (greedy) at step     1000:  13.14 ppl.

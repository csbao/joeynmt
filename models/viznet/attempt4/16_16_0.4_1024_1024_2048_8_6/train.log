2020-08-11 04:40:30,524 Hello! This is Joey-NMT.
2020-08-11 04:40:31,971 Total params: 96384000
2020-08-11 04:40:31,972 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 04:40:35,860 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 04:40:35,861 cfg.data.level                     : bpe
2020-08-11 04:40:35,861 cfg.data.lowercase                 : False
2020-08-11 04:40:35,861 cfg.data.max_sent_length           : 100
2020-08-11 04:40:35,861 cfg.data.src                       : en
2020-08-11 04:40:35,861 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 04:40:35,861 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 04:40:35,861 cfg.data.trg                       : de
2020-08-11 04:40:35,861 cfg.model.bias_initializer         : zeros
2020-08-11 04:40:35,861 cfg.model.decoder.dropout          : 0.1
2020-08-11 04:40:35,861 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 04:40:35,861 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 04:40:35,861 cfg.model.decoder.embeddings.scale : True
2020-08-11 04:40:35,861 cfg.model.decoder.ff_size          : 512
2020-08-11 04:40:35,861 cfg.model.decoder.freeze           : False
2020-08-11 04:40:35,861 cfg.model.decoder.hidden_size      : 1024
2020-08-11 04:40:35,861 cfg.model.decoder.num_heads        : 16
2020-08-11 04:40:35,861 cfg.model.decoder.num_layers       : 6
2020-08-11 04:40:35,861 cfg.model.decoder.type             : transformer
2020-08-11 04:40:35,861 cfg.model.embed_init_gain          : 1.0
2020-08-11 04:40:35,861 cfg.model.embed_initializer        : xavier
2020-08-11 04:40:35,861 cfg.model.encoder.dropout          : 0.4
2020-08-11 04:40:35,861 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 04:40:35,861 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 04:40:35,861 cfg.model.encoder.embeddings.scale : True
2020-08-11 04:40:35,861 cfg.model.encoder.ff_size          : 512
2020-08-11 04:40:35,862 cfg.model.encoder.freeze           : False
2020-08-11 04:40:35,862 cfg.model.encoder.hidden_size      : 1024
2020-08-11 04:40:35,862 cfg.model.encoder.multi_encoder    : False
2020-08-11 04:40:35,862 cfg.model.encoder.num_heads        : 16
2020-08-11 04:40:35,862 cfg.model.encoder.num_layers       : 6
2020-08-11 04:40:35,862 cfg.model.encoder.type             : transformer
2020-08-11 04:40:35,862 cfg.model.init_gain                : 1.0
2020-08-11 04:40:35,862 cfg.model.initializer              : xavier
2020-08-11 04:40:35,862 cfg.model.tied_embeddings          : False
2020-08-11 04:40:35,862 cfg.model.tied_softmax             : True
2020-08-11 04:40:35,862 cfg.name                           : transformer
2020-08-11 04:40:35,862 cfg.testing.alpha                  : 1.0
2020-08-11 04:40:35,862 cfg.testing.beam_size              : 5
2020-08-11 04:40:35,862 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 04:40:35,862 cfg.training.batch_multiplier      : 1
2020-08-11 04:40:35,862 cfg.training.batch_size            : 2048
2020-08-11 04:40:35,862 cfg.training.batch_type            : token
2020-08-11 04:40:35,862 cfg.training.decrease_factor       : 0.7
2020-08-11 04:40:35,862 cfg.training.early_stopping_metric : ppl
2020-08-11 04:40:35,862 cfg.training.epochs                : 20
2020-08-11 04:40:35,862 cfg.training.eval_metric           : bleu
2020-08-11 04:40:35,862 cfg.training.keep_last_ckpts       : 3
2020-08-11 04:40:35,862 cfg.training.label_smoothing       : 0.1
2020-08-11 04:40:35,862 cfg.training.learning_rate         : 0.0002
2020-08-11 04:40:35,862 cfg.training.learning_rate_min     : 1e-08
2020-08-11 04:40:35,862 cfg.training.logging_freq          : 100
2020-08-11 04:40:35,862 cfg.training.loss                  : crossentropy
2020-08-11 04:40:35,863 cfg.training.max_output_length     : 100
2020-08-11 04:40:35,863 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.4_1024_1024_2048_8_6
2020-08-11 04:40:35,863 cfg.training.normalization         : tokens
2020-08-11 04:40:35,863 cfg.training.optimizer             : adam
2020-08-11 04:40:35,863 cfg.training.overwrite             : True
2020-08-11 04:40:35,863 cfg.training.patience              : 8
2020-08-11 04:40:35,863 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 04:40:35,863 cfg.training.random_seed           : 42
2020-08-11 04:40:35,863 cfg.training.scheduling            : plateau
2020-08-11 04:40:35,863 cfg.training.shuffle               : True
2020-08-11 04:40:35,863 cfg.training.use_cuda              : True
2020-08-11 04:40:35,863 cfg.training.validation_freq       : 200
2020-08-11 04:40:35,863 cfg.training.weight_decay          : 0.0
2020-08-11 04:40:35,863 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 04:40:35,863 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 04:40:35,863 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 04:40:35,864 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 04:40:35,864 Number of Src words (types): 3468
2020-08-11 04:40:35,864 Number of Trg words (types): 4487
2020-08-11 04:40:35,864 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 04:40:35,869 EPOCH 1
2020-08-11 04:40:47,495 Epoch   1: total training loss 275.10
2020-08-11 04:40:47,496 EPOCH 2
2020-08-11 04:40:58,115 Epoch   2 Step:      100 Batch Loss:     5.910881 Tokens per Sec:     5519, Lr: 0.000200
2020-08-11 04:40:59,045 Epoch   2: total training loss 236.75
2020-08-11 04:40:59,045 EPOCH 3
2020-08-11 04:41:10,535 Epoch   3: total training loss 214.11
2020-08-11 04:41:10,535 EPOCH 4
2020-08-11 04:41:20,517 Epoch   4 Step:      200 Batch Loss:     4.288789 Tokens per Sec:     5593, Lr: 0.000200
2020-08-11 04:42:23,361 Hooray! New best validation result [ppl]!
2020-08-11 04:42:23,362 Saving new checkpoint.
2020-08-11 04:42:28,039 Example #0
2020-08-11 04:42:28,040 	Raw source:     ['hello', '.']
2020-08-11 04:42:28,040 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:42:28,040 	Source:     hello .
2020-08-11 04:42:28,040 	Reference:  hallo ,
2020-08-11 04:42:28,040 	Hypothesis: hallo .
2020-08-11 04:42:28,040 Example #1
2020-08-11 04:42:28,040 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:42:28,040 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:42:28,040 	Source:     hi , how can i help you ?
2020-08-11 04:42:28,040 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:42:28,040 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:42:28,040 Example #2
2020-08-11 04:42:28,040 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:42:28,040 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar']
2020-08-11 04:42:28,040 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:42:28,040 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:42:28,041 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar
2020-08-11 04:42:28,041 Example #3
2020-08-11 04:42:28,041 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:42:28,041 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', '?']
2020-08-11 04:42:28,041 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:42:28,041 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:42:28,041 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von ?
2020-08-11 04:42:28,041 Validation result (greedy) at epoch   4, step      200: bleu:   2.48, loss: 23910.4180, ppl:  41.9300, duration: 67.5241s
2020-08-11 04:42:29,626 Epoch   4: total training loss 181.66
2020-08-11 04:42:29,626 EPOCH 5
2020-08-11 04:42:41,246 Epoch   5: total training loss 164.33
2020-08-11 04:42:41,246 EPOCH 6
2020-08-11 04:42:50,684 Epoch   6 Step:      300 Batch Loss:     1.848303 Tokens per Sec:     5568, Lr: 0.000200
2020-08-11 04:42:52,889 Epoch   6: total training loss 137.85
2020-08-11 04:42:52,889 EPOCH 7
2020-08-11 04:43:04,400 Epoch   7: total training loss 128.23
2020-08-11 04:43:04,401 EPOCH 8
2020-08-11 04:43:12,930 Epoch   8 Step:      400 Batch Loss:     2.072894 Tokens per Sec:     5629, Lr: 0.000200
2020-08-11 04:44:15,779 Hooray! New best validation result [ppl]!
2020-08-11 04:44:15,779 Saving new checkpoint.
2020-08-11 04:44:20,463 Example #0
2020-08-11 04:44:20,463 	Raw source:     ['hello', '.']
2020-08-11 04:44:20,463 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:44:20,464 	Source:     hello .
2020-08-11 04:44:20,464 	Reference:  hallo ,
2020-08-11 04:44:20,464 	Hypothesis: hallo .
2020-08-11 04:44:20,464 Example #1
2020-08-11 04:44:20,464 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:44:20,464 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:44:20,464 	Source:     hi , how can i help you ?
2020-08-11 04:44:20,464 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:44:20,464 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:44:20,464 Example #2
2020-08-11 04:44:20,464 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:44:20,464 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:44:20,464 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:44:20,465 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:44:20,465 	Hypothesis: hallo , ich bin in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 04:44:20,465 Example #3
2020-08-11 04:44:20,465 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:44:20,465 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'essen', '?']
2020-08-11 04:44:20,465 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:44:20,465 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:44:20,465 	Hypothesis: ok , welche art von essen ?
2020-08-11 04:44:20,465 Validation result (greedy) at epoch   8, step      400: bleu:   8.16, loss: 18438.3867, ppl:  17.8321, duration: 67.5353s
2020-08-11 04:44:23,474 Epoch   8: total training loss 108.66
2020-08-11 04:44:23,474 EPOCH 9
2020-08-11 04:44:34,961 Epoch   9: total training loss 98.03
2020-08-11 04:44:34,962 EPOCH 10
2020-08-11 04:44:42,687 Epoch  10 Step:      500 Batch Loss:     2.130236 Tokens per Sec:     5686, Lr: 0.000200
2020-08-11 04:44:46,478 Epoch  10: total training loss 96.18
2020-08-11 04:44:46,479 EPOCH 11
2020-08-11 04:44:57,996 Epoch  11: total training loss 83.44
2020-08-11 04:44:57,996 EPOCH 12
2020-08-11 04:45:04,600 Epoch  12 Step:      600 Batch Loss:     1.457490 Tokens per Sec:     5622, Lr: 0.000200
2020-08-11 04:46:07,443 Hooray! New best validation result [ppl]!
2020-08-11 04:46:07,443 Saving new checkpoint.
2020-08-11 04:46:12,045 Example #0
2020-08-11 04:46:12,045 	Raw source:     ['hello', '.']
2020-08-11 04:46:12,045 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:46:12,045 	Source:     hello .
2020-08-11 04:46:12,045 	Reference:  hallo ,
2020-08-11 04:46:12,045 	Hypothesis: hallo .
2020-08-11 04:46:12,045 Example #1
2020-08-11 04:46:12,045 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:46:12,045 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:46:12,045 	Source:     hi , how can i help you ?
2020-08-11 04:46:12,045 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:46:12,045 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:46:12,045 Example #2
2020-08-11 04:46:12,045 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:46:12,045 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:46:12,045 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:46:12,045 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:46:12,045 	Hypothesis: hallo , ich suche in san francisco , kalifornien , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien .
2020-08-11 04:46:12,045 Example #3
2020-08-11 04:46:12,045 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:46:12,045 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:46:12,045 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:46:12,045 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:46:12,046 	Hypothesis: ok , welche art von restaurant suchen sie ?
2020-08-11 04:46:12,046 Validation result (greedy) at epoch  12, step      600: bleu:  12.52, loss: 17377.8691, ppl:  15.1090, duration: 67.4456s
2020-08-11 04:46:17,052 Epoch  12: total training loss 73.87
2020-08-11 04:46:17,052 EPOCH 13
2020-08-11 04:46:28,657 Epoch  13: total training loss 61.19
2020-08-11 04:46:28,657 EPOCH 14
2020-08-11 04:46:34,760 Epoch  14 Step:      700 Batch Loss:     1.154684 Tokens per Sec:     5523, Lr: 0.000200
2020-08-11 04:46:40,271 Epoch  14: total training loss 54.29
2020-08-11 04:46:40,271 EPOCH 15
2020-08-11 04:46:51,856 Epoch  15: total training loss 47.85
2020-08-11 04:46:51,856 EPOCH 16
2020-08-11 04:46:56,937 Epoch  16 Step:      800 Batch Loss:     0.737235 Tokens per Sec:     5636, Lr: 0.000200
2020-08-11 04:47:59,782 Hooray! New best validation result [ppl]!
2020-08-11 04:47:59,782 Saving new checkpoint.
2020-08-11 04:48:04,582 Example #0
2020-08-11 04:48:04,582 	Raw source:     ['hello', '.']
2020-08-11 04:48:04,582 	Raw hypothesis: ['hallo']
2020-08-11 04:48:04,582 	Source:     hello .
2020-08-11 04:48:04,582 	Reference:  hallo ,
2020-08-11 04:48:04,582 	Hypothesis: hallo
2020-08-11 04:48:04,582 Example #1
2020-08-11 04:48:04,583 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:48:04,583 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:48:04,583 	Source:     hi , how can i help you ?
2020-08-11 04:48:04,583 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:48:04,583 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:48:04,583 Example #2
2020-08-11 04:48:04,583 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:48:04,583 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:48:04,583 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:48:04,583 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:48:04,583 	Hypothesis: hallo , ich suche in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien .
2020-08-11 04:48:04,583 Example #3
2020-08-11 04:48:04,583 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:48:04,583 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:48:04,583 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:48:04,583 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:48:04,583 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:48:04,583 Validation result (greedy) at epoch  16, step      800: bleu:  15.07, loss: 16573.4922, ppl:  13.3245, duration: 67.6461s
2020-08-11 04:48:11,020 Epoch  16: total training loss 41.49
2020-08-11 04:48:11,020 EPOCH 17
2020-08-11 04:48:22,496 Epoch  17: total training loss 36.75
2020-08-11 04:48:22,496 EPOCH 18
2020-08-11 04:48:26,747 Epoch  18 Step:      900 Batch Loss:     0.472494 Tokens per Sec:     5498, Lr: 0.000200
2020-08-11 04:48:34,231 Epoch  18: total training loss 33.95
2020-08-11 04:48:34,231 EPOCH 19
2020-08-11 04:48:45,748 Epoch  19: total training loss 30.30
2020-08-11 04:48:45,749 EPOCH 20
2020-08-11 04:48:48,993 Epoch  20 Step:     1000 Batch Loss:     0.194336 Tokens per Sec:     5534, Lr: 0.000200
2020-08-11 04:49:33,691 Hooray! New best validation result [ppl]!
2020-08-11 04:49:33,691 Saving new checkpoint.
2020-08-11 04:49:38,511 Example #0
2020-08-11 04:49:38,511 	Raw source:     ['hello', '.']
2020-08-11 04:49:38,512 	Raw hypothesis: ['hallo']
2020-08-11 04:49:38,512 	Source:     hello .
2020-08-11 04:49:38,512 	Reference:  hallo ,
2020-08-11 04:49:38,512 	Hypothesis: hallo
2020-08-11 04:49:38,512 Example #1
2020-08-11 04:49:38,512 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:49:38,512 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:49:38,512 	Source:     hi , how can i help you ?
2020-08-11 04:49:38,512 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:49:38,512 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:49:38,512 Example #2
2020-08-11 04:49:38,512 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:49:38,512 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 04:49:38,512 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:49:38,512 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:49:38,512 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 04:49:38,513 Example #3
2020-08-11 04:49:38,513 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:49:38,513 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:49:38,513 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:49:38,513 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:49:38,513 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:49:38,513 Validation result (greedy) at epoch  20, step     1000: bleu:  25.19, loss: 16482.9160, ppl:  13.1373, duration: 49.5196s
2020-08-11 04:49:46,979 Epoch  20: total training loss 26.87
2020-08-11 04:49:46,979 Training ended after  20 epochs.
2020-08-11 04:49:46,979 Best validation result (greedy) at step     1000:  13.14 ppl.

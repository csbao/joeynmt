2020-08-11 03:08:32,053 Hello! This is Joey-NMT.
2020-08-11 03:08:33,564 Total params: 96384000
2020-08-11 03:08:33,566 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 03:08:37,502 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 03:08:37,502 cfg.data.level                     : bpe
2020-08-11 03:08:37,502 cfg.data.lowercase                 : False
2020-08-11 03:08:37,502 cfg.data.max_sent_length           : 100
2020-08-11 03:08:37,502 cfg.data.src                       : en
2020-08-11 03:08:37,502 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 03:08:37,502 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 03:08:37,502 cfg.data.trg                       : de
2020-08-11 03:08:37,503 cfg.model.bias_initializer         : zeros
2020-08-11 03:08:37,503 cfg.model.decoder.dropout          : 0.1
2020-08-11 03:08:37,503 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 03:08:37,503 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 03:08:37,503 cfg.model.decoder.embeddings.scale : True
2020-08-11 03:08:37,503 cfg.model.decoder.ff_size          : 512
2020-08-11 03:08:37,503 cfg.model.decoder.freeze           : False
2020-08-11 03:08:37,503 cfg.model.decoder.hidden_size      : 1024
2020-08-11 03:08:37,503 cfg.model.decoder.num_heads        : 16
2020-08-11 03:08:37,503 cfg.model.decoder.num_layers       : 6
2020-08-11 03:08:37,503 cfg.model.decoder.type             : transformer
2020-08-11 03:08:37,503 cfg.model.embed_init_gain          : 1.0
2020-08-11 03:08:37,503 cfg.model.embed_initializer        : xavier
2020-08-11 03:08:37,503 cfg.model.encoder.dropout          : 0.2
2020-08-11 03:08:37,503 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 03:08:37,503 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 03:08:37,503 cfg.model.encoder.embeddings.scale : True
2020-08-11 03:08:37,503 cfg.model.encoder.ff_size          : 512
2020-08-11 03:08:37,504 cfg.model.encoder.freeze           : False
2020-08-11 03:08:37,504 cfg.model.encoder.hidden_size      : 1024
2020-08-11 03:08:37,504 cfg.model.encoder.multi_encoder    : False
2020-08-11 03:08:37,504 cfg.model.encoder.num_heads        : 16
2020-08-11 03:08:37,504 cfg.model.encoder.num_layers       : 6
2020-08-11 03:08:37,504 cfg.model.encoder.type             : transformer
2020-08-11 03:08:37,504 cfg.model.init_gain                : 1.0
2020-08-11 03:08:37,504 cfg.model.initializer              : xavier
2020-08-11 03:08:37,504 cfg.model.tied_embeddings          : False
2020-08-11 03:08:37,504 cfg.model.tied_softmax             : True
2020-08-11 03:08:37,504 cfg.name                           : transformer
2020-08-11 03:08:37,504 cfg.testing.alpha                  : 1.0
2020-08-11 03:08:37,504 cfg.testing.beam_size              : 5
2020-08-11 03:08:37,504 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 03:08:37,504 cfg.training.batch_multiplier      : 1
2020-08-11 03:08:37,504 cfg.training.batch_size            : 2048
2020-08-11 03:08:37,504 cfg.training.batch_type            : token
2020-08-11 03:08:37,504 cfg.training.decrease_factor       : 0.7
2020-08-11 03:08:37,504 cfg.training.early_stopping_metric : ppl
2020-08-11 03:08:37,504 cfg.training.epochs                : 20
2020-08-11 03:08:37,504 cfg.training.eval_metric           : bleu
2020-08-11 03:08:37,504 cfg.training.keep_last_ckpts       : 3
2020-08-11 03:08:37,504 cfg.training.label_smoothing       : 0.1
2020-08-11 03:08:37,504 cfg.training.learning_rate         : 0.0002
2020-08-11 03:08:37,504 cfg.training.learning_rate_min     : 1e-08
2020-08-11 03:08:37,505 cfg.training.logging_freq          : 100
2020-08-11 03:08:37,505 cfg.training.loss                  : crossentropy
2020-08-11 03:08:37,505 cfg.training.max_output_length     : 100
2020-08-11 03:08:37,505 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.2_1024_1024_2048_6_8
2020-08-11 03:08:37,505 cfg.training.normalization         : tokens
2020-08-11 03:08:37,505 cfg.training.optimizer             : adam
2020-08-11 03:08:37,505 cfg.training.overwrite             : True
2020-08-11 03:08:37,505 cfg.training.patience              : 8
2020-08-11 03:08:37,505 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 03:08:37,505 cfg.training.random_seed           : 42
2020-08-11 03:08:37,505 cfg.training.scheduling            : plateau
2020-08-11 03:08:37,505 cfg.training.shuffle               : True
2020-08-11 03:08:37,505 cfg.training.use_cuda              : True
2020-08-11 03:08:37,505 cfg.training.validation_freq       : 200
2020-08-11 03:08:37,505 cfg.training.weight_decay          : 0.0
2020-08-11 03:08:37,505 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 03:08:37,505 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 03:08:37,505 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 03:08:37,506 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 03:08:37,506 Number of Src words (types): 3468
2020-08-11 03:08:37,506 Number of Trg words (types): 4487
2020-08-11 03:08:37,506 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 03:08:37,511 EPOCH 1
2020-08-11 03:08:49,078 Epoch   1: total training loss 276.17
2020-08-11 03:08:49,079 EPOCH 2
2020-08-11 03:08:59,810 Epoch   2 Step:      100 Batch Loss:     5.841509 Tokens per Sec:     5462, Lr: 0.000200
2020-08-11 03:09:00,740 Epoch   2: total training loss 239.24
2020-08-11 03:09:00,740 EPOCH 3
2020-08-11 03:09:12,310 Epoch   3: total training loss 216.96
2020-08-11 03:09:12,310 EPOCH 4
2020-08-11 03:09:22,232 Epoch   4 Step:      200 Batch Loss:     4.385108 Tokens per Sec:     5627, Lr: 0.000200
2020-08-11 03:10:25,197 Hooray! New best validation result [ppl]!
2020-08-11 03:10:25,197 Saving new checkpoint.
2020-08-11 03:10:30,062 Example #0
2020-08-11 03:10:30,062 	Raw source:     ['hello', '.']
2020-08-11 03:10:30,062 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:10:30,063 	Source:     hello .
2020-08-11 03:10:30,063 	Reference:  hallo ,
2020-08-11 03:10:30,063 	Hypothesis: hallo .
2020-08-11 03:10:30,063 Example #1
2020-08-11 03:10:30,063 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:10:30,063 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:10:30,063 	Source:     hi , how can i help you ?
2020-08-11 03:10:30,063 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:10:30,063 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:10:30,063 Example #2
2020-08-11 03:10:30,063 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:10:30,063 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', '.']
2020-08-11 03:10:30,063 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:10:30,063 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:10:30,063 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar mit mit mit .
2020-08-11 03:10:30,063 Example #3
2020-08-11 03:10:30,063 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:10:30,063 	Raw hypothesis: ['okay', ',', 'was', 'möchten', 'sie', '?']
2020-08-11 03:10:30,063 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:10:30,063 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:10:30,063 	Hypothesis: okay , was möchten sie ?
2020-08-11 03:10:30,063 Validation result (greedy) at epoch   4, step      200: bleu:   3.26, loss: 24170.8125, ppl:  43.6712, duration: 67.8313s
2020-08-11 03:10:31,662 Epoch   4: total training loss 186.81
2020-08-11 03:10:31,662 EPOCH 5
2020-08-11 03:10:43,232 Epoch   5: total training loss 168.58
2020-08-11 03:10:43,232 EPOCH 6
2020-08-11 03:10:52,627 Epoch   6 Step:      300 Batch Loss:     1.924582 Tokens per Sec:     5594, Lr: 0.000200
2020-08-11 03:10:54,838 Epoch   6: total training loss 142.02
2020-08-11 03:10:54,838 EPOCH 7
2020-08-11 03:11:06,367 Epoch   7: total training loss 128.70
2020-08-11 03:11:06,367 EPOCH 8
2020-08-11 03:11:14,860 Epoch   8 Step:      400 Batch Loss:     2.046563 Tokens per Sec:     5653, Lr: 0.000200
2020-08-11 03:12:17,819 Hooray! New best validation result [ppl]!
2020-08-11 03:12:17,820 Saving new checkpoint.
2020-08-11 03:12:22,553 Example #0
2020-08-11 03:12:22,553 	Raw source:     ['hello', '.']
2020-08-11 03:12:22,553 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:12:22,553 	Source:     hello .
2020-08-11 03:12:22,553 	Reference:  hallo ,
2020-08-11 03:12:22,553 	Hypothesis: hallo .
2020-08-11 03:12:22,553 Example #1
2020-08-11 03:12:22,553 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:12:22,553 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:12:22,553 	Source:     hi , how can i help you ?
2020-08-11 03:12:22,553 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:12:22,553 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:12:22,554 Example #2
2020-08-11 03:12:22,554 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:12:22,554 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', 'in', 'der', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:12:22,554 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:12:22,554 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:12:22,554 	Hypothesis: hallo , ich bin in sacramento in der arden fair mall in san francisco , kalifornien .
2020-08-11 03:12:22,554 Example #3
2020-08-11 03:12:22,554 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:12:22,554 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-11 03:12:22,554 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:12:22,554 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:12:22,554 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-11 03:12:22,554 Validation result (greedy) at epoch   8, step      400: bleu:  13.91, loss: 17739.1934, ppl:  15.9866, duration: 67.6937s
2020-08-11 03:12:25,562 Epoch   8: total training loss 107.46
2020-08-11 03:12:25,562 EPOCH 9
2020-08-11 03:12:37,062 Epoch   9: total training loss 95.44
2020-08-11 03:12:37,062 EPOCH 10
2020-08-11 03:12:44,802 Epoch  10 Step:      500 Batch Loss:     2.035819 Tokens per Sec:     5675, Lr: 0.000200
2020-08-11 03:12:48,664 Epoch  10: total training loss 91.65
2020-08-11 03:12:48,664 EPOCH 11
2020-08-11 03:13:00,205 Epoch  11: total training loss 77.76
2020-08-11 03:13:00,205 EPOCH 12
2020-08-11 03:13:07,011 Epoch  12 Step:      600 Batch Loss:     1.298036 Tokens per Sec:     5455, Lr: 0.000200
2020-08-11 03:13:45,518 Hooray! New best validation result [ppl]!
2020-08-11 03:13:45,519 Saving new checkpoint.
2020-08-11 03:13:50,276 Example #0
2020-08-11 03:13:50,277 	Raw source:     ['hello', '.']
2020-08-11 03:13:50,277 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:13:50,277 	Source:     hello .
2020-08-11 03:13:50,277 	Reference:  hallo ,
2020-08-11 03:13:50,277 	Hypothesis: hallo .
2020-08-11 03:13:50,277 Example #1
2020-08-11 03:13:50,277 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:13:50,277 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:13:50,277 	Source:     hi , how can i help you ?
2020-08-11 03:13:50,277 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:13:50,277 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:13:50,277 Example #2
2020-08-11 03:13:50,277 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:13:50,277 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:13:50,277 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:13:50,277 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:13:50,277 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien .
2020-08-11 03:13:50,277 Example #3
2020-08-11 03:13:50,277 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:13:50,277 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:13:50,278 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:13:50,278 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:13:50,278 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:13:50,278 Validation result (greedy) at epoch  12, step      600: bleu:  24.89, loss: 16240.0293, ppl:  12.6481, duration: 43.2667s
2020-08-11 03:13:55,267 Epoch  12: total training loss 66.85
2020-08-11 03:13:55,267 EPOCH 13
2020-08-11 03:14:06,757 Epoch  13: total training loss 55.15
2020-08-11 03:14:06,757 EPOCH 14
2020-08-11 03:14:12,878 Epoch  14 Step:      700 Batch Loss:     1.006325 Tokens per Sec:     5507, Lr: 0.000200
2020-08-11 03:14:18,319 Epoch  14: total training loss 47.52
2020-08-11 03:14:18,320 EPOCH 15
2020-08-11 03:14:29,865 Epoch  15: total training loss 42.02
2020-08-11 03:14:29,865 EPOCH 16
2020-08-11 03:14:35,013 Epoch  16 Step:      800 Batch Loss:     0.628578 Tokens per Sec:     5563, Lr: 0.000200
2020-08-11 03:15:04,754 Hooray! New best validation result [ppl]!
2020-08-11 03:15:04,755 Saving new checkpoint.
2020-08-11 03:15:09,626 Example #0
2020-08-11 03:15:09,626 	Raw source:     ['hello', '.']
2020-08-11 03:15:09,626 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:15:09,626 	Source:     hello .
2020-08-11 03:15:09,626 	Reference:  hallo ,
2020-08-11 03:15:09,626 	Hypothesis: hallo .
2020-08-11 03:15:09,626 Example #1
2020-08-11 03:15:09,626 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:15:09,626 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:15:09,626 	Source:     hi , how can i help you ?
2020-08-11 03:15:09,626 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:15:09,626 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:15:09,626 Example #2
2020-08-11 03:15:09,626 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:15:09,626 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 03:15:09,627 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:15:09,627 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:15:09,627 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 03:15:09,627 Example #3
2020-08-11 03:15:09,627 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:15:09,627 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:15:09,627 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:15:09,627 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:15:09,627 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:15:09,627 Validation result (greedy) at epoch  16, step      800: bleu:  29.01, loss: 15603.6152, ppl:  11.4509, duration: 34.6135s
2020-08-11 03:15:15,975 Epoch  16: total training loss 35.67
2020-08-11 03:15:15,976 EPOCH 17
2020-08-11 03:15:27,593 Epoch  17: total training loss 31.55
2020-08-11 03:15:27,593 EPOCH 18
2020-08-11 03:15:31,771 Epoch  18 Step:      900 Batch Loss:     0.380682 Tokens per Sec:     5596, Lr: 0.000200
2020-08-11 03:15:39,255 Epoch  18: total training loss 28.61
2020-08-11 03:15:39,255 EPOCH 19
2020-08-11 03:15:50,755 Epoch  19: total training loss 24.47
2020-08-11 03:15:50,755 EPOCH 20
2020-08-11 03:15:53,907 Epoch  20 Step:     1000 Batch Loss:     0.137829 Tokens per Sec:     5696, Lr: 0.000200
2020-08-11 03:16:17,351 Example #0
2020-08-11 03:16:17,352 	Raw source:     ['hello', '.']
2020-08-11 03:16:17,352 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:16:17,352 	Source:     hello .
2020-08-11 03:16:17,352 	Reference:  hallo ,
2020-08-11 03:16:17,352 	Hypothesis: hallo .
2020-08-11 03:16:17,352 Example #1
2020-08-11 03:16:17,352 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:16:17,352 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:16:17,352 	Source:     hi , how can i help you ?
2020-08-11 03:16:17,352 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:16:17,352 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:16:17,352 Example #2
2020-08-11 03:16:17,352 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:16:17,352 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:16:17,352 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:16:17,352 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:16:17,352 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 03:16:17,352 Example #3
2020-08-11 03:16:17,352 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:16:17,352 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:16:17,352 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:16:17,353 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:16:17,353 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:16:17,353 Validation result (greedy) at epoch  20, step     1000: bleu:  33.00, loss: 15715.4883, ppl:  11.6528, duration: 23.4455s
2020-08-11 03:16:25,954 Epoch  20: total training loss 21.52
2020-08-11 03:16:25,954 Training ended after  20 epochs.
2020-08-11 03:16:25,954 Best validation result (greedy) at step      800:  11.45 ppl.

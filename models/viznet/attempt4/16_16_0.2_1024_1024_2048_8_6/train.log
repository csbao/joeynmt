2020-08-11 03:16:32,700 Hello! This is Joey-NMT.
2020-08-11 03:16:34,016 Total params: 96384000
2020-08-11 03:16:34,017 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 03:16:37,918 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 03:16:37,918 cfg.data.level                     : bpe
2020-08-11 03:16:37,918 cfg.data.lowercase                 : False
2020-08-11 03:16:37,918 cfg.data.max_sent_length           : 100
2020-08-11 03:16:37,918 cfg.data.src                       : en
2020-08-11 03:16:37,918 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 03:16:37,918 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 03:16:37,919 cfg.data.trg                       : de
2020-08-11 03:16:37,919 cfg.model.bias_initializer         : zeros
2020-08-11 03:16:37,919 cfg.model.decoder.dropout          : 0.1
2020-08-11 03:16:37,919 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 03:16:37,919 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 03:16:37,919 cfg.model.decoder.embeddings.scale : True
2020-08-11 03:16:37,919 cfg.model.decoder.ff_size          : 512
2020-08-11 03:16:37,919 cfg.model.decoder.freeze           : False
2020-08-11 03:16:37,919 cfg.model.decoder.hidden_size      : 1024
2020-08-11 03:16:37,919 cfg.model.decoder.num_heads        : 16
2020-08-11 03:16:37,919 cfg.model.decoder.num_layers       : 6
2020-08-11 03:16:37,919 cfg.model.decoder.type             : transformer
2020-08-11 03:16:37,919 cfg.model.embed_init_gain          : 1.0
2020-08-11 03:16:37,919 cfg.model.embed_initializer        : xavier
2020-08-11 03:16:37,919 cfg.model.encoder.dropout          : 0.2
2020-08-11 03:16:37,919 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 03:16:37,919 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 03:16:37,919 cfg.model.encoder.embeddings.scale : True
2020-08-11 03:16:37,920 cfg.model.encoder.ff_size          : 512
2020-08-11 03:16:37,920 cfg.model.encoder.freeze           : False
2020-08-11 03:16:37,920 cfg.model.encoder.hidden_size      : 1024
2020-08-11 03:16:37,920 cfg.model.encoder.multi_encoder    : False
2020-08-11 03:16:37,920 cfg.model.encoder.num_heads        : 16
2020-08-11 03:16:37,920 cfg.model.encoder.num_layers       : 6
2020-08-11 03:16:37,920 cfg.model.encoder.type             : transformer
2020-08-11 03:16:37,920 cfg.model.init_gain                : 1.0
2020-08-11 03:16:37,920 cfg.model.initializer              : xavier
2020-08-11 03:16:37,920 cfg.model.tied_embeddings          : False
2020-08-11 03:16:37,920 cfg.model.tied_softmax             : True
2020-08-11 03:16:37,920 cfg.name                           : transformer
2020-08-11 03:16:37,920 cfg.testing.alpha                  : 1.0
2020-08-11 03:16:37,920 cfg.testing.beam_size              : 5
2020-08-11 03:16:37,920 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 03:16:37,920 cfg.training.batch_multiplier      : 1
2020-08-11 03:16:37,920 cfg.training.batch_size            : 2048
2020-08-11 03:16:37,920 cfg.training.batch_type            : token
2020-08-11 03:16:37,920 cfg.training.decrease_factor       : 0.7
2020-08-11 03:16:37,921 cfg.training.early_stopping_metric : ppl
2020-08-11 03:16:37,921 cfg.training.epochs                : 20
2020-08-11 03:16:37,921 cfg.training.eval_metric           : bleu
2020-08-11 03:16:37,921 cfg.training.keep_last_ckpts       : 3
2020-08-11 03:16:37,921 cfg.training.label_smoothing       : 0.1
2020-08-11 03:16:37,921 cfg.training.learning_rate         : 0.0002
2020-08-11 03:16:37,921 cfg.training.learning_rate_min     : 1e-08
2020-08-11 03:16:37,921 cfg.training.logging_freq          : 100
2020-08-11 03:16:37,921 cfg.training.loss                  : crossentropy
2020-08-11 03:16:37,921 cfg.training.max_output_length     : 100
2020-08-11 03:16:37,921 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.2_1024_1024_2048_8_6
2020-08-11 03:16:37,921 cfg.training.normalization         : tokens
2020-08-11 03:16:37,921 cfg.training.optimizer             : adam
2020-08-11 03:16:37,921 cfg.training.overwrite             : True
2020-08-11 03:16:37,921 cfg.training.patience              : 8
2020-08-11 03:16:37,921 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 03:16:37,921 cfg.training.random_seed           : 42
2020-08-11 03:16:37,921 cfg.training.scheduling            : plateau
2020-08-11 03:16:37,922 cfg.training.shuffle               : True
2020-08-11 03:16:37,922 cfg.training.use_cuda              : True
2020-08-11 03:16:37,922 cfg.training.validation_freq       : 200
2020-08-11 03:16:37,922 cfg.training.weight_decay          : 0.0
2020-08-11 03:16:37,922 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 03:16:37,922 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 03:16:37,922 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 03:16:37,922 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 03:16:37,923 Number of Src words (types): 3468
2020-08-11 03:16:37,923 Number of Trg words (types): 4487
2020-08-11 03:16:37,923 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 03:16:37,927 EPOCH 1
2020-08-11 03:16:49,508 Epoch   1: total training loss 276.17
2020-08-11 03:16:49,508 EPOCH 2
2020-08-11 03:17:00,195 Epoch   2 Step:      100 Batch Loss:     5.841509 Tokens per Sec:     5484, Lr: 0.000200
2020-08-11 03:17:01,163 Epoch   2: total training loss 239.24
2020-08-11 03:17:01,163 EPOCH 3
2020-08-11 03:17:12,668 Epoch   3: total training loss 216.96
2020-08-11 03:17:12,669 EPOCH 4
2020-08-11 03:17:22,592 Epoch   4 Step:      200 Batch Loss:     4.385108 Tokens per Sec:     5625, Lr: 0.000200
2020-08-11 03:18:25,346 Hooray! New best validation result [ppl]!
2020-08-11 03:18:25,346 Saving new checkpoint.
2020-08-11 03:18:30,113 Example #0
2020-08-11 03:18:30,113 	Raw source:     ['hello', '.']
2020-08-11 03:18:30,113 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:18:30,113 	Source:     hello .
2020-08-11 03:18:30,113 	Reference:  hallo ,
2020-08-11 03:18:30,113 	Hypothesis: hallo .
2020-08-11 03:18:30,113 Example #1
2020-08-11 03:18:30,113 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:18:30,113 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:18:30,113 	Source:     hi , how can i help you ?
2020-08-11 03:18:30,113 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:18:30,113 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:18:30,113 Example #2
2020-08-11 03:18:30,113 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:18:30,113 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', '.']
2020-08-11 03:18:30,114 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:18:30,114 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:18:30,114 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar mit mit mit .
2020-08-11 03:18:30,114 Example #3
2020-08-11 03:18:30,114 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:18:30,114 	Raw hypothesis: ['okay', ',', 'was', 'möchten', 'sie', '?']
2020-08-11 03:18:30,114 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:18:30,114 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:18:30,114 	Hypothesis: okay , was möchten sie ?
2020-08-11 03:18:30,114 Validation result (greedy) at epoch   4, step      200: bleu:   3.26, loss: 24170.8125, ppl:  43.6712, duration: 67.5211s
2020-08-11 03:18:31,712 Epoch   4: total training loss 186.81
2020-08-11 03:18:31,713 EPOCH 5
2020-08-11 03:18:43,260 Epoch   5: total training loss 168.58
2020-08-11 03:18:43,260 EPOCH 6
2020-08-11 03:18:52,668 Epoch   6 Step:      300 Batch Loss:     1.924582 Tokens per Sec:     5585, Lr: 0.000200
2020-08-11 03:18:54,870 Epoch   6: total training loss 142.02
2020-08-11 03:18:54,870 EPOCH 7
2020-08-11 03:19:06,376 Epoch   7: total training loss 128.70
2020-08-11 03:19:06,376 EPOCH 8
2020-08-11 03:19:14,949 Epoch   8 Step:      400 Batch Loss:     2.046563 Tokens per Sec:     5601, Lr: 0.000200
2020-08-11 03:20:17,700 Hooray! New best validation result [ppl]!
2020-08-11 03:20:17,701 Saving new checkpoint.
2020-08-11 03:20:22,364 Example #0
2020-08-11 03:20:22,364 	Raw source:     ['hello', '.']
2020-08-11 03:20:22,364 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:20:22,364 	Source:     hello .
2020-08-11 03:20:22,364 	Reference:  hallo ,
2020-08-11 03:20:22,364 	Hypothesis: hallo .
2020-08-11 03:20:22,364 Example #1
2020-08-11 03:20:22,364 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:20:22,364 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:20:22,364 	Source:     hi , how can i help you ?
2020-08-11 03:20:22,365 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:20:22,365 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:20:22,365 Example #2
2020-08-11 03:20:22,365 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:20:22,365 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', 'in', 'der', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:20:22,365 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:20:22,365 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:20:22,365 	Hypothesis: hallo , ich bin in sacramento in der arden fair mall in san francisco , kalifornien .
2020-08-11 03:20:22,365 Example #3
2020-08-11 03:20:22,365 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:20:22,365 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-11 03:20:22,365 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:20:22,365 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:20:22,365 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-11 03:20:22,365 Validation result (greedy) at epoch   8, step      400: bleu:  13.91, loss: 17739.1934, ppl:  15.9866, duration: 67.4156s
2020-08-11 03:20:25,386 Epoch   8: total training loss 107.46
2020-08-11 03:20:25,386 EPOCH 9
2020-08-11 03:20:36,941 Epoch   9: total training loss 95.44
2020-08-11 03:20:36,942 EPOCH 10
2020-08-11 03:20:44,721 Epoch  10 Step:      500 Batch Loss:     2.035819 Tokens per Sec:     5646, Lr: 0.000200
2020-08-11 03:20:48,551 Epoch  10: total training loss 91.65
2020-08-11 03:20:48,551 EPOCH 11
2020-08-11 03:21:00,095 Epoch  11: total training loss 77.76
2020-08-11 03:21:00,096 EPOCH 12
2020-08-11 03:21:06,831 Epoch  12 Step:      600 Batch Loss:     1.298036 Tokens per Sec:     5512, Lr: 0.000200
2020-08-11 03:21:45,226 Hooray! New best validation result [ppl]!
2020-08-11 03:21:45,226 Saving new checkpoint.
2020-08-11 03:21:49,915 Example #0
2020-08-11 03:21:49,915 	Raw source:     ['hello', '.']
2020-08-11 03:21:49,915 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:21:49,915 	Source:     hello .
2020-08-11 03:21:49,915 	Reference:  hallo ,
2020-08-11 03:21:49,916 	Hypothesis: hallo .
2020-08-11 03:21:49,916 Example #1
2020-08-11 03:21:49,916 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:21:49,916 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:21:49,916 	Source:     hi , how can i help you ?
2020-08-11 03:21:49,916 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:21:49,916 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:21:49,916 Example #2
2020-08-11 03:21:49,916 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:21:49,916 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:21:49,916 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:21:49,916 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:21:49,916 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien .
2020-08-11 03:21:49,916 Example #3
2020-08-11 03:21:49,916 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:21:49,916 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:21:49,916 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:21:49,916 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:21:49,916 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:21:49,916 Validation result (greedy) at epoch  12, step      600: bleu:  24.89, loss: 16240.0293, ppl:  12.6481, duration: 43.0849s
2020-08-11 03:21:54,924 Epoch  12: total training loss 66.85
2020-08-11 03:21:54,924 EPOCH 13
2020-08-11 03:22:06,415 Epoch  13: total training loss 55.15
2020-08-11 03:22:06,415 EPOCH 14
2020-08-11 03:22:12,553 Epoch  14 Step:      700 Batch Loss:     1.006325 Tokens per Sec:     5491, Lr: 0.000200
2020-08-11 03:22:18,103 Epoch  14: total training loss 47.52
2020-08-11 03:22:18,104 EPOCH 15
2020-08-11 03:22:29,714 Epoch  15: total training loss 42.02
2020-08-11 03:22:29,714 EPOCH 16
2020-08-11 03:22:34,824 Epoch  16 Step:      800 Batch Loss:     0.628578 Tokens per Sec:     5605, Lr: 0.000200
2020-08-11 03:23:04,506 Hooray! New best validation result [ppl]!
2020-08-11 03:23:04,506 Saving new checkpoint.
2020-08-11 03:23:09,348 Example #0
2020-08-11 03:23:09,348 	Raw source:     ['hello', '.']
2020-08-11 03:23:09,348 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:23:09,348 	Source:     hello .
2020-08-11 03:23:09,348 	Reference:  hallo ,
2020-08-11 03:23:09,348 	Hypothesis: hallo .
2020-08-11 03:23:09,348 Example #1
2020-08-11 03:23:09,349 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:23:09,349 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:23:09,349 	Source:     hi , how can i help you ?
2020-08-11 03:23:09,349 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:23:09,349 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:23:09,349 Example #2
2020-08-11 03:23:09,349 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:23:09,349 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 03:23:09,349 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:23:09,349 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:23:09,349 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 03:23:09,349 Example #3
2020-08-11 03:23:09,349 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:23:09,349 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:23:09,349 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:23:09,349 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:23:09,349 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:23:09,349 Validation result (greedy) at epoch  16, step      800: bleu:  29.01, loss: 15603.6152, ppl:  11.4509, duration: 34.5256s
2020-08-11 03:23:15,736 Epoch  16: total training loss 35.67
2020-08-11 03:23:15,736 EPOCH 17
2020-08-11 03:23:27,257 Epoch  17: total training loss 31.55
2020-08-11 03:23:27,257 EPOCH 18
2020-08-11 03:23:31,472 Epoch  18 Step:      900 Batch Loss:     0.380682 Tokens per Sec:     5546, Lr: 0.000200
2020-08-11 03:23:38,914 Epoch  18: total training loss 28.61
2020-08-11 03:23:38,914 EPOCH 19
2020-08-11 03:23:50,427 Epoch  19: total training loss 24.47
2020-08-11 03:23:50,427 EPOCH 20
2020-08-11 03:23:53,582 Epoch  20 Step:     1000 Batch Loss:     0.137829 Tokens per Sec:     5691, Lr: 0.000200
2020-08-11 03:24:16,982 Example #0
2020-08-11 03:24:16,982 	Raw source:     ['hello', '.']
2020-08-11 03:24:16,982 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:24:16,983 	Source:     hello .
2020-08-11 03:24:16,983 	Reference:  hallo ,
2020-08-11 03:24:16,983 	Hypothesis: hallo .
2020-08-11 03:24:16,983 Example #1
2020-08-11 03:24:16,983 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:24:16,983 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:24:16,983 	Source:     hi , how can i help you ?
2020-08-11 03:24:16,983 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:24:16,983 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:24:16,983 Example #2
2020-08-11 03:24:16,983 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:24:16,983 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:24:16,983 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:24:16,983 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:24:16,983 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 03:24:16,983 Example #3
2020-08-11 03:24:16,983 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:24:16,983 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:24:16,983 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:24:16,983 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:24:16,983 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:24:16,983 Validation result (greedy) at epoch  20, step     1000: bleu:  33.00, loss: 15715.4883, ppl:  11.6528, duration: 23.4014s
2020-08-11 03:24:25,441 Epoch  20: total training loss 21.52
2020-08-11 03:24:25,441 Training ended after  20 epochs.
2020-08-11 03:24:25,441 Best validation result (greedy) at step      800:  11.45 ppl.

2020-08-11 04:21:41,936 Hello! This is Joey-NMT.
2020-08-11 04:21:43,256 Total params: 96384000
2020-08-11 04:21:43,257 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 04:21:47,152 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 04:21:47,152 cfg.data.level                     : bpe
2020-08-11 04:21:47,152 cfg.data.lowercase                 : False
2020-08-11 04:21:47,152 cfg.data.max_sent_length           : 100
2020-08-11 04:21:47,152 cfg.data.src                       : en
2020-08-11 04:21:47,152 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 04:21:47,152 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 04:21:47,152 cfg.data.trg                       : de
2020-08-11 04:21:47,153 cfg.model.bias_initializer         : zeros
2020-08-11 04:21:47,153 cfg.model.decoder.dropout          : 0.1
2020-08-11 04:21:47,153 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 04:21:47,153 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 04:21:47,153 cfg.model.decoder.embeddings.scale : True
2020-08-11 04:21:47,153 cfg.model.decoder.ff_size          : 512
2020-08-11 04:21:47,153 cfg.model.decoder.freeze           : False
2020-08-11 04:21:47,153 cfg.model.decoder.hidden_size      : 1024
2020-08-11 04:21:47,153 cfg.model.decoder.num_heads        : 16
2020-08-11 04:21:47,153 cfg.model.decoder.num_layers       : 6
2020-08-11 04:21:47,153 cfg.model.decoder.type             : transformer
2020-08-11 04:21:47,153 cfg.model.embed_init_gain          : 1.0
2020-08-11 04:21:47,153 cfg.model.embed_initializer        : xavier
2020-08-11 04:21:47,153 cfg.model.encoder.dropout          : 0.4
2020-08-11 04:21:47,153 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 04:21:47,153 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 04:21:47,153 cfg.model.encoder.embeddings.scale : True
2020-08-11 04:21:47,153 cfg.model.encoder.ff_size          : 512
2020-08-11 04:21:47,153 cfg.model.encoder.freeze           : False
2020-08-11 04:21:47,153 cfg.model.encoder.hidden_size      : 1024
2020-08-11 04:21:47,153 cfg.model.encoder.multi_encoder    : False
2020-08-11 04:21:47,153 cfg.model.encoder.num_heads        : 16
2020-08-11 04:21:47,153 cfg.model.encoder.num_layers       : 6
2020-08-11 04:21:47,154 cfg.model.encoder.type             : transformer
2020-08-11 04:21:47,154 cfg.model.init_gain                : 1.0
2020-08-11 04:21:47,154 cfg.model.initializer              : xavier
2020-08-11 04:21:47,154 cfg.model.tied_embeddings          : False
2020-08-11 04:21:47,154 cfg.model.tied_softmax             : True
2020-08-11 04:21:47,154 cfg.name                           : transformer
2020-08-11 04:21:47,154 cfg.testing.alpha                  : 1.0
2020-08-11 04:21:47,154 cfg.testing.beam_size              : 5
2020-08-11 04:21:47,154 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 04:21:47,154 cfg.training.batch_multiplier      : 1
2020-08-11 04:21:47,154 cfg.training.batch_size            : 2048
2020-08-11 04:21:47,154 cfg.training.batch_type            : token
2020-08-11 04:21:47,154 cfg.training.decrease_factor       : 0.7
2020-08-11 04:21:47,154 cfg.training.early_stopping_metric : ppl
2020-08-11 04:21:47,154 cfg.training.epochs                : 20
2020-08-11 04:21:47,154 cfg.training.eval_metric           : bleu
2020-08-11 04:21:47,154 cfg.training.keep_last_ckpts       : 3
2020-08-11 04:21:47,154 cfg.training.label_smoothing       : 0.1
2020-08-11 04:21:47,154 cfg.training.learning_rate         : 0.0002
2020-08-11 04:21:47,154 cfg.training.learning_rate_min     : 1e-08
2020-08-11 04:21:47,154 cfg.training.logging_freq          : 100
2020-08-11 04:21:47,155 cfg.training.loss                  : crossentropy
2020-08-11 04:21:47,155 cfg.training.max_output_length     : 100
2020-08-11 04:21:47,155 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.4_1024_1024_2048_6_6
2020-08-11 04:21:47,155 cfg.training.normalization         : tokens
2020-08-11 04:21:47,155 cfg.training.optimizer             : adam
2020-08-11 04:21:47,155 cfg.training.overwrite             : True
2020-08-11 04:21:47,155 cfg.training.patience              : 8
2020-08-11 04:21:47,155 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 04:21:47,155 cfg.training.random_seed           : 42
2020-08-11 04:21:47,155 cfg.training.scheduling            : plateau
2020-08-11 04:21:47,155 cfg.training.shuffle               : True
2020-08-11 04:21:47,155 cfg.training.use_cuda              : True
2020-08-11 04:21:47,155 cfg.training.validation_freq       : 200
2020-08-11 04:21:47,155 cfg.training.weight_decay          : 0.0
2020-08-11 04:21:47,155 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 04:21:47,155 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 04:21:47,155 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 04:21:47,156 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 04:21:47,156 Number of Src words (types): 3468
2020-08-11 04:21:47,156 Number of Trg words (types): 4487
2020-08-11 04:21:47,156 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 04:21:47,161 EPOCH 1
2020-08-11 04:21:58,788 Epoch   1: total training loss 275.10
2020-08-11 04:21:58,788 EPOCH 2
2020-08-11 04:22:09,555 Epoch   2 Step:      100 Batch Loss:     5.910881 Tokens per Sec:     5443, Lr: 0.000200
2020-08-11 04:22:10,495 Epoch   2: total training loss 236.75
2020-08-11 04:22:10,496 EPOCH 3
2020-08-11 04:22:22,043 Epoch   3: total training loss 214.11
2020-08-11 04:22:22,044 EPOCH 4
2020-08-11 04:22:32,008 Epoch   4 Step:      200 Batch Loss:     4.288789 Tokens per Sec:     5603, Lr: 0.000200
2020-08-11 04:23:34,757 Hooray! New best validation result [ppl]!
2020-08-11 04:23:34,758 Saving new checkpoint.
2020-08-11 04:23:39,610 Example #0
2020-08-11 04:23:39,611 	Raw source:     ['hello', '.']
2020-08-11 04:23:39,611 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:23:39,611 	Source:     hello .
2020-08-11 04:23:39,611 	Reference:  hallo ,
2020-08-11 04:23:39,611 	Hypothesis: hallo .
2020-08-11 04:23:39,611 Example #1
2020-08-11 04:23:39,611 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:23:39,611 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:23:39,611 	Source:     hi , how can i help you ?
2020-08-11 04:23:39,611 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:23:39,611 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:23:39,611 Example #2
2020-08-11 04:23:39,611 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:23:39,611 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar']
2020-08-11 04:23:39,611 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:23:39,611 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:23:39,612 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar
2020-08-11 04:23:39,612 Example #3
2020-08-11 04:23:39,612 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:23:39,612 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', '?']
2020-08-11 04:23:39,612 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:23:39,612 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:23:39,612 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von ?
2020-08-11 04:23:39,612 Validation result (greedy) at epoch   4, step      200: bleu:   2.48, loss: 23910.4180, ppl:  41.9300, duration: 67.6041s
2020-08-11 04:23:41,216 Epoch   4: total training loss 181.66
2020-08-11 04:23:41,216 EPOCH 5
2020-08-11 04:23:52,761 Epoch   5: total training loss 164.33
2020-08-11 04:23:52,761 EPOCH 6
2020-08-11 04:24:02,213 Epoch   6 Step:      300 Batch Loss:     1.848303 Tokens per Sec:     5559, Lr: 0.000200
2020-08-11 04:24:04,454 Epoch   6: total training loss 137.85
2020-08-11 04:24:04,455 EPOCH 7
2020-08-11 04:24:16,107 Epoch   7: total training loss 128.23
2020-08-11 04:24:16,108 EPOCH 8
2020-08-11 04:24:24,662 Epoch   8 Step:      400 Batch Loss:     2.072894 Tokens per Sec:     5613, Lr: 0.000200
2020-08-11 04:25:27,414 Hooray! New best validation result [ppl]!
2020-08-11 04:25:27,414 Saving new checkpoint.
2020-08-11 04:25:32,249 Example #0
2020-08-11 04:25:32,250 	Raw source:     ['hello', '.']
2020-08-11 04:25:32,250 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:25:32,250 	Source:     hello .
2020-08-11 04:25:32,250 	Reference:  hallo ,
2020-08-11 04:25:32,250 	Hypothesis: hallo .
2020-08-11 04:25:32,250 Example #1
2020-08-11 04:25:32,250 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:25:32,250 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:25:32,250 	Source:     hi , how can i help you ?
2020-08-11 04:25:32,250 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:25:32,250 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:25:32,250 Example #2
2020-08-11 04:25:32,250 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:25:32,250 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:25:32,250 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:25:32,250 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:25:32,250 	Hypothesis: hallo , ich bin in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 04:25:32,250 Example #3
2020-08-11 04:25:32,250 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:25:32,250 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'essen', '?']
2020-08-11 04:25:32,250 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:25:32,250 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:25:32,250 	Hypothesis: ok , welche art von essen ?
2020-08-11 04:25:32,251 Validation result (greedy) at epoch   8, step      400: bleu:   8.16, loss: 18438.3867, ppl:  17.8321, duration: 67.5882s
2020-08-11 04:25:35,209 Epoch   8: total training loss 108.66
2020-08-11 04:25:35,210 EPOCH 9
2020-08-11 04:25:46,788 Epoch   9: total training loss 98.03
2020-08-11 04:25:46,788 EPOCH 10
2020-08-11 04:25:54,464 Epoch  10 Step:      500 Batch Loss:     2.130236 Tokens per Sec:     5722, Lr: 0.000200
2020-08-11 04:25:58,287 Epoch  10: total training loss 96.18
2020-08-11 04:25:58,287 EPOCH 11
2020-08-11 04:26:09,845 Epoch  11: total training loss 83.44
2020-08-11 04:26:09,845 EPOCH 12
2020-08-11 04:26:16,537 Epoch  12 Step:      600 Batch Loss:     1.457490 Tokens per Sec:     5547, Lr: 0.000200
2020-08-11 04:27:19,287 Hooray! New best validation result [ppl]!
2020-08-11 04:27:19,288 Saving new checkpoint.
2020-08-11 04:27:24,135 Example #0
2020-08-11 04:27:24,135 	Raw source:     ['hello', '.']
2020-08-11 04:27:24,135 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:27:24,135 	Source:     hello .
2020-08-11 04:27:24,135 	Reference:  hallo ,
2020-08-11 04:27:24,135 	Hypothesis: hallo .
2020-08-11 04:27:24,135 Example #1
2020-08-11 04:27:24,135 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:27:24,135 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:27:24,135 	Source:     hi , how can i help you ?
2020-08-11 04:27:24,135 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:27:24,135 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:27:24,135 Example #2
2020-08-11 04:27:24,136 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:27:24,136 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:27:24,136 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:27:24,136 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:27:24,136 	Hypothesis: hallo , ich suche in san francisco , kalifornien , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien .
2020-08-11 04:27:24,136 Example #3
2020-08-11 04:27:24,136 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:27:24,136 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:27:24,136 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:27:24,136 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:27:24,136 	Hypothesis: ok , welche art von restaurant suchen sie ?
2020-08-11 04:27:24,136 Validation result (greedy) at epoch  12, step      600: bleu:  12.52, loss: 17377.8691, ppl:  15.1090, duration: 67.5986s
2020-08-11 04:27:29,161 Epoch  12: total training loss 73.87
2020-08-11 04:27:29,162 EPOCH 13
2020-08-11 04:27:40,697 Epoch  13: total training loss 61.19
2020-08-11 04:27:40,697 EPOCH 14
2020-08-11 04:27:46,806 Epoch  14 Step:      700 Batch Loss:     1.154684 Tokens per Sec:     5517, Lr: 0.000200
2020-08-11 04:27:52,299 Epoch  14: total training loss 54.29
2020-08-11 04:27:52,299 EPOCH 15
2020-08-11 04:28:03,847 Epoch  15: total training loss 47.85
2020-08-11 04:28:03,848 EPOCH 16
2020-08-11 04:28:08,935 Epoch  16 Step:      800 Batch Loss:     0.737235 Tokens per Sec:     5629, Lr: 0.000200
2020-08-11 04:29:11,709 Hooray! New best validation result [ppl]!
2020-08-11 04:29:11,710 Saving new checkpoint.
2020-08-11 04:29:16,857 Example #0
2020-08-11 04:29:16,857 	Raw source:     ['hello', '.']
2020-08-11 04:29:16,858 	Raw hypothesis: ['hallo']
2020-08-11 04:29:16,858 	Source:     hello .
2020-08-11 04:29:16,858 	Reference:  hallo ,
2020-08-11 04:29:16,858 	Hypothesis: hallo
2020-08-11 04:29:16,858 Example #1
2020-08-11 04:29:16,858 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:29:16,858 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:29:16,858 	Source:     hi , how can i help you ?
2020-08-11 04:29:16,858 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:29:16,858 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:29:16,858 Example #2
2020-08-11 04:29:16,858 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:29:16,858 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:29:16,858 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:29:16,858 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:29:16,858 	Hypothesis: hallo , ich suche in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien .
2020-08-11 04:29:16,858 Example #3
2020-08-11 04:29:16,858 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:29:16,858 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:29:16,858 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:29:16,858 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:29:16,858 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:29:16,858 Validation result (greedy) at epoch  16, step      800: bleu:  15.07, loss: 16573.4922, ppl:  13.3245, duration: 67.9234s
2020-08-11 04:29:23,247 Epoch  16: total training loss 41.49
2020-08-11 04:29:23,247 EPOCH 17
2020-08-11 04:29:34,846 Epoch  17: total training loss 36.75
2020-08-11 04:29:34,847 EPOCH 18
2020-08-11 04:29:39,121 Epoch  18 Step:      900 Batch Loss:     0.472494 Tokens per Sec:     5468, Lr: 0.000200
2020-08-11 04:29:46,618 Epoch  18: total training loss 33.95
2020-08-11 04:29:46,618 EPOCH 19
2020-08-11 04:29:58,161 Epoch  19: total training loss 30.30
2020-08-11 04:29:58,162 EPOCH 20
2020-08-11 04:30:01,364 Epoch  20 Step:     1000 Batch Loss:     0.194336 Tokens per Sec:     5607, Lr: 0.000200
2020-08-11 04:30:46,002 Hooray! New best validation result [ppl]!
2020-08-11 04:30:46,003 Saving new checkpoint.
2020-08-11 04:30:51,097 Example #0
2020-08-11 04:30:51,098 	Raw source:     ['hello', '.']
2020-08-11 04:30:51,098 	Raw hypothesis: ['hallo']
2020-08-11 04:30:51,098 	Source:     hello .
2020-08-11 04:30:51,098 	Reference:  hallo ,
2020-08-11 04:30:51,098 	Hypothesis: hallo
2020-08-11 04:30:51,098 Example #1
2020-08-11 04:30:51,098 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:30:51,098 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:30:51,098 	Source:     hi , how can i help you ?
2020-08-11 04:30:51,098 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:30:51,098 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:30:51,098 Example #2
2020-08-11 04:30:51,098 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:30:51,098 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 04:30:51,098 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:30:51,098 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:30:51,099 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 04:30:51,099 Example #3
2020-08-11 04:30:51,099 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:30:51,099 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:30:51,099 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:30:51,099 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:30:51,099 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:30:51,099 Validation result (greedy) at epoch  20, step     1000: bleu:  25.19, loss: 16482.9160, ppl:  13.1373, duration: 49.7343s
2020-08-11 04:30:59,694 Epoch  20: total training loss 26.87
2020-08-11 04:30:59,694 Training ended after  20 epochs.
2020-08-11 04:30:59,694 Best validation result (greedy) at step     1000:  13.14 ppl.

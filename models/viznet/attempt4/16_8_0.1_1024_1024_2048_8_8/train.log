2020-08-11 05:56:04,714 Hello! This is Joey-NMT.
2020-08-11 05:56:06,047 Total params: 96384000
2020-08-11 05:56:06,048 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 05:56:10,047 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 05:56:10,048 cfg.data.level                     : bpe
2020-08-11 05:56:10,048 cfg.data.lowercase                 : False
2020-08-11 05:56:10,048 cfg.data.max_sent_length           : 100
2020-08-11 05:56:10,048 cfg.data.src                       : en
2020-08-11 05:56:10,048 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 05:56:10,048 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 05:56:10,048 cfg.data.trg                       : de
2020-08-11 05:56:10,048 cfg.model.bias_initializer         : zeros
2020-08-11 05:56:10,048 cfg.model.decoder.dropout          : 0.1
2020-08-11 05:56:10,048 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 05:56:10,048 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 05:56:10,048 cfg.model.decoder.embeddings.scale : True
2020-08-11 05:56:10,048 cfg.model.decoder.ff_size          : 512
2020-08-11 05:56:10,048 cfg.model.decoder.freeze           : False
2020-08-11 05:56:10,048 cfg.model.decoder.hidden_size      : 1024
2020-08-11 05:56:10,048 cfg.model.decoder.num_heads        : 8
2020-08-11 05:56:10,048 cfg.model.decoder.num_layers       : 6
2020-08-11 05:56:10,048 cfg.model.decoder.type             : transformer
2020-08-11 05:56:10,048 cfg.model.embed_init_gain          : 1.0
2020-08-11 05:56:10,048 cfg.model.embed_initializer        : xavier
2020-08-11 05:56:10,048 cfg.model.encoder.dropout          : 0.1
2020-08-11 05:56:10,048 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 05:56:10,048 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 05:56:10,049 cfg.model.encoder.embeddings.scale : True
2020-08-11 05:56:10,049 cfg.model.encoder.ff_size          : 512
2020-08-11 05:56:10,049 cfg.model.encoder.freeze           : False
2020-08-11 05:56:10,049 cfg.model.encoder.hidden_size      : 1024
2020-08-11 05:56:10,049 cfg.model.encoder.multi_encoder    : False
2020-08-11 05:56:10,049 cfg.model.encoder.num_heads        : 16
2020-08-11 05:56:10,049 cfg.model.encoder.num_layers       : 6
2020-08-11 05:56:10,049 cfg.model.encoder.type             : transformer
2020-08-11 05:56:10,049 cfg.model.init_gain                : 1.0
2020-08-11 05:56:10,049 cfg.model.initializer              : xavier
2020-08-11 05:56:10,049 cfg.model.tied_embeddings          : False
2020-08-11 05:56:10,049 cfg.model.tied_softmax             : True
2020-08-11 05:56:10,049 cfg.name                           : transformer
2020-08-11 05:56:10,049 cfg.testing.alpha                  : 1.0
2020-08-11 05:56:10,049 cfg.testing.beam_size              : 5
2020-08-11 05:56:10,049 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 05:56:10,049 cfg.training.batch_multiplier      : 1
2020-08-11 05:56:10,049 cfg.training.batch_size            : 2048
2020-08-11 05:56:10,049 cfg.training.batch_type            : token
2020-08-11 05:56:10,049 cfg.training.decrease_factor       : 0.7
2020-08-11 05:56:10,049 cfg.training.early_stopping_metric : ppl
2020-08-11 05:56:10,049 cfg.training.epochs                : 20
2020-08-11 05:56:10,049 cfg.training.eval_metric           : bleu
2020-08-11 05:56:10,049 cfg.training.keep_last_ckpts       : 3
2020-08-11 05:56:10,049 cfg.training.label_smoothing       : 0.1
2020-08-11 05:56:10,049 cfg.training.learning_rate         : 0.0002
2020-08-11 05:56:10,049 cfg.training.learning_rate_min     : 1e-08
2020-08-11 05:56:10,049 cfg.training.logging_freq          : 100
2020-08-11 05:56:10,050 cfg.training.loss                  : crossentropy
2020-08-11 05:56:10,050 cfg.training.max_output_length     : 100
2020-08-11 05:56:10,050 cfg.training.model_dir             : models/viznet/attempt4/16_8_0.1_1024_1024_2048_8_8
2020-08-11 05:56:10,050 cfg.training.normalization         : tokens
2020-08-11 05:56:10,050 cfg.training.optimizer             : adam
2020-08-11 05:56:10,050 cfg.training.overwrite             : True
2020-08-11 05:56:10,050 cfg.training.patience              : 8
2020-08-11 05:56:10,050 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 05:56:10,050 cfg.training.random_seed           : 42
2020-08-11 05:56:10,050 cfg.training.scheduling            : plateau
2020-08-11 05:56:10,050 cfg.training.shuffle               : True
2020-08-11 05:56:10,050 cfg.training.use_cuda              : True
2020-08-11 05:56:10,050 cfg.training.validation_freq       : 200
2020-08-11 05:56:10,050 cfg.training.weight_decay          : 0.0
2020-08-11 05:56:10,050 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 05:56:10,050 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 05:56:10,050 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 05:56:10,051 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 05:56:10,051 Number of Src words (types): 3468
2020-08-11 05:56:10,051 Number of Trg words (types): 4487
2020-08-11 05:56:10,051 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=8),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 05:56:10,055 EPOCH 1
2020-08-11 05:56:21,494 Epoch   1: total training loss 276.21
2020-08-11 05:56:21,494 EPOCH 2
2020-08-11 05:56:31,982 Epoch   2 Step:      100 Batch Loss:     5.886423 Tokens per Sec:     5588, Lr: 0.000200
2020-08-11 05:56:32,895 Epoch   2: total training loss 240.76
2020-08-11 05:56:32,895 EPOCH 3
2020-08-11 05:56:44,320 Epoch   3: total training loss 222.29
2020-08-11 05:56:44,321 EPOCH 4
2020-08-11 05:56:54,126 Epoch   4 Step:      200 Batch Loss:     4.569406 Tokens per Sec:     5693, Lr: 0.000200
2020-08-11 05:57:50,064 Hooray! New best validation result [ppl]!
2020-08-11 05:57:50,064 Saving new checkpoint.
2020-08-11 05:57:54,901 Example #0
2020-08-11 05:57:54,901 	Raw source:     ['hello', '.']
2020-08-11 05:57:54,901 	Raw hypothesis: ['hallo', '.']
2020-08-11 05:57:54,901 	Source:     hello .
2020-08-11 05:57:54,901 	Reference:  hallo ,
2020-08-11 05:57:54,901 	Hypothesis: hallo .
2020-08-11 05:57:54,901 Example #1
2020-08-11 05:57:54,901 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 05:57:54,901 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 05:57:54,901 	Source:     hi , how can i help you ?
2020-08-11 05:57:54,901 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 05:57:54,901 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 05:57:54,901 Example #2
2020-08-11 05:57:54,901 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 05:57:54,901 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'ein', 'restaurant', 'restaurant', 'restaurant', 'restaurant', 'restaurant', '.']
2020-08-11 05:57:54,901 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 05:57:54,901 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 05:57:54,901 	Hypothesis: hallo , ich möchte ein ein restaurant restaurant restaurant restaurant restaurant .
2020-08-11 05:57:54,901 Example #3
2020-08-11 05:57:54,902 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 05:57:54,902 	Raw hypothesis: ['okay', ',', 'wie', 'viele', 'viele', '?']
2020-08-11 05:57:54,902 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 05:57:54,902 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 05:57:54,902 	Hypothesis: okay , wie viele viele ?
2020-08-11 05:57:54,902 Validation result (greedy) at epoch   4, step      200: bleu:   4.60, loss: 25133.4043, ppl:  50.7593, duration: 60.7754s
2020-08-11 05:57:56,477 Epoch   4: total training loss 195.65
2020-08-11 05:57:56,478 EPOCH 5
2020-08-11 05:58:07,852 Epoch   5: total training loss 179.36
2020-08-11 05:58:07,852 EPOCH 6
2020-08-11 05:58:17,246 Epoch   6 Step:      300 Batch Loss:     1.966964 Tokens per Sec:     5593, Lr: 0.000200
2020-08-11 05:58:19,423 Epoch   6: total training loss 150.82
2020-08-11 05:58:19,423 EPOCH 7
2020-08-11 05:58:30,713 Epoch   7: total training loss 135.10
2020-08-11 05:58:30,713 EPOCH 8
2020-08-11 05:58:39,055 Epoch   8 Step:      400 Batch Loss:     2.082359 Tokens per Sec:     5756, Lr: 0.000200
2020-08-11 05:59:37,023 Hooray! New best validation result [ppl]!
2020-08-11 05:59:37,023 Saving new checkpoint.
2020-08-11 05:59:41,894 Example #0
2020-08-11 05:59:41,894 	Raw source:     ['hello', '.']
2020-08-11 05:59:41,894 	Raw hypothesis: ['hallo', '.']
2020-08-11 05:59:41,894 	Source:     hello .
2020-08-11 05:59:41,894 	Reference:  hallo ,
2020-08-11 05:59:41,894 	Hypothesis: hallo .
2020-08-11 05:59:41,894 Example #1
2020-08-11 05:59:41,894 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 05:59:41,895 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 05:59:41,895 	Source:     hi , how can i help you ?
2020-08-11 05:59:41,895 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 05:59:41,895 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 05:59:41,895 Example #2
2020-08-11 05:59:41,895 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 05:59:41,895 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 05:59:41,895 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 05:59:41,895 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 05:59:41,895 	Hypothesis: hallo , ich bin in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 05:59:41,895 Example #3
2020-08-11 05:59:41,895 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 05:59:41,895 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'essen', '?']
2020-08-11 05:59:41,895 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 05:59:41,895 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 05:59:41,895 	Hypothesis: ok , welche art von essen ?
2020-08-11 05:59:41,895 Validation result (greedy) at epoch   8, step      400: bleu:  14.64, loss: 17923.3027, ppl:  16.4531, duration: 62.8401s
2020-08-11 05:59:44,860 Epoch   8: total training loss 112.81
2020-08-11 05:59:44,860 EPOCH 9
2020-08-11 05:59:56,230 Epoch   9: total training loss 98.02
2020-08-11 05:59:56,230 EPOCH 10
2020-08-11 06:00:03,840 Epoch  10 Step:      500 Batch Loss:     1.997460 Tokens per Sec:     5772, Lr: 0.000200
2020-08-11 06:00:07,618 Epoch  10: total training loss 88.30
2020-08-11 06:00:07,618 EPOCH 11
2020-08-11 06:00:18,992 Epoch  11: total training loss 76.43
2020-08-11 06:00:18,993 EPOCH 12
2020-08-11 06:00:25,635 Epoch  12 Step:      600 Batch Loss:     1.277534 Tokens per Sec:     5588, Lr: 0.000200
2020-08-11 06:01:00,429 Hooray! New best validation result [ppl]!
2020-08-11 06:01:00,429 Saving new checkpoint.
2020-08-11 06:01:05,260 Example #0
2020-08-11 06:01:05,260 	Raw source:     ['hello', '.']
2020-08-11 06:01:05,260 	Raw hypothesis: ['hallo']
2020-08-11 06:01:05,260 	Source:     hello .
2020-08-11 06:01:05,260 	Reference:  hallo ,
2020-08-11 06:01:05,260 	Hypothesis: hallo
2020-08-11 06:01:05,260 Example #1
2020-08-11 06:01:05,260 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 06:01:05,261 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 06:01:05,261 	Source:     hi , how can i help you ?
2020-08-11 06:01:05,261 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 06:01:05,261 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 06:01:05,261 Example #2
2020-08-11 06:01:05,261 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 06:01:05,261 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'sacramento', ',', 'kalifornien', ',', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 06:01:05,261 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 06:01:05,261 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 06:01:05,261 	Hypothesis: hallo , ich suche ein restaurant in sacramento , kalifornien , in sacramento , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 06:01:05,261 Example #3
2020-08-11 06:01:05,261 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 06:01:05,261 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 06:01:05,261 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 06:01:05,261 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 06:01:05,261 	Hypothesis: ok , welche art von restaurant suchen sie ?
2020-08-11 06:01:05,261 Validation result (greedy) at epoch  12, step      600: bleu:  25.65, loss: 16110.9355, ppl:  12.3955, duration: 39.6256s
2020-08-11 06:01:10,150 Epoch  12: total training loss 67.36
2020-08-11 06:01:10,151 EPOCH 13
2020-08-11 06:01:21,459 Epoch  13: total training loss 55.30
2020-08-11 06:01:21,460 EPOCH 14
2020-08-11 06:01:27,497 Epoch  14 Step:      700 Batch Loss:     0.988325 Tokens per Sec:     5583, Lr: 0.000200
2020-08-11 06:01:32,886 Epoch  14: total training loss 46.69
2020-08-11 06:01:32,887 EPOCH 15
2020-08-11 06:01:44,281 Epoch  15: total training loss 40.90
2020-08-11 06:01:44,281 EPOCH 16
2020-08-11 06:01:49,307 Epoch  16 Step:      800 Batch Loss:     0.541230 Tokens per Sec:     5698, Lr: 0.000200
2020-08-11 06:02:20,705 Hooray! New best validation result [ppl]!
2020-08-11 06:02:20,706 Saving new checkpoint.
2020-08-11 06:02:25,621 Example #0
2020-08-11 06:02:25,621 	Raw source:     ['hello', '.']
2020-08-11 06:02:25,621 	Raw hypothesis: ['hallo', '.']
2020-08-11 06:02:25,621 	Source:     hello .
2020-08-11 06:02:25,621 	Reference:  hallo ,
2020-08-11 06:02:25,621 	Hypothesis: hallo .
2020-08-11 06:02:25,621 Example #1
2020-08-11 06:02:25,621 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 06:02:25,621 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 06:02:25,621 	Source:     hi , how can i help you ?
2020-08-11 06:02:25,621 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 06:02:25,621 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 06:02:25,621 Example #2
2020-08-11 06:02:25,621 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 06:02:25,622 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 06:02:25,622 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 06:02:25,622 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 06:02:25,622 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien .
2020-08-11 06:02:25,622 Example #3
2020-08-11 06:02:25,622 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 06:02:25,622 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 06:02:25,622 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 06:02:25,622 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 06:02:25,622 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 06:02:25,622 Validation result (greedy) at epoch  16, step      800: bleu:  30.48, loss: 15131.3184, ppl:  10.6363, duration: 36.3148s
2020-08-11 06:02:31,896 Epoch  16: total training loss 35.06
2020-08-11 06:02:31,897 EPOCH 17
2020-08-11 06:02:43,252 Epoch  17: total training loss 30.39
2020-08-11 06:02:43,252 EPOCH 18
2020-08-11 06:02:47,427 Epoch  18 Step:      900 Batch Loss:     0.315400 Tokens per Sec:     5600, Lr: 0.000200
2020-08-11 06:02:54,851 Epoch  18: total training loss 27.94
2020-08-11 06:02:54,851 EPOCH 19
2020-08-11 06:03:06,224 Epoch  19: total training loss 25.42
2020-08-11 06:03:06,224 EPOCH 20
2020-08-11 06:03:09,385 Epoch  20 Step:     1000 Batch Loss:     0.120481 Tokens per Sec:     5680, Lr: 0.000200
2020-08-11 06:03:26,580 Example #0
2020-08-11 06:03:26,580 	Raw source:     ['hello', '.']
2020-08-11 06:03:26,580 	Raw hypothesis: ['hallo', '.']
2020-08-11 06:03:26,580 	Source:     hello .
2020-08-11 06:03:26,580 	Reference:  hallo ,
2020-08-11 06:03:26,580 	Hypothesis: hallo .
2020-08-11 06:03:26,580 Example #1
2020-08-11 06:03:26,580 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 06:03:26,580 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 06:03:26,580 	Source:     hi , how can i help you ?
2020-08-11 06:03:26,580 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 06:03:26,580 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 06:03:26,581 Example #2
2020-08-11 06:03:26,581 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 06:03:26,581 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'zum', 'arden', 'fair', 'in', 'sacramento', ',', 'kalifornien', '.']
2020-08-11 06:03:26,581 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 06:03:26,581 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 06:03:26,581 	Hypothesis: hallo , ich suche ein restaurant zum arden fair in sacramento , kalifornien .
2020-08-11 06:03:26,581 Example #3
2020-08-11 06:03:26,581 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 06:03:26,581 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 06:03:26,581 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 06:03:26,581 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 06:03:26,581 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 06:03:26,581 Validation result (greedy) at epoch  20, step     1000: bleu:  35.09, loss: 15204.4023, ppl:  10.7584, duration: 17.1959s
2020-08-11 06:03:35,030 Epoch  20: total training loss 23.28
2020-08-11 06:03:35,030 Training ended after  20 epochs.
2020-08-11 06:03:35,030 Best validation result (greedy) at step      800:  10.64 ppl.

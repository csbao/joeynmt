2020-08-11 03:24:32,187 Hello! This is Joey-NMT.
2020-08-11 03:24:33,526 Total params: 96384000
2020-08-11 03:24:33,527 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 03:24:37,492 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 03:24:37,492 cfg.data.level                     : bpe
2020-08-11 03:24:37,492 cfg.data.lowercase                 : False
2020-08-11 03:24:37,492 cfg.data.max_sent_length           : 100
2020-08-11 03:24:37,492 cfg.data.src                       : en
2020-08-11 03:24:37,492 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 03:24:37,492 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 03:24:37,492 cfg.data.trg                       : de
2020-08-11 03:24:37,492 cfg.model.bias_initializer         : zeros
2020-08-11 03:24:37,492 cfg.model.decoder.dropout          : 0.1
2020-08-11 03:24:37,492 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 03:24:37,493 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 03:24:37,493 cfg.model.decoder.embeddings.scale : True
2020-08-11 03:24:37,493 cfg.model.decoder.ff_size          : 512
2020-08-11 03:24:37,493 cfg.model.decoder.freeze           : False
2020-08-11 03:24:37,493 cfg.model.decoder.hidden_size      : 1024
2020-08-11 03:24:37,493 cfg.model.decoder.num_heads        : 16
2020-08-11 03:24:37,493 cfg.model.decoder.num_layers       : 6
2020-08-11 03:24:37,493 cfg.model.decoder.type             : transformer
2020-08-11 03:24:37,493 cfg.model.embed_init_gain          : 1.0
2020-08-11 03:24:37,493 cfg.model.embed_initializer        : xavier
2020-08-11 03:24:37,493 cfg.model.encoder.dropout          : 0.2
2020-08-11 03:24:37,493 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 03:24:37,493 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 03:24:37,493 cfg.model.encoder.embeddings.scale : True
2020-08-11 03:24:37,493 cfg.model.encoder.ff_size          : 512
2020-08-11 03:24:37,493 cfg.model.encoder.freeze           : False
2020-08-11 03:24:37,493 cfg.model.encoder.hidden_size      : 1024
2020-08-11 03:24:37,493 cfg.model.encoder.multi_encoder    : False
2020-08-11 03:24:37,493 cfg.model.encoder.num_heads        : 16
2020-08-11 03:24:37,493 cfg.model.encoder.num_layers       : 6
2020-08-11 03:24:37,493 cfg.model.encoder.type             : transformer
2020-08-11 03:24:37,494 cfg.model.init_gain                : 1.0
2020-08-11 03:24:37,494 cfg.model.initializer              : xavier
2020-08-11 03:24:37,494 cfg.model.tied_embeddings          : False
2020-08-11 03:24:37,494 cfg.model.tied_softmax             : True
2020-08-11 03:24:37,494 cfg.name                           : transformer
2020-08-11 03:24:37,494 cfg.testing.alpha                  : 1.0
2020-08-11 03:24:37,494 cfg.testing.beam_size              : 5
2020-08-11 03:24:37,494 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 03:24:37,494 cfg.training.batch_multiplier      : 1
2020-08-11 03:24:37,494 cfg.training.batch_size            : 2048
2020-08-11 03:24:37,494 cfg.training.batch_type            : token
2020-08-11 03:24:37,494 cfg.training.decrease_factor       : 0.7
2020-08-11 03:24:37,494 cfg.training.early_stopping_metric : ppl
2020-08-11 03:24:37,494 cfg.training.epochs                : 20
2020-08-11 03:24:37,494 cfg.training.eval_metric           : bleu
2020-08-11 03:24:37,494 cfg.training.keep_last_ckpts       : 3
2020-08-11 03:24:37,494 cfg.training.label_smoothing       : 0.1
2020-08-11 03:24:37,494 cfg.training.learning_rate         : 0.0002
2020-08-11 03:24:37,494 cfg.training.learning_rate_min     : 1e-08
2020-08-11 03:24:37,494 cfg.training.logging_freq          : 100
2020-08-11 03:24:37,494 cfg.training.loss                  : crossentropy
2020-08-11 03:24:37,495 cfg.training.max_output_length     : 100
2020-08-11 03:24:37,495 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.2_1024_1024_2048_8_8
2020-08-11 03:24:37,495 cfg.training.normalization         : tokens
2020-08-11 03:24:37,495 cfg.training.optimizer             : adam
2020-08-11 03:24:37,495 cfg.training.overwrite             : True
2020-08-11 03:24:37,495 cfg.training.patience              : 8
2020-08-11 03:24:37,495 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 03:24:37,495 cfg.training.random_seed           : 42
2020-08-11 03:24:37,495 cfg.training.scheduling            : plateau
2020-08-11 03:24:37,495 cfg.training.shuffle               : True
2020-08-11 03:24:37,495 cfg.training.use_cuda              : True
2020-08-11 03:24:37,495 cfg.training.validation_freq       : 200
2020-08-11 03:24:37,495 cfg.training.weight_decay          : 0.0
2020-08-11 03:24:37,495 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 03:24:37,495 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 03:24:37,495 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 03:24:37,496 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 03:24:37,496 Number of Src words (types): 3468
2020-08-11 03:24:37,496 Number of Trg words (types): 4487
2020-08-11 03:24:37,496 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 03:24:37,501 EPOCH 1
2020-08-11 03:24:49,052 Epoch   1: total training loss 276.17
2020-08-11 03:24:49,053 EPOCH 2
2020-08-11 03:24:59,791 Epoch   2 Step:      100 Batch Loss:     5.841509 Tokens per Sec:     5458, Lr: 0.000200
2020-08-11 03:25:00,731 Epoch   2: total training loss 239.24
2020-08-11 03:25:00,731 EPOCH 3
2020-08-11 03:25:12,301 Epoch   3: total training loss 216.96
2020-08-11 03:25:12,301 EPOCH 4
2020-08-11 03:25:22,220 Epoch   4 Step:      200 Batch Loss:     4.385108 Tokens per Sec:     5628, Lr: 0.000200
2020-08-11 03:26:24,967 Hooray! New best validation result [ppl]!
2020-08-11 03:26:24,967 Saving new checkpoint.
2020-08-11 03:26:29,704 Example #0
2020-08-11 03:26:29,704 	Raw source:     ['hello', '.']
2020-08-11 03:26:29,704 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:26:29,705 	Source:     hello .
2020-08-11 03:26:29,705 	Reference:  hallo ,
2020-08-11 03:26:29,705 	Hypothesis: hallo .
2020-08-11 03:26:29,705 Example #1
2020-08-11 03:26:29,705 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:26:29,705 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:26:29,705 	Source:     hi , how can i help you ?
2020-08-11 03:26:29,705 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:26:29,705 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:26:29,705 Example #2
2020-08-11 03:26:29,705 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:26:29,705 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', '.']
2020-08-11 03:26:29,705 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:26:29,705 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:26:29,706 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar mit mit mit .
2020-08-11 03:26:29,706 Example #3
2020-08-11 03:26:29,706 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:26:29,706 	Raw hypothesis: ['okay', ',', 'was', 'möchten', 'sie', '?']
2020-08-11 03:26:29,706 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:26:29,706 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:26:29,706 	Hypothesis: okay , was möchten sie ?
2020-08-11 03:26:29,706 Validation result (greedy) at epoch   4, step      200: bleu:   3.26, loss: 24170.8125, ppl:  43.6712, duration: 67.4852s
2020-08-11 03:26:31,341 Epoch   4: total training loss 186.81
2020-08-11 03:26:31,341 EPOCH 5
2020-08-11 03:26:42,928 Epoch   5: total training loss 168.58
2020-08-11 03:26:42,928 EPOCH 6
2020-08-11 03:26:52,305 Epoch   6 Step:      300 Batch Loss:     1.924582 Tokens per Sec:     5604, Lr: 0.000200
2020-08-11 03:26:54,516 Epoch   6: total training loss 142.02
2020-08-11 03:26:54,516 EPOCH 7
2020-08-11 03:27:06,112 Epoch   7: total training loss 128.70
2020-08-11 03:27:06,113 EPOCH 8
2020-08-11 03:27:14,643 Epoch   8 Step:      400 Batch Loss:     2.046563 Tokens per Sec:     5629, Lr: 0.000200
2020-08-11 03:28:17,380 Hooray! New best validation result [ppl]!
2020-08-11 03:28:17,380 Saving new checkpoint.
2020-08-11 03:28:22,155 Example #0
2020-08-11 03:28:22,156 	Raw source:     ['hello', '.']
2020-08-11 03:28:22,156 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:28:22,156 	Source:     hello .
2020-08-11 03:28:22,156 	Reference:  hallo ,
2020-08-11 03:28:22,156 	Hypothesis: hallo .
2020-08-11 03:28:22,156 Example #1
2020-08-11 03:28:22,156 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:28:22,156 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:28:22,156 	Source:     hi , how can i help you ?
2020-08-11 03:28:22,156 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:28:22,156 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:28:22,156 Example #2
2020-08-11 03:28:22,156 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:28:22,156 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', 'in', 'der', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:28:22,157 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:28:22,157 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:28:22,157 	Hypothesis: hallo , ich bin in sacramento in der arden fair mall in san francisco , kalifornien .
2020-08-11 03:28:22,157 Example #3
2020-08-11 03:28:22,157 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:28:22,157 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-11 03:28:22,157 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:28:22,157 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:28:22,157 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-11 03:28:22,157 Validation result (greedy) at epoch   8, step      400: bleu:  13.91, loss: 17739.1934, ppl:  15.9866, duration: 67.5143s
2020-08-11 03:28:25,124 Epoch   8: total training loss 107.46
2020-08-11 03:28:25,125 EPOCH 9
2020-08-11 03:28:36,698 Epoch   9: total training loss 95.44
2020-08-11 03:28:36,698 EPOCH 10
2020-08-11 03:28:44,570 Epoch  10 Step:      500 Batch Loss:     2.035819 Tokens per Sec:     5580, Lr: 0.000200
2020-08-11 03:28:48,401 Epoch  10: total training loss 91.65
2020-08-11 03:28:48,401 EPOCH 11
2020-08-11 03:28:59,984 Epoch  11: total training loss 77.76
2020-08-11 03:28:59,984 EPOCH 12
2020-08-11 03:29:06,655 Epoch  12 Step:      600 Batch Loss:     1.298036 Tokens per Sec:     5565, Lr: 0.000200
2020-08-11 03:29:45,053 Hooray! New best validation result [ppl]!
2020-08-11 03:29:45,054 Saving new checkpoint.
2020-08-11 03:29:49,859 Example #0
2020-08-11 03:29:49,859 	Raw source:     ['hello', '.']
2020-08-11 03:29:49,859 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:29:49,859 	Source:     hello .
2020-08-11 03:29:49,860 	Reference:  hallo ,
2020-08-11 03:29:49,860 	Hypothesis: hallo .
2020-08-11 03:29:49,860 Example #1
2020-08-11 03:29:49,860 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:29:49,860 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:29:49,860 	Source:     hi , how can i help you ?
2020-08-11 03:29:49,860 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:29:49,860 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:29:49,860 Example #2
2020-08-11 03:29:49,860 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:29:49,860 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:29:49,860 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:29:49,860 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:29:49,860 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien .
2020-08-11 03:29:49,860 Example #3
2020-08-11 03:29:49,860 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:29:49,860 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:29:49,860 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:29:49,860 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:29:49,860 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:29:49,861 Validation result (greedy) at epoch  12, step      600: bleu:  24.89, loss: 16240.0293, ppl:  12.6481, duration: 43.2051s
2020-08-11 03:29:54,846 Epoch  12: total training loss 66.85
2020-08-11 03:29:54,846 EPOCH 13
2020-08-11 03:30:06,418 Epoch  13: total training loss 55.15
2020-08-11 03:30:06,418 EPOCH 14
2020-08-11 03:30:12,512 Epoch  14 Step:      700 Batch Loss:     1.006325 Tokens per Sec:     5531, Lr: 0.000200
2020-08-11 03:30:18,039 Epoch  14: total training loss 47.52
2020-08-11 03:30:18,039 EPOCH 15
2020-08-11 03:30:29,710 Epoch  15: total training loss 42.02
2020-08-11 03:30:29,710 EPOCH 16
2020-08-11 03:30:34,835 Epoch  16 Step:      800 Batch Loss:     0.628578 Tokens per Sec:     5588, Lr: 0.000200
2020-08-11 03:31:04,538 Hooray! New best validation result [ppl]!
2020-08-11 03:31:04,538 Saving new checkpoint.
2020-08-11 03:31:09,534 Example #0
2020-08-11 03:31:09,534 	Raw source:     ['hello', '.']
2020-08-11 03:31:09,535 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:31:09,535 	Source:     hello .
2020-08-11 03:31:09,535 	Reference:  hallo ,
2020-08-11 03:31:09,535 	Hypothesis: hallo .
2020-08-11 03:31:09,535 Example #1
2020-08-11 03:31:09,535 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:31:09,535 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:31:09,535 	Source:     hi , how can i help you ?
2020-08-11 03:31:09,535 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:31:09,535 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:31:09,535 Example #2
2020-08-11 03:31:09,535 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:31:09,535 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 03:31:09,535 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:31:09,535 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:31:09,535 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 03:31:09,535 Example #3
2020-08-11 03:31:09,535 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:31:09,535 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:31:09,535 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:31:09,535 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:31:09,535 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:31:09,536 Validation result (greedy) at epoch  16, step      800: bleu:  29.01, loss: 15603.6152, ppl:  11.4509, duration: 34.7004s
2020-08-11 03:31:15,914 Epoch  16: total training loss 35.67
2020-08-11 03:31:15,914 EPOCH 17
2020-08-11 03:31:27,423 Epoch  17: total training loss 31.55
2020-08-11 03:31:27,424 EPOCH 18
2020-08-11 03:31:31,619 Epoch  18 Step:      900 Batch Loss:     0.380682 Tokens per Sec:     5572, Lr: 0.000200
2020-08-11 03:31:39,100 Epoch  18: total training loss 28.61
2020-08-11 03:31:39,100 EPOCH 19
2020-08-11 03:31:50,735 Epoch  19: total training loss 24.47
2020-08-11 03:31:50,735 EPOCH 20
2020-08-11 03:31:53,913 Epoch  20 Step:     1000 Batch Loss:     0.137829 Tokens per Sec:     5650, Lr: 0.000200
2020-08-11 03:32:17,325 Example #0
2020-08-11 03:32:17,326 	Raw source:     ['hello', '.']
2020-08-11 03:32:17,326 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:32:17,326 	Source:     hello .
2020-08-11 03:32:17,326 	Reference:  hallo ,
2020-08-11 03:32:17,326 	Hypothesis: hallo .
2020-08-11 03:32:17,326 Example #1
2020-08-11 03:32:17,326 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:32:17,326 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:32:17,326 	Source:     hi , how can i help you ?
2020-08-11 03:32:17,326 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:32:17,326 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:32:17,326 Example #2
2020-08-11 03:32:17,326 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:32:17,326 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:32:17,326 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:32:17,326 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:32:17,326 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 03:32:17,326 Example #3
2020-08-11 03:32:17,326 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:32:17,326 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:32:17,326 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:32:17,326 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:32:17,326 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:32:17,326 Validation result (greedy) at epoch  20, step     1000: bleu:  33.00, loss: 15715.4883, ppl:  11.6528, duration: 23.4128s
2020-08-11 03:32:25,882 Epoch  20: total training loss 21.52
2020-08-11 03:32:25,883 Training ended after  20 epochs.
2020-08-11 03:32:25,883 Best validation result (greedy) at step      800:  11.45 ppl.

2020-08-11 03:00:32,388 Hello! This is Joey-NMT.
2020-08-11 03:00:33,741 Total params: 96384000
2020-08-11 03:00:33,743 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 03:00:37,678 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 03:00:37,678 cfg.data.level                     : bpe
2020-08-11 03:00:37,679 cfg.data.lowercase                 : False
2020-08-11 03:00:37,679 cfg.data.max_sent_length           : 100
2020-08-11 03:00:37,679 cfg.data.src                       : en
2020-08-11 03:00:37,679 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 03:00:37,679 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 03:00:37,679 cfg.data.trg                       : de
2020-08-11 03:00:37,679 cfg.model.bias_initializer         : zeros
2020-08-11 03:00:37,679 cfg.model.decoder.dropout          : 0.1
2020-08-11 03:00:37,679 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 03:00:37,679 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 03:00:37,679 cfg.model.decoder.embeddings.scale : True
2020-08-11 03:00:37,679 cfg.model.decoder.ff_size          : 512
2020-08-11 03:00:37,679 cfg.model.decoder.freeze           : False
2020-08-11 03:00:37,679 cfg.model.decoder.hidden_size      : 1024
2020-08-11 03:00:37,679 cfg.model.decoder.num_heads        : 16
2020-08-11 03:00:37,679 cfg.model.decoder.num_layers       : 6
2020-08-11 03:00:37,679 cfg.model.decoder.type             : transformer
2020-08-11 03:00:37,679 cfg.model.embed_init_gain          : 1.0
2020-08-11 03:00:37,679 cfg.model.embed_initializer        : xavier
2020-08-11 03:00:37,679 cfg.model.encoder.dropout          : 0.2
2020-08-11 03:00:37,679 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 03:00:37,679 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 03:00:37,679 cfg.model.encoder.embeddings.scale : True
2020-08-11 03:00:37,679 cfg.model.encoder.ff_size          : 512
2020-08-11 03:00:37,679 cfg.model.encoder.freeze           : False
2020-08-11 03:00:37,680 cfg.model.encoder.hidden_size      : 1024
2020-08-11 03:00:37,680 cfg.model.encoder.multi_encoder    : False
2020-08-11 03:00:37,680 cfg.model.encoder.num_heads        : 16
2020-08-11 03:00:37,680 cfg.model.encoder.num_layers       : 6
2020-08-11 03:00:37,680 cfg.model.encoder.type             : transformer
2020-08-11 03:00:37,680 cfg.model.init_gain                : 1.0
2020-08-11 03:00:37,680 cfg.model.initializer              : xavier
2020-08-11 03:00:37,680 cfg.model.tied_embeddings          : False
2020-08-11 03:00:37,680 cfg.model.tied_softmax             : True
2020-08-11 03:00:37,680 cfg.name                           : transformer
2020-08-11 03:00:37,680 cfg.testing.alpha                  : 1.0
2020-08-11 03:00:37,680 cfg.testing.beam_size              : 5
2020-08-11 03:00:37,680 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 03:00:37,680 cfg.training.batch_multiplier      : 1
2020-08-11 03:00:37,680 cfg.training.batch_size            : 2048
2020-08-11 03:00:37,680 cfg.training.batch_type            : token
2020-08-11 03:00:37,680 cfg.training.decrease_factor       : 0.7
2020-08-11 03:00:37,680 cfg.training.early_stopping_metric : ppl
2020-08-11 03:00:37,680 cfg.training.epochs                : 20
2020-08-11 03:00:37,680 cfg.training.eval_metric           : bleu
2020-08-11 03:00:37,680 cfg.training.keep_last_ckpts       : 3
2020-08-11 03:00:37,680 cfg.training.label_smoothing       : 0.1
2020-08-11 03:00:37,680 cfg.training.learning_rate         : 0.0002
2020-08-11 03:00:37,680 cfg.training.learning_rate_min     : 1e-08
2020-08-11 03:00:37,680 cfg.training.logging_freq          : 100
2020-08-11 03:00:37,680 cfg.training.loss                  : crossentropy
2020-08-11 03:00:37,680 cfg.training.max_output_length     : 100
2020-08-11 03:00:37,680 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.2_1024_1024_2048_6_6
2020-08-11 03:00:37,681 cfg.training.normalization         : tokens
2020-08-11 03:00:37,681 cfg.training.optimizer             : adam
2020-08-11 03:00:37,681 cfg.training.overwrite             : True
2020-08-11 03:00:37,681 cfg.training.patience              : 8
2020-08-11 03:00:37,681 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 03:00:37,681 cfg.training.random_seed           : 42
2020-08-11 03:00:37,681 cfg.training.scheduling            : plateau
2020-08-11 03:00:37,681 cfg.training.shuffle               : True
2020-08-11 03:00:37,681 cfg.training.use_cuda              : True
2020-08-11 03:00:37,681 cfg.training.validation_freq       : 200
2020-08-11 03:00:37,681 cfg.training.weight_decay          : 0.0
2020-08-11 03:00:37,681 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 03:00:37,681 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 03:00:37,681 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 03:00:37,682 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 03:00:37,682 Number of Src words (types): 3468
2020-08-11 03:00:37,682 Number of Trg words (types): 4487
2020-08-11 03:00:37,682 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 03:00:37,686 EPOCH 1
2020-08-11 03:00:49,322 Epoch   1: total training loss 276.17
2020-08-11 03:00:49,322 EPOCH 2
2020-08-11 03:01:00,016 Epoch   2 Step:      100 Batch Loss:     5.841509 Tokens per Sec:     5481, Lr: 0.000200
2020-08-11 03:01:00,956 Epoch   2: total training loss 239.24
2020-08-11 03:01:00,956 EPOCH 3
2020-08-11 03:01:12,499 Epoch   3: total training loss 216.96
2020-08-11 03:01:12,499 EPOCH 4
2020-08-11 03:01:22,498 Epoch   4 Step:      200 Batch Loss:     4.385108 Tokens per Sec:     5583, Lr: 0.000200
2020-08-11 03:02:25,422 Hooray! New best validation result [ppl]!
2020-08-11 03:02:25,422 Saving new checkpoint.
2020-08-11 03:02:30,062 Example #0
2020-08-11 03:02:30,062 	Raw source:     ['hello', '.']
2020-08-11 03:02:30,062 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:02:30,062 	Source:     hello .
2020-08-11 03:02:30,062 	Reference:  hallo ,
2020-08-11 03:02:30,062 	Hypothesis: hallo .
2020-08-11 03:02:30,063 Example #1
2020-08-11 03:02:30,063 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:02:30,063 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:02:30,063 	Source:     hi , how can i help you ?
2020-08-11 03:02:30,063 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:02:30,063 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:02:30,063 Example #2
2020-08-11 03:02:30,063 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:02:30,063 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', '.']
2020-08-11 03:02:30,063 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:02:30,063 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:02:30,063 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar mit mit mit .
2020-08-11 03:02:30,063 Example #3
2020-08-11 03:02:30,063 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:02:30,063 	Raw hypothesis: ['okay', ',', 'was', 'möchten', 'sie', '?']
2020-08-11 03:02:30,063 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:02:30,064 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:02:30,064 	Hypothesis: okay , was möchten sie ?
2020-08-11 03:02:30,064 Validation result (greedy) at epoch   4, step      200: bleu:   3.26, loss: 24170.8125, ppl:  43.6712, duration: 67.5651s
2020-08-11 03:02:31,692 Epoch   4: total training loss 186.81
2020-08-11 03:02:31,693 EPOCH 5
2020-08-11 03:02:43,241 Epoch   5: total training loss 168.58
2020-08-11 03:02:43,242 EPOCH 6
2020-08-11 03:02:52,642 Epoch   6 Step:      300 Batch Loss:     1.924582 Tokens per Sec:     5590, Lr: 0.000200
2020-08-11 03:02:54,889 Epoch   6: total training loss 142.02
2020-08-11 03:02:54,889 EPOCH 7
2020-08-11 03:03:06,377 Epoch   7: total training loss 128.70
2020-08-11 03:03:06,377 EPOCH 8
2020-08-11 03:03:14,858 Epoch   8 Step:      400 Batch Loss:     2.046563 Tokens per Sec:     5661, Lr: 0.000200
2020-08-11 03:04:17,746 Hooray! New best validation result [ppl]!
2020-08-11 03:04:17,746 Saving new checkpoint.
2020-08-11 03:04:22,470 Example #0
2020-08-11 03:04:22,470 	Raw source:     ['hello', '.']
2020-08-11 03:04:22,470 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:04:22,470 	Source:     hello .
2020-08-11 03:04:22,471 	Reference:  hallo ,
2020-08-11 03:04:22,471 	Hypothesis: hallo .
2020-08-11 03:04:22,471 Example #1
2020-08-11 03:04:22,471 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:04:22,471 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:04:22,471 	Source:     hi , how can i help you ?
2020-08-11 03:04:22,471 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:04:22,471 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:04:22,471 Example #2
2020-08-11 03:04:22,471 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:04:22,471 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', 'in', 'der', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:04:22,471 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:04:22,471 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:04:22,471 	Hypothesis: hallo , ich bin in sacramento in der arden fair mall in san francisco , kalifornien .
2020-08-11 03:04:22,471 Example #3
2020-08-11 03:04:22,471 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:04:22,471 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-11 03:04:22,471 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:04:22,471 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:04:22,471 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-11 03:04:22,471 Validation result (greedy) at epoch   8, step      400: bleu:  13.91, loss: 17739.1934, ppl:  15.9866, duration: 67.6125s
2020-08-11 03:04:25,464 Epoch   8: total training loss 107.46
2020-08-11 03:04:25,464 EPOCH 9
2020-08-11 03:04:37,018 Epoch   9: total training loss 95.44
2020-08-11 03:04:37,018 EPOCH 10
2020-08-11 03:04:44,783 Epoch  10 Step:      500 Batch Loss:     2.035819 Tokens per Sec:     5657, Lr: 0.000200
2020-08-11 03:04:48,626 Epoch  10: total training loss 91.65
2020-08-11 03:04:48,626 EPOCH 11
2020-08-11 03:05:00,108 Epoch  11: total training loss 77.76
2020-08-11 03:05:00,108 EPOCH 12
2020-08-11 03:05:06,728 Epoch  12 Step:      600 Batch Loss:     1.298036 Tokens per Sec:     5608, Lr: 0.000200
2020-08-11 03:05:45,184 Hooray! New best validation result [ppl]!
2020-08-11 03:05:45,185 Saving new checkpoint.
2020-08-11 03:05:49,797 Example #0
2020-08-11 03:05:49,797 	Raw source:     ['hello', '.']
2020-08-11 03:05:49,797 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:05:49,797 	Source:     hello .
2020-08-11 03:05:49,797 	Reference:  hallo ,
2020-08-11 03:05:49,797 	Hypothesis: hallo .
2020-08-11 03:05:49,797 Example #1
2020-08-11 03:05:49,797 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:05:49,797 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:05:49,797 	Source:     hi , how can i help you ?
2020-08-11 03:05:49,798 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:05:49,798 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:05:49,798 Example #2
2020-08-11 03:05:49,798 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:05:49,798 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:05:49,798 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:05:49,798 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:05:49,798 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien .
2020-08-11 03:05:49,798 Example #3
2020-08-11 03:05:49,798 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:05:49,798 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:05:49,798 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:05:49,798 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:05:49,798 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:05:49,798 Validation result (greedy) at epoch  12, step      600: bleu:  24.89, loss: 16240.0293, ppl:  12.6481, duration: 43.0703s
2020-08-11 03:05:54,774 Epoch  12: total training loss 66.85
2020-08-11 03:05:54,774 EPOCH 13
2020-08-11 03:06:06,358 Epoch  13: total training loss 55.15
2020-08-11 03:06:06,359 EPOCH 14
2020-08-11 03:06:12,462 Epoch  14 Step:      700 Batch Loss:     1.006325 Tokens per Sec:     5522, Lr: 0.000200
2020-08-11 03:06:17,931 Epoch  14: total training loss 47.52
2020-08-11 03:06:17,931 EPOCH 15
2020-08-11 03:06:29,452 Epoch  15: total training loss 42.02
2020-08-11 03:06:29,453 EPOCH 16
2020-08-11 03:06:34,570 Epoch  16 Step:      800 Batch Loss:     0.628578 Tokens per Sec:     5596, Lr: 0.000200
2020-08-11 03:07:04,293 Hooray! New best validation result [ppl]!
2020-08-11 03:07:04,293 Saving new checkpoint.
2020-08-11 03:07:09,096 Example #0
2020-08-11 03:07:09,096 	Raw source:     ['hello', '.']
2020-08-11 03:07:09,096 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:07:09,096 	Source:     hello .
2020-08-11 03:07:09,096 	Reference:  hallo ,
2020-08-11 03:07:09,096 	Hypothesis: hallo .
2020-08-11 03:07:09,097 Example #1
2020-08-11 03:07:09,097 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:07:09,097 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:07:09,097 	Source:     hi , how can i help you ?
2020-08-11 03:07:09,097 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:07:09,097 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:07:09,097 Example #2
2020-08-11 03:07:09,097 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:07:09,097 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 03:07:09,097 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:07:09,097 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:07:09,097 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 03:07:09,097 Example #3
2020-08-11 03:07:09,097 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:07:09,097 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:07:09,098 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:07:09,098 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:07:09,098 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:07:09,098 Validation result (greedy) at epoch  16, step      800: bleu:  29.01, loss: 15603.6152, ppl:  11.4509, duration: 34.5275s
2020-08-11 03:07:15,530 Epoch  16: total training loss 35.67
2020-08-11 03:07:15,530 EPOCH 17
2020-08-11 03:07:27,077 Epoch  17: total training loss 31.55
2020-08-11 03:07:27,077 EPOCH 18
2020-08-11 03:07:31,256 Epoch  18 Step:      900 Batch Loss:     0.380682 Tokens per Sec:     5594, Lr: 0.000200
2020-08-11 03:07:38,708 Epoch  18: total training loss 28.61
2020-08-11 03:07:38,708 EPOCH 19
2020-08-11 03:07:50,233 Epoch  19: total training loss 24.47
2020-08-11 03:07:50,233 EPOCH 20
2020-08-11 03:07:53,382 Epoch  20 Step:     1000 Batch Loss:     0.137829 Tokens per Sec:     5701, Lr: 0.000200
2020-08-11 03:08:16,826 Example #0
2020-08-11 03:08:16,827 	Raw source:     ['hello', '.']
2020-08-11 03:08:16,827 	Raw hypothesis: ['hallo', '.']
2020-08-11 03:08:16,827 	Source:     hello .
2020-08-11 03:08:16,827 	Reference:  hallo ,
2020-08-11 03:08:16,827 	Hypothesis: hallo .
2020-08-11 03:08:16,827 Example #1
2020-08-11 03:08:16,827 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 03:08:16,827 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 03:08:16,827 	Source:     hi , how can i help you ?
2020-08-11 03:08:16,827 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 03:08:16,827 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 03:08:16,827 Example #2
2020-08-11 03:08:16,827 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 03:08:16,827 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 03:08:16,827 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 03:08:16,827 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 03:08:16,827 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 03:08:16,827 Example #3
2020-08-11 03:08:16,827 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 03:08:16,827 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 03:08:16,827 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 03:08:16,828 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 03:08:16,828 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 03:08:16,828 Validation result (greedy) at epoch  20, step     1000: bleu:  33.00, loss: 15715.4883, ppl:  11.6528, duration: 23.4448s
2020-08-11 03:08:25,346 Epoch  20: total training loss 21.52
2020-08-11 03:08:25,346 Training ended after  20 epochs.
2020-08-11 03:08:25,347 Best validation result (greedy) at step      800:  11.45 ppl.

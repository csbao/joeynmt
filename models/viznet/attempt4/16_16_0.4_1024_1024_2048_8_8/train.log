2020-08-11 04:49:53,788 Hello! This is Joey-NMT.
2020-08-11 04:49:55,124 Total params: 96384000
2020-08-11 04:49:55,125 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 04:49:59,121 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 04:49:59,121 cfg.data.level                     : bpe
2020-08-11 04:49:59,121 cfg.data.lowercase                 : False
2020-08-11 04:49:59,121 cfg.data.max_sent_length           : 100
2020-08-11 04:49:59,121 cfg.data.src                       : en
2020-08-11 04:49:59,122 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 04:49:59,122 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 04:49:59,122 cfg.data.trg                       : de
2020-08-11 04:49:59,122 cfg.model.bias_initializer         : zeros
2020-08-11 04:49:59,122 cfg.model.decoder.dropout          : 0.1
2020-08-11 04:49:59,122 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 04:49:59,122 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 04:49:59,122 cfg.model.decoder.embeddings.scale : True
2020-08-11 04:49:59,122 cfg.model.decoder.ff_size          : 512
2020-08-11 04:49:59,122 cfg.model.decoder.freeze           : False
2020-08-11 04:49:59,122 cfg.model.decoder.hidden_size      : 1024
2020-08-11 04:49:59,122 cfg.model.decoder.num_heads        : 16
2020-08-11 04:49:59,122 cfg.model.decoder.num_layers       : 6
2020-08-11 04:49:59,122 cfg.model.decoder.type             : transformer
2020-08-11 04:49:59,122 cfg.model.embed_init_gain          : 1.0
2020-08-11 04:49:59,122 cfg.model.embed_initializer        : xavier
2020-08-11 04:49:59,122 cfg.model.encoder.dropout          : 0.4
2020-08-11 04:49:59,122 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 04:49:59,122 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 04:49:59,122 cfg.model.encoder.embeddings.scale : True
2020-08-11 04:49:59,122 cfg.model.encoder.ff_size          : 512
2020-08-11 04:49:59,122 cfg.model.encoder.freeze           : False
2020-08-11 04:49:59,123 cfg.model.encoder.hidden_size      : 1024
2020-08-11 04:49:59,123 cfg.model.encoder.multi_encoder    : False
2020-08-11 04:49:59,123 cfg.model.encoder.num_heads        : 16
2020-08-11 04:49:59,123 cfg.model.encoder.num_layers       : 6
2020-08-11 04:49:59,123 cfg.model.encoder.type             : transformer
2020-08-11 04:49:59,123 cfg.model.init_gain                : 1.0
2020-08-11 04:49:59,123 cfg.model.initializer              : xavier
2020-08-11 04:49:59,123 cfg.model.tied_embeddings          : False
2020-08-11 04:49:59,123 cfg.model.tied_softmax             : True
2020-08-11 04:49:59,123 cfg.name                           : transformer
2020-08-11 04:49:59,123 cfg.testing.alpha                  : 1.0
2020-08-11 04:49:59,123 cfg.testing.beam_size              : 5
2020-08-11 04:49:59,123 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 04:49:59,123 cfg.training.batch_multiplier      : 1
2020-08-11 04:49:59,123 cfg.training.batch_size            : 2048
2020-08-11 04:49:59,123 cfg.training.batch_type            : token
2020-08-11 04:49:59,123 cfg.training.decrease_factor       : 0.7
2020-08-11 04:49:59,123 cfg.training.early_stopping_metric : ppl
2020-08-11 04:49:59,123 cfg.training.epochs                : 20
2020-08-11 04:49:59,123 cfg.training.eval_metric           : bleu
2020-08-11 04:49:59,123 cfg.training.keep_last_ckpts       : 3
2020-08-11 04:49:59,123 cfg.training.label_smoothing       : 0.1
2020-08-11 04:49:59,123 cfg.training.learning_rate         : 0.0002
2020-08-11 04:49:59,124 cfg.training.learning_rate_min     : 1e-08
2020-08-11 04:49:59,124 cfg.training.logging_freq          : 100
2020-08-11 04:49:59,124 cfg.training.loss                  : crossentropy
2020-08-11 04:49:59,124 cfg.training.max_output_length     : 100
2020-08-11 04:49:59,124 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.4_1024_1024_2048_8_8
2020-08-11 04:49:59,124 cfg.training.normalization         : tokens
2020-08-11 04:49:59,124 cfg.training.optimizer             : adam
2020-08-11 04:49:59,124 cfg.training.overwrite             : True
2020-08-11 04:49:59,124 cfg.training.patience              : 8
2020-08-11 04:49:59,124 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 04:49:59,124 cfg.training.random_seed           : 42
2020-08-11 04:49:59,124 cfg.training.scheduling            : plateau
2020-08-11 04:49:59,124 cfg.training.shuffle               : True
2020-08-11 04:49:59,124 cfg.training.use_cuda              : True
2020-08-11 04:49:59,124 cfg.training.validation_freq       : 200
2020-08-11 04:49:59,124 cfg.training.weight_decay          : 0.0
2020-08-11 04:49:59,125 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 04:49:59,125 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 04:49:59,125 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 04:49:59,125 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 04:49:59,125 Number of Src words (types): 3468
2020-08-11 04:49:59,126 Number of Trg words (types): 4487
2020-08-11 04:49:59,126 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 04:49:59,130 EPOCH 1
2020-08-11 04:50:10,651 Epoch   1: total training loss 275.10
2020-08-11 04:50:10,651 EPOCH 2
2020-08-11 04:50:21,410 Epoch   2 Step:      100 Batch Loss:     5.910881 Tokens per Sec:     5448, Lr: 0.000200
2020-08-11 04:50:22,335 Epoch   2: total training loss 236.75
2020-08-11 04:50:22,335 EPOCH 3
2020-08-11 04:50:33,915 Epoch   3: total training loss 214.11
2020-08-11 04:50:33,915 EPOCH 4
2020-08-11 04:50:43,857 Epoch   4 Step:      200 Batch Loss:     4.288789 Tokens per Sec:     5615, Lr: 0.000200
2020-08-11 04:51:46,776 Hooray! New best validation result [ppl]!
2020-08-11 04:51:46,776 Saving new checkpoint.
2020-08-11 04:51:51,545 Example #0
2020-08-11 04:51:51,546 	Raw source:     ['hello', '.']
2020-08-11 04:51:51,546 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:51:51,546 	Source:     hello .
2020-08-11 04:51:51,546 	Reference:  hallo ,
2020-08-11 04:51:51,546 	Hypothesis: hallo .
2020-08-11 04:51:51,546 Example #1
2020-08-11 04:51:51,546 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:51:51,546 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:51:51,546 	Source:     hi , how can i help you ?
2020-08-11 04:51:51,546 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:51:51,546 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:51:51,546 Example #2
2020-08-11 04:51:51,546 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:51:51,546 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar']
2020-08-11 04:51:51,546 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:51:51,546 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:51:51,546 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar paar
2020-08-11 04:51:51,547 Example #3
2020-08-11 04:51:51,547 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:51:51,547 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', '?']
2020-08-11 04:51:51,547 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:51:51,547 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:51:51,547 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von ?
2020-08-11 04:51:51,547 Validation result (greedy) at epoch   4, step      200: bleu:   2.48, loss: 23910.4180, ppl:  41.9300, duration: 67.6897s
2020-08-11 04:51:53,157 Epoch   4: total training loss 181.66
2020-08-11 04:51:53,157 EPOCH 5
2020-08-11 04:52:04,664 Epoch   5: total training loss 164.33
2020-08-11 04:52:04,664 EPOCH 6
2020-08-11 04:52:14,025 Epoch   6 Step:      300 Batch Loss:     1.848303 Tokens per Sec:     5614, Lr: 0.000200
2020-08-11 04:52:16,236 Epoch   6: total training loss 137.85
2020-08-11 04:52:16,236 EPOCH 7
2020-08-11 04:52:27,705 Epoch   7: total training loss 128.23
2020-08-11 04:52:27,705 EPOCH 8
2020-08-11 04:52:36,145 Epoch   8 Step:      400 Batch Loss:     2.072894 Tokens per Sec:     5689, Lr: 0.000200
2020-08-11 04:53:39,036 Hooray! New best validation result [ppl]!
2020-08-11 04:53:39,036 Saving new checkpoint.
2020-08-11 04:53:43,677 Example #0
2020-08-11 04:53:43,678 	Raw source:     ['hello', '.']
2020-08-11 04:53:43,678 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:53:43,678 	Source:     hello .
2020-08-11 04:53:43,678 	Reference:  hallo ,
2020-08-11 04:53:43,678 	Hypothesis: hallo .
2020-08-11 04:53:43,678 Example #1
2020-08-11 04:53:43,678 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:53:43,678 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:53:43,678 	Source:     hi , how can i help you ?
2020-08-11 04:53:43,678 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:53:43,678 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:53:43,678 Example #2
2020-08-11 04:53:43,678 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:53:43,678 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:53:43,679 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:53:43,679 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:53:43,679 	Hypothesis: hallo , ich bin in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 04:53:43,679 Example #3
2020-08-11 04:53:43,679 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:53:43,679 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'essen', '?']
2020-08-11 04:53:43,679 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:53:43,679 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:53:43,679 	Hypothesis: ok , welche art von essen ?
2020-08-11 04:53:43,679 Validation result (greedy) at epoch   8, step      400: bleu:   8.16, loss: 18438.3867, ppl:  17.8321, duration: 67.5342s
2020-08-11 04:53:46,657 Epoch   8: total training loss 108.66
2020-08-11 04:53:46,658 EPOCH 9
2020-08-11 04:53:58,133 Epoch   9: total training loss 98.03
2020-08-11 04:53:58,133 EPOCH 10
2020-08-11 04:54:05,866 Epoch  10 Step:      500 Batch Loss:     2.130236 Tokens per Sec:     5680, Lr: 0.000200
2020-08-11 04:54:09,661 Epoch  10: total training loss 96.18
2020-08-11 04:54:09,661 EPOCH 11
2020-08-11 04:54:21,229 Epoch  11: total training loss 83.44
2020-08-11 04:54:21,230 EPOCH 12
2020-08-11 04:54:27,871 Epoch  12 Step:      600 Batch Loss:     1.457490 Tokens per Sec:     5589, Lr: 0.000200
2020-08-11 04:55:30,764 Hooray! New best validation result [ppl]!
2020-08-11 04:55:30,764 Saving new checkpoint.
2020-08-11 04:55:35,578 Example #0
2020-08-11 04:55:35,579 	Raw source:     ['hello', '.']
2020-08-11 04:55:35,579 	Raw hypothesis: ['hallo', '.']
2020-08-11 04:55:35,579 	Source:     hello .
2020-08-11 04:55:35,579 	Reference:  hallo ,
2020-08-11 04:55:35,579 	Hypothesis: hallo .
2020-08-11 04:55:35,579 Example #1
2020-08-11 04:55:35,579 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:55:35,579 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:55:35,579 	Source:     hi , how can i help you ?
2020-08-11 04:55:35,579 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:55:35,579 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:55:35,579 Example #2
2020-08-11 04:55:35,579 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:55:35,579 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:55:35,579 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:55:35,579 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:55:35,579 	Hypothesis: hallo , ich suche in san francisco , kalifornien , kalifornien , in san francisco , kalifornien , kalifornien , kalifornien .
2020-08-11 04:55:35,579 Example #3
2020-08-11 04:55:35,579 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:55:35,580 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:55:35,580 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:55:35,580 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:55:35,580 	Hypothesis: ok , welche art von restaurant suchen sie ?
2020-08-11 04:55:35,580 Validation result (greedy) at epoch  12, step      600: bleu:  12.52, loss: 17377.8691, ppl:  15.1090, duration: 67.7080s
2020-08-11 04:55:40,646 Epoch  12: total training loss 73.87
2020-08-11 04:55:40,647 EPOCH 13
2020-08-11 04:55:52,151 Epoch  13: total training loss 61.19
2020-08-11 04:55:52,151 EPOCH 14
2020-08-11 04:55:58,228 Epoch  14 Step:      700 Batch Loss:     1.154684 Tokens per Sec:     5546, Lr: 0.000200
2020-08-11 04:56:03,703 Epoch  14: total training loss 54.29
2020-08-11 04:56:03,703 EPOCH 15
2020-08-11 04:56:15,314 Epoch  15: total training loss 47.85
2020-08-11 04:56:15,314 EPOCH 16
2020-08-11 04:56:20,396 Epoch  16 Step:      800 Batch Loss:     0.737235 Tokens per Sec:     5635, Lr: 0.000200
2020-08-11 04:57:23,309 Hooray! New best validation result [ppl]!
2020-08-11 04:57:23,309 Saving new checkpoint.
2020-08-11 04:57:28,207 Example #0
2020-08-11 04:57:28,207 	Raw source:     ['hello', '.']
2020-08-11 04:57:28,207 	Raw hypothesis: ['hallo']
2020-08-11 04:57:28,207 	Source:     hello .
2020-08-11 04:57:28,207 	Reference:  hallo ,
2020-08-11 04:57:28,208 	Hypothesis: hallo
2020-08-11 04:57:28,208 Example #1
2020-08-11 04:57:28,208 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:57:28,208 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:57:28,208 	Source:     hi , how can i help you ?
2020-08-11 04:57:28,208 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:57:28,208 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:57:28,208 Example #2
2020-08-11 04:57:28,208 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:57:28,208 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 04:57:28,208 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:57:28,208 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:57:28,208 	Hypothesis: hallo , ich suche in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , kalifornien .
2020-08-11 04:57:28,208 Example #3
2020-08-11 04:57:28,208 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:57:28,208 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:57:28,208 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:57:28,208 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:57:28,208 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:57:28,208 Validation result (greedy) at epoch  16, step      800: bleu:  15.07, loss: 16573.4922, ppl:  13.3245, duration: 67.8121s
2020-08-11 04:57:34,616 Epoch  16: total training loss 41.49
2020-08-11 04:57:34,617 EPOCH 17
2020-08-11 04:57:46,196 Epoch  17: total training loss 36.75
2020-08-11 04:57:46,197 EPOCH 18
2020-08-11 04:57:50,473 Epoch  18 Step:      900 Batch Loss:     0.472494 Tokens per Sec:     5467, Lr: 0.000200
2020-08-11 04:57:57,908 Epoch  18: total training loss 33.95
2020-08-11 04:57:57,908 EPOCH 19
2020-08-11 04:58:09,455 Epoch  19: total training loss 30.30
2020-08-11 04:58:09,455 EPOCH 20
2020-08-11 04:58:12,671 Epoch  20 Step:     1000 Batch Loss:     0.194336 Tokens per Sec:     5583, Lr: 0.000200
2020-08-11 04:58:57,417 Hooray! New best validation result [ppl]!
2020-08-11 04:58:57,417 Saving new checkpoint.
2020-08-11 04:59:02,336 Example #0
2020-08-11 04:59:02,336 	Raw source:     ['hello', '.']
2020-08-11 04:59:02,336 	Raw hypothesis: ['hallo']
2020-08-11 04:59:02,336 	Source:     hello .
2020-08-11 04:59:02,336 	Reference:  hallo ,
2020-08-11 04:59:02,336 	Hypothesis: hallo
2020-08-11 04:59:02,336 Example #1
2020-08-11 04:59:02,337 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 04:59:02,337 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 04:59:02,337 	Source:     hi , how can i help you ?
2020-08-11 04:59:02,337 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 04:59:02,337 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 04:59:02,337 Example #2
2020-08-11 04:59:02,337 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 04:59:02,337 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-11 04:59:02,337 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 04:59:02,337 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 04:59:02,337 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien .
2020-08-11 04:59:02,337 Example #3
2020-08-11 04:59:02,337 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 04:59:02,337 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 04:59:02,337 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 04:59:02,337 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 04:59:02,337 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 04:59:02,337 Validation result (greedy) at epoch  20, step     1000: bleu:  25.19, loss: 16482.9160, ppl:  13.1373, duration: 49.6661s
2020-08-11 04:59:10,825 Epoch  20: total training loss 26.87
2020-08-11 04:59:10,826 Training ended after  20 epochs.
2020-08-11 04:59:10,826 Best validation result (greedy) at step     1000:  13.14 ppl.

2020-08-11 02:06:52,677 Hello! This is Joey-NMT.
2020-08-11 02:06:53,989 Total params: 96384000
2020-08-11 02:06:53,990 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-11 02:06:57,808 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-11 02:06:57,808 cfg.data.level                     : bpe
2020-08-11 02:06:57,809 cfg.data.lowercase                 : False
2020-08-11 02:06:57,809 cfg.data.max_sent_length           : 100
2020-08-11 02:06:57,809 cfg.data.src                       : en
2020-08-11 02:06:57,809 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-11 02:06:57,809 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-11 02:06:57,809 cfg.data.trg                       : de
2020-08-11 02:06:57,809 cfg.model.bias_initializer         : zeros
2020-08-11 02:06:57,809 cfg.model.decoder.dropout          : 0.1
2020-08-11 02:06:57,809 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-11 02:06:57,809 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-11 02:06:57,809 cfg.model.decoder.embeddings.scale : True
2020-08-11 02:06:57,809 cfg.model.decoder.ff_size          : 512
2020-08-11 02:06:57,809 cfg.model.decoder.freeze           : False
2020-08-11 02:06:57,809 cfg.model.decoder.hidden_size      : 1024
2020-08-11 02:06:57,809 cfg.model.decoder.num_heads        : 16
2020-08-11 02:06:57,809 cfg.model.decoder.num_layers       : 6
2020-08-11 02:06:57,810 cfg.model.decoder.type             : transformer
2020-08-11 02:06:57,810 cfg.model.embed_init_gain          : 1.0
2020-08-11 02:06:57,810 cfg.model.embed_initializer        : xavier
2020-08-11 02:06:57,810 cfg.model.encoder.dropout          : 0.1
2020-08-11 02:06:57,810 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-11 02:06:57,810 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-11 02:06:57,810 cfg.model.encoder.embeddings.scale : True
2020-08-11 02:06:57,810 cfg.model.encoder.ff_size          : 512
2020-08-11 02:06:57,810 cfg.model.encoder.freeze           : False
2020-08-11 02:06:57,810 cfg.model.encoder.hidden_size      : 1024
2020-08-11 02:06:57,810 cfg.model.encoder.multi_encoder    : False
2020-08-11 02:06:57,810 cfg.model.encoder.num_heads        : 16
2020-08-11 02:06:57,810 cfg.model.encoder.num_layers       : 6
2020-08-11 02:06:57,810 cfg.model.encoder.type             : transformer
2020-08-11 02:06:57,810 cfg.model.init_gain                : 1.0
2020-08-11 02:06:57,810 cfg.model.initializer              : xavier
2020-08-11 02:06:57,810 cfg.model.tied_embeddings          : False
2020-08-11 02:06:57,810 cfg.model.tied_softmax             : True
2020-08-11 02:06:57,811 cfg.name                           : transformer
2020-08-11 02:06:57,811 cfg.testing.alpha                  : 1.0
2020-08-11 02:06:57,811 cfg.testing.beam_size              : 5
2020-08-11 02:06:57,811 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-11 02:06:57,811 cfg.training.batch_multiplier      : 1
2020-08-11 02:06:57,811 cfg.training.batch_size            : 2048
2020-08-11 02:06:57,811 cfg.training.batch_type            : token
2020-08-11 02:06:57,811 cfg.training.decrease_factor       : 0.7
2020-08-11 02:06:57,811 cfg.training.early_stopping_metric : ppl
2020-08-11 02:06:57,811 cfg.training.epochs                : 20
2020-08-11 02:06:57,811 cfg.training.eval_metric           : bleu
2020-08-11 02:06:57,811 cfg.training.keep_last_ckpts       : 3
2020-08-11 02:06:57,811 cfg.training.label_smoothing       : 0.1
2020-08-11 02:06:57,811 cfg.training.learning_rate         : 0.0002
2020-08-11 02:06:57,811 cfg.training.learning_rate_min     : 1e-08
2020-08-11 02:06:57,811 cfg.training.logging_freq          : 100
2020-08-11 02:06:57,811 cfg.training.loss                  : crossentropy
2020-08-11 02:06:57,811 cfg.training.max_output_length     : 100
2020-08-11 02:06:57,812 cfg.training.model_dir             : models/viznet/attempt4/16_16_0.1_1024_1024_2048_8_6
2020-08-11 02:06:57,812 cfg.training.normalization         : tokens
2020-08-11 02:06:57,812 cfg.training.optimizer             : adam
2020-08-11 02:06:57,812 cfg.training.overwrite             : True
2020-08-11 02:06:57,812 cfg.training.patience              : 8
2020-08-11 02:06:57,812 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-11 02:06:57,812 cfg.training.random_seed           : 42
2020-08-11 02:06:57,812 cfg.training.scheduling            : plateau
2020-08-11 02:06:57,812 cfg.training.shuffle               : True
2020-08-11 02:06:57,812 cfg.training.use_cuda              : True
2020-08-11 02:06:57,812 cfg.training.validation_freq       : 200
2020-08-11 02:06:57,812 cfg.training.weight_decay          : 0.0
2020-08-11 02:06:57,812 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-11 02:06:57,812 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-11 02:06:57,812 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-11 02:06:57,813 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-11 02:06:57,813 Number of Src words (types): 3468
2020-08-11 02:06:57,813 Number of Trg words (types): 4487
2020-08-11 02:06:57,813 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-11 02:06:57,818 EPOCH 1
2020-08-11 02:07:09,447 Epoch   1: total training loss 276.34
2020-08-11 02:07:09,447 EPOCH 2
2020-08-11 02:07:20,189 Epoch   2 Step:      100 Batch Loss:     5.815919 Tokens per Sec:     5456, Lr: 0.000200
2020-08-11 02:07:21,119 Epoch   2: total training loss 239.10
2020-08-11 02:07:21,119 EPOCH 3
2020-08-11 02:07:32,632 Epoch   3: total training loss 217.87
2020-08-11 02:07:32,632 EPOCH 4
2020-08-11 02:07:42,628 Epoch   4 Step:      200 Batch Loss:     4.461979 Tokens per Sec:     5585, Lr: 0.000200
2020-08-11 02:08:45,384 Hooray! New best validation result [ppl]!
2020-08-11 02:08:45,384 Saving new checkpoint.
2020-08-11 02:08:49,922 Example #0
2020-08-11 02:08:49,923 	Raw source:     ['hello', '.']
2020-08-11 02:08:49,923 	Raw hypothesis: ['hallo', '.']
2020-08-11 02:08:49,923 	Source:     hello .
2020-08-11 02:08:49,923 	Reference:  hallo ,
2020-08-11 02:08:49,923 	Hypothesis: hallo .
2020-08-11 02:08:49,923 Example #1
2020-08-11 02:08:49,923 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 02:08:49,923 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 02:08:49,923 	Source:     hi , how can i help you ?
2020-08-11 02:08:49,923 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 02:08:49,923 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 02:08:49,923 Example #2
2020-08-11 02:08:49,923 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 02:08:49,923 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'bestellung', 'mit', 'der', 'bestellung', 'bestellung', 'bestellung', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'der', 'mit', 'mit', 'der', 'mit', 'der', 'mit', 'mit', 'mit']
2020-08-11 02:08:49,923 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 02:08:49,923 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 02:08:49,923 	Hypothesis: hallo , ich möchte ein bestellung mit der bestellung bestellung bestellung mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der mit der mit der mit der mit der mit der mit der mit der mit der mit der mit der mit mit der mit der mit mit mit
2020-08-11 02:08:49,923 Example #3
2020-08-11 02:08:49,923 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 02:08:49,923 	Raw hypothesis: ['okay', ',', 'wie', 'viele', 'viele', 'viele', 'viele', 'viele', '?']
2020-08-11 02:08:49,924 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 02:08:49,924 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 02:08:49,924 	Hypothesis: okay , wie viele viele viele viele viele ?
2020-08-11 02:08:49,924 Validation result (greedy) at epoch   4, step      200: bleu:   2.91, loss: 24505.9102, ppl:  46.0187, duration: 67.2955s
2020-08-11 02:08:51,557 Epoch   4: total training loss 189.62
2020-08-11 02:08:51,558 EPOCH 5
2020-08-11 02:09:03,171 Epoch   5: total training loss 171.49
2020-08-11 02:09:03,172 EPOCH 6
2020-08-11 02:09:12,584 Epoch   6 Step:      300 Batch Loss:     1.898170 Tokens per Sec:     5582, Lr: 0.000200
2020-08-11 02:09:14,853 Epoch   6: total training loss 143.06
2020-08-11 02:09:14,853 EPOCH 7
2020-08-11 02:09:26,477 Epoch   7: total training loss 128.77
2020-08-11 02:09:26,477 EPOCH 8
2020-08-11 02:09:35,069 Epoch   8 Step:      400 Batch Loss:     1.986258 Tokens per Sec:     5588, Lr: 0.000200
2020-08-11 02:10:17,466 Hooray! New best validation result [ppl]!
2020-08-11 02:10:17,466 Saving new checkpoint.
2020-08-11 02:10:22,012 Example #0
2020-08-11 02:10:22,012 	Raw source:     ['hello', '.']
2020-08-11 02:10:22,012 	Raw hypothesis: ['hallo', ',', 'removemeimaboundary']
2020-08-11 02:10:22,012 	Source:     hello .
2020-08-11 02:10:22,012 	Reference:  hallo ,
2020-08-11 02:10:22,012 	Hypothesis: hallo , removemeimaboundary
2020-08-11 02:10:22,013 Example #1
2020-08-11 02:10:22,013 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 02:10:22,013 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 02:10:22,013 	Source:     hi , how can i help you ?
2020-08-11 02:10:22,013 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 02:10:22,013 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 02:10:22,013 Example #2
2020-08-11 02:10:22,013 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 02:10:22,013 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', '.']
2020-08-11 02:10:22,013 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 02:10:22,013 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 02:10:22,013 	Hypothesis: hallo , ich bin in sacramento , kalifornien .
2020-08-11 02:10:22,013 Example #3
2020-08-11 02:10:22,013 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 02:10:22,013 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'haben', 'sie', '?']
2020-08-11 02:10:22,013 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 02:10:22,013 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 02:10:22,013 	Hypothesis: ok , welche art von restaurant haben sie ?
2020-08-11 02:10:22,014 Validation result (greedy) at epoch   8, step      400: bleu:  21.31, loss: 17587.4707, ppl:  15.6120, duration: 46.9441s
2020-08-11 02:10:24,992 Epoch   8: total training loss 107.33
2020-08-11 02:10:24,993 EPOCH 9
2020-08-11 02:10:36,531 Epoch   9: total training loss 93.83
2020-08-11 02:10:36,531 EPOCH 10
2020-08-11 02:10:44,309 Epoch  10 Step:      500 Batch Loss:     1.905013 Tokens per Sec:     5647, Lr: 0.000200
2020-08-11 02:10:48,119 Epoch  10: total training loss 85.23
2020-08-11 02:10:48,119 EPOCH 11
2020-08-11 02:10:59,725 Epoch  11: total training loss 73.66
2020-08-11 02:10:59,726 EPOCH 12
2020-08-11 02:11:06,451 Epoch  12 Step:      600 Batch Loss:     1.203083 Tokens per Sec:     5520, Lr: 0.000200
2020-08-11 02:11:42,841 Hooray! New best validation result [ppl]!
2020-08-11 02:11:42,841 Saving new checkpoint.
2020-08-11 02:11:47,320 Example #0
2020-08-11 02:11:47,320 	Raw source:     ['hello', '.']
2020-08-11 02:11:47,320 	Raw hypothesis: ['hallo', '.']
2020-08-11 02:11:47,320 	Source:     hello .
2020-08-11 02:11:47,320 	Reference:  hallo ,
2020-08-11 02:11:47,320 	Hypothesis: hallo .
2020-08-11 02:11:47,320 Example #1
2020-08-11 02:11:47,320 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 02:11:47,320 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 02:11:47,320 	Source:     hi , how can i help you ?
2020-08-11 02:11:47,321 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 02:11:47,321 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 02:11:47,321 Example #2
2020-08-11 02:11:47,321 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 02:11:47,321 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-11 02:11:47,321 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 02:11:47,321 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 02:11:47,321 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-11 02:11:47,321 Example #3
2020-08-11 02:11:47,321 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 02:11:47,321 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 02:11:47,321 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 02:11:47,321 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 02:11:47,321 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 02:11:47,321 Validation result (greedy) at epoch  12, step      600: bleu:  28.96, loss: 15934.0957, ppl:  12.0577, duration: 40.8700s
2020-08-11 02:11:52,358 Epoch  12: total training loss 62.77
2020-08-11 02:11:52,358 EPOCH 13
2020-08-11 02:12:03,900 Epoch  13: total training loss 50.92
2020-08-11 02:12:03,900 EPOCH 14
2020-08-11 02:12:10,095 Epoch  14 Step:      700 Batch Loss:     0.920144 Tokens per Sec:     5440, Lr: 0.000200
2020-08-11 02:12:15,602 Epoch  14: total training loss 43.54
2020-08-11 02:12:15,603 EPOCH 15
2020-08-11 02:12:27,161 Epoch  15: total training loss 37.76
2020-08-11 02:12:27,161 EPOCH 16
2020-08-11 02:12:32,287 Epoch  16 Step:      800 Batch Loss:     0.506182 Tokens per Sec:     5588, Lr: 0.000200
2020-08-11 02:12:54,484 Hooray! New best validation result [ppl]!
2020-08-11 02:12:54,484 Saving new checkpoint.
2020-08-11 02:12:59,114 Example #0
2020-08-11 02:12:59,114 	Raw source:     ['hello', '.']
2020-08-11 02:12:59,114 	Raw hypothesis: ['hallo', ',']
2020-08-11 02:12:59,114 	Source:     hello .
2020-08-11 02:12:59,114 	Reference:  hallo ,
2020-08-11 02:12:59,114 	Hypothesis: hallo ,
2020-08-11 02:12:59,114 Example #1
2020-08-11 02:12:59,114 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 02:12:59,114 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 02:12:59,114 	Source:     hi , how can i help you ?
2020-08-11 02:12:59,114 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 02:12:59,114 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 02:12:59,115 Example #2
2020-08-11 02:12:59,115 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 02:12:59,115 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-11 02:12:59,115 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 02:12:59,115 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 02:12:59,115 	Hypothesis: hallo , ich suche ein restaurant in der arden fair mall .
2020-08-11 02:12:59,115 Example #3
2020-08-11 02:12:59,115 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 02:12:59,115 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 02:12:59,115 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 02:12:59,115 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 02:12:59,115 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 02:12:59,115 Validation result (greedy) at epoch  16, step      800: bleu:  30.42, loss: 15356.3281, ppl:  11.0169, duration: 26.8283s
2020-08-11 02:13:05,538 Epoch  16: total training loss 31.53
2020-08-11 02:13:05,538 EPOCH 17
2020-08-11 02:13:17,159 Epoch  17: total training loss 26.54
2020-08-11 02:13:17,160 EPOCH 18
2020-08-11 02:13:21,462 Epoch  18 Step:      900 Batch Loss:     0.313782 Tokens per Sec:     5434, Lr: 0.000200
2020-08-11 02:13:29,012 Epoch  18: total training loss 24.12
2020-08-11 02:13:29,012 EPOCH 19
2020-08-11 02:13:40,590 Epoch  19: total training loss 22.05
2020-08-11 02:13:40,591 EPOCH 20
2020-08-11 02:13:43,774 Epoch  20 Step:     1000 Batch Loss:     0.128697 Tokens per Sec:     5640, Lr: 0.000200
2020-08-11 02:13:56,413 Example #0
2020-08-11 02:13:56,413 	Raw source:     ['hello', '.']
2020-08-11 02:13:56,413 	Raw hypothesis: ['hallo', '.']
2020-08-11 02:13:56,413 	Source:     hello .
2020-08-11 02:13:56,413 	Reference:  hallo ,
2020-08-11 02:13:56,413 	Hypothesis: hallo .
2020-08-11 02:13:56,413 Example #1
2020-08-11 02:13:56,413 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-11 02:13:56,414 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-11 02:13:56,414 	Source:     hi , how can i help you ?
2020-08-11 02:13:56,414 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-11 02:13:56,414 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-11 02:13:56,414 Example #2
2020-08-11 02:13:56,414 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-11 02:13:56,414 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-11 02:13:56,414 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-11 02:13:56,414 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-11 02:13:56,414 	Hypothesis: hallo , ich suche ein restaurant in der arden fair mall .
2020-08-11 02:13:56,414 Example #3
2020-08-11 02:13:56,414 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-11 02:13:56,414 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-11 02:13:56,414 	Source:     ok , what type of restaurant are you looking for ?
2020-08-11 02:13:56,414 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-11 02:13:56,414 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-11 02:13:56,414 Validation result (greedy) at epoch  20, step     1000: bleu:  34.97, loss: 15586.1045, ppl:  11.4196, duration: 12.6398s
2020-08-11 02:14:04,987 Epoch  20: total training loss 20.37
2020-08-11 02:14:04,988 Training ended after  20 epochs.
2020-08-11 02:14:04,988 Best validation result (greedy) at step      800:  11.02 ppl.

2020-08-18 17:18:49,242 Hello! This is Joey-NMT.
2020-08-18 17:18:50,598 Total params: 96384000
2020-08-18 17:18:50,600 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 17:18:54,518 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 17:18:54,518 cfg.data.level                     : bpe
2020-08-18 17:18:54,518 cfg.data.lowercase                 : False
2020-08-18 17:18:54,518 cfg.data.max_sent_length           : 100
2020-08-18 17:18:54,518 cfg.data.src                       : en
2020-08-18 17:18:54,519 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 17:18:54,519 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 17:18:54,519 cfg.data.trg                       : de
2020-08-18 17:18:54,519 cfg.model.bias_initializer         : zeros
2020-08-18 17:18:54,519 cfg.model.decoder.dropout          : 0.1
2020-08-18 17:18:54,519 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 17:18:54,519 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-18 17:18:54,519 cfg.model.decoder.embeddings.scale : True
2020-08-18 17:18:54,519 cfg.model.decoder.ff_size          : 512
2020-08-18 17:18:54,519 cfg.model.decoder.freeze           : False
2020-08-18 17:18:54,519 cfg.model.decoder.hidden_size      : 1024
2020-08-18 17:18:54,519 cfg.model.decoder.num_heads        : 16
2020-08-18 17:18:54,519 cfg.model.decoder.num_layers       : 6
2020-08-18 17:18:54,519 cfg.model.decoder.type             : transformer
2020-08-18 17:18:54,519 cfg.model.embed_init_gain          : 1.0
2020-08-18 17:18:54,519 cfg.model.embed_initializer        : xavier
2020-08-18 17:18:54,519 cfg.model.encoder.dropout          : 0.3
2020-08-18 17:18:54,520 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 17:18:54,520 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-18 17:18:54,520 cfg.model.encoder.embeddings.scale : True
2020-08-18 17:18:54,520 cfg.model.encoder.ff_size          : 512
2020-08-18 17:18:54,520 cfg.model.encoder.freeze           : False
2020-08-18 17:18:54,520 cfg.model.encoder.hidden_size      : 1024
2020-08-18 17:18:54,520 cfg.model.encoder.multi_encoder    : False
2020-08-18 17:18:54,520 cfg.model.encoder.num_heads        : 16
2020-08-18 17:18:54,520 cfg.model.encoder.num_layers       : 6
2020-08-18 17:18:54,520 cfg.model.encoder.type             : transformer
2020-08-18 17:18:54,520 cfg.model.init_gain                : 1.0
2020-08-18 17:18:54,520 cfg.model.initializer              : xavier
2020-08-18 17:18:54,520 cfg.model.tied_embeddings          : False
2020-08-18 17:18:54,520 cfg.model.tied_softmax             : True
2020-08-18 17:18:54,520 cfg.name                           : transformer
2020-08-18 17:18:54,520 cfg.testing.alpha                  : 1.0
2020-08-18 17:18:54,520 cfg.testing.beam_size              : 5
2020-08-18 17:18:54,521 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 17:18:54,521 cfg.training.batch_multiplier      : 1
2020-08-18 17:18:54,521 cfg.training.batch_size            : 2048
2020-08-18 17:18:54,521 cfg.training.batch_type            : token
2020-08-18 17:18:54,521 cfg.training.decrease_factor       : 0.7
2020-08-18 17:18:54,521 cfg.training.early_stopping_metric : ppl
2020-08-18 17:18:54,521 cfg.training.epochs                : 20
2020-08-18 17:18:54,521 cfg.training.eval_metric           : bleu
2020-08-18 17:18:54,521 cfg.training.keep_last_ckpts       : 3
2020-08-18 17:18:54,521 cfg.training.label_smoothing       : 0.1
2020-08-18 17:18:54,521 cfg.training.learning_rate         : 0.0002
2020-08-18 17:18:54,521 cfg.training.learning_rate_min     : 1e-08
2020-08-18 17:18:54,521 cfg.training.logging_freq          : 100
2020-08-18 17:18:54,521 cfg.training.loss                  : crossentropy
2020-08-18 17:18:54,521 cfg.training.max_output_length     : 100
2020-08-18 17:18:54,521 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_1024_1024_2048_8_10
2020-08-18 17:18:54,521 cfg.training.normalization         : tokens
2020-08-18 17:18:54,521 cfg.training.optimizer             : adam
2020-08-18 17:18:54,521 cfg.training.overwrite             : True
2020-08-18 17:18:54,522 cfg.training.patience              : 8
2020-08-18 17:18:54,522 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 17:18:54,522 cfg.training.random_seed           : 42
2020-08-18 17:18:54,522 cfg.training.scheduling            : plateau
2020-08-18 17:18:54,522 cfg.training.shuffle               : True
2020-08-18 17:18:54,522 cfg.training.use_cuda              : True
2020-08-18 17:18:54,522 cfg.training.validation_freq       : 200
2020-08-18 17:18:54,522 cfg.training.weight_decay          : 0.0
2020-08-18 17:18:54,522 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 17:18:54,522 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 17:18:54,522 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 17:18:54,523 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 17:18:54,523 Number of Src words (types): 3468
2020-08-18 17:18:54,523 Number of Trg words (types): 4487
2020-08-18 17:18:54,523 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-18 17:18:54,527 EPOCH 1
2020-08-18 17:19:06,122 Epoch   1: total training loss 275.72
2020-08-18 17:19:06,122 EPOCH 2
2020-08-18 17:19:16,864 Epoch   2 Step:      100 Batch Loss:     5.843812 Tokens per Sec:     5456, Lr: 0.000200
2020-08-18 17:19:17,806 Epoch   2: total training loss 238.18
2020-08-18 17:19:17,806 EPOCH 3
2020-08-18 17:19:29,381 Epoch   3: total training loss 215.45
2020-08-18 17:19:29,381 EPOCH 4
2020-08-18 17:19:39,357 Epoch   4 Step:      200 Batch Loss:     4.359450 Tokens per Sec:     5596, Lr: 0.000200
2020-08-18 17:20:42,377 Hooray! New best validation result [ppl]!
2020-08-18 17:20:42,377 Saving new checkpoint.
2020-08-18 17:20:47,152 Example #0
2020-08-18 17:20:47,153 	Raw source:     ['hello', '.']
2020-08-18 17:20:47,153 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:20:47,153 	Source:     hello .
2020-08-18 17:20:47,153 	Reference:  hallo ,
2020-08-18 17:20:47,153 	Hypothesis: hallo .
2020-08-18 17:20:47,153 Example #1
2020-08-18 17:20:47,153 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:20:47,153 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:20:47,153 	Source:     hi , how can i help you ?
2020-08-18 17:20:47,153 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:20:47,153 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:20:47,153 Example #2
2020-08-18 17:20:47,153 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:20:47,153 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2020-08-18 17:20:47,153 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:20:47,153 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:20:47,153 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der der der der der der der der der der der der der der der der der der
2020-08-18 17:20:47,153 Example #3
2020-08-18 17:20:47,153 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:20:47,153 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von']
2020-08-18 17:20:47,153 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:20:47,153 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:20:47,153 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von
2020-08-18 17:20:47,153 Validation result (greedy) at epoch   4, step      200: bleu:   1.76, loss: 24026.3262, ppl:  42.6964, duration: 67.7959s
2020-08-18 17:20:48,756 Epoch   4: total training loss 184.13
2020-08-18 17:20:48,756 EPOCH 5
2020-08-18 17:21:00,306 Epoch   5: total training loss 166.88
2020-08-18 17:21:00,306 EPOCH 6
2020-08-18 17:21:09,719 Epoch   6 Step:      300 Batch Loss:     1.843859 Tokens per Sec:     5583, Lr: 0.000200
2020-08-18 17:21:11,956 Epoch   6: total training loss 138.81
2020-08-18 17:21:11,957 EPOCH 7
2020-08-18 17:21:23,542 Epoch   7: total training loss 127.27
2020-08-18 17:21:23,543 EPOCH 8
2020-08-18 17:21:32,066 Epoch   8 Step:      400 Batch Loss:     2.046960 Tokens per Sec:     5633, Lr: 0.000200
2020-08-18 17:22:31,344 Hooray! New best validation result [ppl]!
2020-08-18 17:22:31,345 Saving new checkpoint.
2020-08-18 17:22:36,158 Example #0
2020-08-18 17:22:36,158 	Raw source:     ['hello', '.']
2020-08-18 17:22:36,158 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:22:36,158 	Source:     hello .
2020-08-18 17:22:36,158 	Reference:  hallo ,
2020-08-18 17:22:36,158 	Hypothesis: hallo .
2020-08-18 17:22:36,158 Example #1
2020-08-18 17:22:36,158 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:22:36,158 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:22:36,158 	Source:     hi , how can i help you ?
2020-08-18 17:22:36,158 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:22:36,158 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:22:36,158 Example #2
2020-08-18 17:22:36,159 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:22:36,159 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:22:36,159 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:22:36,159 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:22:36,159 	Hypothesis: hallo , ich bin in sacramento , kalifornien , kalifornien , kalifornien in der arden fair mall .
2020-08-18 17:22:36,159 Example #3
2020-08-18 17:22:36,159 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:22:36,159 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-08-18 17:22:36,159 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:22:36,159 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:22:36,159 	Hypothesis: ok , welche art von restaurant für sie ?
2020-08-18 17:22:36,159 Validation result (greedy) at epoch   8, step      400: bleu:  12.12, loss: 17894.2324, ppl:  16.3786, duration: 64.0932s
2020-08-18 17:22:39,153 Epoch   8: total training loss 107.96
2020-08-18 17:22:39,153 EPOCH 9
2020-08-18 17:22:50,697 Epoch   9: total training loss 96.02
2020-08-18 17:22:50,697 EPOCH 10
2020-08-18 17:22:58,512 Epoch  10 Step:      500 Batch Loss:     2.032404 Tokens per Sec:     5621, Lr: 0.000200
2020-08-18 17:23:02,351 Epoch  10: total training loss 91.57
2020-08-18 17:23:02,351 EPOCH 11
2020-08-18 17:23:13,920 Epoch  11: total training loss 80.18
2020-08-18 17:23:13,920 EPOCH 12
2020-08-18 17:23:20,601 Epoch  12 Step:      600 Batch Loss:     1.372831 Tokens per Sec:     5557, Lr: 0.000200
2020-08-18 17:23:57,860 Hooray! New best validation result [ppl]!
2020-08-18 17:23:57,860 Saving new checkpoint.
2020-08-18 17:24:03,347 Example #0
2020-08-18 17:24:03,347 	Raw source:     ['hello', '.']
2020-08-18 17:24:03,347 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:24:03,347 	Source:     hello .
2020-08-18 17:24:03,347 	Reference:  hallo ,
2020-08-18 17:24:03,347 	Hypothesis: hallo .
2020-08-18 17:24:03,347 Example #1
2020-08-18 17:24:03,347 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:24:03,347 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:24:03,348 	Source:     hi , how can i help you ?
2020-08-18 17:24:03,348 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:24:03,348 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:24:03,348 Example #2
2020-08-18 17:24:03,348 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:24:03,348 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 17:24:03,348 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:24:03,348 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:24:03,348 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien in san francisco , kalifornien in san francisco , kalifornien .
2020-08-18 17:24:03,348 Example #3
2020-08-18 17:24:03,348 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:24:03,348 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:24:03,348 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:24:03,348 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:24:03,348 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:24:03,348 Validation result (greedy) at epoch  12, step      600: bleu:  23.63, loss: 16627.6602, ppl:  13.4378, duration: 42.7472s
2020-08-18 17:24:08,341 Epoch  12: total training loss 69.67
2020-08-18 17:24:08,342 EPOCH 13
2020-08-18 17:24:19,905 Epoch  13: total training loss 58.24
2020-08-18 17:24:19,905 EPOCH 14
2020-08-18 17:24:26,052 Epoch  14 Step:      700 Batch Loss:     1.082558 Tokens per Sec:     5483, Lr: 0.000200
2020-08-18 17:24:31,561 Epoch  14: total training loss 50.53
2020-08-18 17:24:31,562 EPOCH 15
2020-08-18 17:24:43,176 Epoch  15: total training loss 43.78
2020-08-18 17:24:43,176 EPOCH 16
2020-08-18 17:24:48,331 Epoch  16 Step:      800 Batch Loss:     0.655878 Tokens per Sec:     5555, Lr: 0.000200
2020-08-18 17:25:40,549 Hooray! New best validation result [ppl]!
2020-08-18 17:25:40,549 Saving new checkpoint.
2020-08-18 17:25:45,840 Example #0
2020-08-18 17:25:45,840 	Raw source:     ['hello', '.']
2020-08-18 17:25:45,840 	Raw hypothesis: ['hallo']
2020-08-18 17:25:45,840 	Source:     hello .
2020-08-18 17:25:45,840 	Reference:  hallo ,
2020-08-18 17:25:45,840 	Hypothesis: hallo
2020-08-18 17:25:45,840 Example #1
2020-08-18 17:25:45,840 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:25:45,840 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:25:45,840 	Source:     hi , how can i help you ?
2020-08-18 17:25:45,841 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:25:45,841 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:25:45,841 Example #2
2020-08-18 17:25:45,841 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:25:45,841 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:25:45,841 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:25:45,841 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:25:45,841 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:25:45,841 Example #3
2020-08-18 17:25:45,841 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:25:45,841 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:25:45,841 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:25:45,841 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:25:45,841 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:25:45,841 Validation result (greedy) at epoch  16, step      800: bleu:  24.36, loss: 15877.6338, ppl:  11.9518, duration: 57.5099s
2020-08-18 17:25:52,249 Epoch  16: total training loss 38.23
2020-08-18 17:25:52,249 EPOCH 17
2020-08-18 17:26:03,865 Epoch  17: total training loss 33.75
2020-08-18 17:26:03,865 EPOCH 18
2020-08-18 17:26:08,104 Epoch  18 Step:      900 Batch Loss:     0.425437 Tokens per Sec:     5514, Lr: 0.000200
2020-08-18 17:26:15,599 Epoch  18: total training loss 30.37
2020-08-18 17:26:15,599 EPOCH 19
2020-08-18 17:26:27,191 Epoch  19: total training loss 27.66
2020-08-18 17:26:27,191 EPOCH 20
2020-08-18 17:26:30,391 Epoch  20 Step:     1000 Batch Loss:     0.161490 Tokens per Sec:     5610, Lr: 0.000200
2020-08-18 17:26:47,812 Example #0
2020-08-18 17:26:47,812 	Raw source:     ['hello', '.']
2020-08-18 17:26:47,812 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:26:47,812 	Source:     hello .
2020-08-18 17:26:47,812 	Reference:  hallo ,
2020-08-18 17:26:47,812 	Hypothesis: hallo .
2020-08-18 17:26:47,812 Example #1
2020-08-18 17:26:47,812 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:26:47,812 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:26:47,812 	Source:     hi , how can i help you ?
2020-08-18 17:26:47,812 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:26:47,812 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:26:47,812 Example #2
2020-08-18 17:26:47,812 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:26:47,812 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:26:47,812 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:26:47,812 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:26:47,812 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:26:47,812 Example #3
2020-08-18 17:26:47,812 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:26:47,812 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:26:47,813 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:26:47,813 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:26:47,813 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:26:47,813 Validation result (greedy) at epoch  20, step     1000: bleu:  31.74, loss: 15943.3701, ppl:  12.0752, duration: 17.4212s
2020-08-18 17:26:56,378 Epoch  20: total training loss 25.11
2020-08-18 17:26:56,378 Training ended after  20 epochs.
2020-08-18 17:26:56,379 Best validation result (greedy) at step      800:  11.95 ppl.

2020-08-18 19:30:56,518 Hello! This is Joey-NMT.
2020-08-18 19:30:58,826 Total params: 343756800
2020-08-18 19:30:58,828 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 19:31:03,184 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 19:31:03,184 cfg.data.level                     : bpe
2020-08-18 19:31:03,184 cfg.data.lowercase                 : False
2020-08-18 19:31:03,185 cfg.data.max_sent_length           : 100
2020-08-18 19:31:03,185 cfg.data.src                       : en
2020-08-18 19:31:03,185 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 19:31:03,185 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 19:31:03,185 cfg.data.trg                       : de
2020-08-18 19:31:03,185 cfg.model.bias_initializer         : zeros
2020-08-18 19:31:03,185 cfg.model.decoder.dropout          : 0.1
2020-08-18 19:31:03,185 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 19:31:03,185 cfg.model.decoder.embeddings.embedding_dim : 2048
2020-08-18 19:31:03,185 cfg.model.decoder.embeddings.scale : True
2020-08-18 19:31:03,185 cfg.model.decoder.ff_size          : 512
2020-08-18 19:31:03,185 cfg.model.decoder.freeze           : False
2020-08-18 19:31:03,185 cfg.model.decoder.hidden_size      : 2048
2020-08-18 19:31:03,185 cfg.model.decoder.num_heads        : 16
2020-08-18 19:31:03,185 cfg.model.decoder.num_layers       : 6
2020-08-18 19:31:03,185 cfg.model.decoder.type             : transformer
2020-08-18 19:31:03,185 cfg.model.embed_init_gain          : 1.0
2020-08-18 19:31:03,185 cfg.model.embed_initializer        : xavier
2020-08-18 19:31:03,185 cfg.model.encoder.dropout          : 0.3
2020-08-18 19:31:03,185 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 19:31:03,185 cfg.model.encoder.embeddings.embedding_dim : 2048
2020-08-18 19:31:03,185 cfg.model.encoder.embeddings.scale : True
2020-08-18 19:31:03,185 cfg.model.encoder.ff_size          : 512
2020-08-18 19:31:03,185 cfg.model.encoder.freeze           : False
2020-08-18 19:31:03,185 cfg.model.encoder.hidden_size      : 2048
2020-08-18 19:31:03,185 cfg.model.encoder.multi_encoder    : False
2020-08-18 19:31:03,186 cfg.model.encoder.num_heads        : 16
2020-08-18 19:31:03,186 cfg.model.encoder.num_layers       : 6
2020-08-18 19:31:03,186 cfg.model.encoder.type             : transformer
2020-08-18 19:31:03,186 cfg.model.init_gain                : 1.0
2020-08-18 19:31:03,186 cfg.model.initializer              : xavier
2020-08-18 19:31:03,186 cfg.model.tied_embeddings          : False
2020-08-18 19:31:03,186 cfg.model.tied_softmax             : True
2020-08-18 19:31:03,186 cfg.name                           : transformer
2020-08-18 19:31:03,186 cfg.testing.alpha                  : 1.0
2020-08-18 19:31:03,186 cfg.testing.beam_size              : 5
2020-08-18 19:31:03,186 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 19:31:03,186 cfg.training.batch_multiplier      : 1
2020-08-18 19:31:03,186 cfg.training.batch_size            : 2048
2020-08-18 19:31:03,186 cfg.training.batch_type            : token
2020-08-18 19:31:03,186 cfg.training.decrease_factor       : 0.7
2020-08-18 19:31:03,186 cfg.training.early_stopping_metric : ppl
2020-08-18 19:31:03,186 cfg.training.epochs                : 20
2020-08-18 19:31:03,186 cfg.training.eval_metric           : bleu
2020-08-18 19:31:03,186 cfg.training.keep_last_ckpts       : 3
2020-08-18 19:31:03,186 cfg.training.label_smoothing       : 0.1
2020-08-18 19:31:03,186 cfg.training.learning_rate         : 0.0002
2020-08-18 19:31:03,186 cfg.training.learning_rate_min     : 1e-08
2020-08-18 19:31:03,186 cfg.training.logging_freq          : 100
2020-08-18 19:31:03,186 cfg.training.loss                  : crossentropy
2020-08-18 19:31:03,186 cfg.training.max_output_length     : 100
2020-08-18 19:31:03,187 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_2048_2048_2048_6_6
2020-08-18 19:31:03,187 cfg.training.normalization         : tokens
2020-08-18 19:31:03,187 cfg.training.optimizer             : adam
2020-08-18 19:31:03,187 cfg.training.overwrite             : True
2020-08-18 19:31:03,187 cfg.training.patience              : 8
2020-08-18 19:31:03,187 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 19:31:03,187 cfg.training.random_seed           : 42
2020-08-18 19:31:03,187 cfg.training.scheduling            : plateau
2020-08-18 19:31:03,187 cfg.training.shuffle               : True
2020-08-18 19:31:03,187 cfg.training.use_cuda              : True
2020-08-18 19:31:03,187 cfg.training.validation_freq       : 200
2020-08-18 19:31:03,187 cfg.training.weight_decay          : 0.0
2020-08-18 19:31:03,187 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 19:31:03,187 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 19:31:03,187 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 19:31:03,188 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 19:31:03,188 Number of Src words (types): 3468
2020-08-18 19:31:03,188 Number of Trg words (types): 4487
2020-08-18 19:31:03,188 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=2048, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=2048, vocab_size=4487))
2020-08-18 19:31:03,193 EPOCH 1
2020-08-18 19:31:34,410 Epoch   1: total training loss 290.58
2020-08-18 19:31:34,411 EPOCH 2
2020-08-18 19:32:03,190 Epoch   2 Step:      100 Batch Loss:     6.340784 Tokens per Sec:     2036, Lr: 0.000200
2020-08-18 19:32:05,733 Epoch   2: total training loss 253.71
2020-08-18 19:32:05,733 EPOCH 3
2020-08-18 19:32:36,846 Epoch   3: total training loss 242.50
2020-08-18 19:32:36,846 EPOCH 4
2020-08-18 19:33:03,754 Epoch   4 Step:      200 Batch Loss:     4.861712 Tokens per Sec:     2075, Lr: 0.000200
2020-08-18 19:36:00,304 Hooray! New best validation result [ppl]!
2020-08-18 19:36:00,304 Saving new checkpoint.
2020-08-18 19:36:33,099 Example #0
2020-08-18 19:36:33,099 	Raw source:     ['hello', '.']
2020-08-18 19:36:33,099 	Raw hypothesis: ['removemeimaboundary']
2020-08-18 19:36:33,099 	Source:     hello .
2020-08-18 19:36:33,099 	Reference:  hallo ,
2020-08-18 19:36:33,099 	Hypothesis: removemeimaboundary
2020-08-18 19:36:33,099 Example #1
2020-08-18 19:36:33,099 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:36:33,099 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 19:36:33,099 	Source:     hi , how can i help you ?
2020-08-18 19:36:33,099 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:36:33,099 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 19:36:33,099 Example #2
2020-08-18 19:36:33,099 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:36:33,099 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein']
2020-08-18 19:36:33,099 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:36:33,099 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:36:33,099 	Hypothesis: hallo , ich möchte ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein
2020-08-18 19:36:33,100 Example #3
2020-08-18 19:36:33,100 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:36:33,100 	Raw hypothesis: ['hallo', ',', 'wie', 'sie', '?']
2020-08-18 19:36:33,100 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:36:33,100 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:36:33,100 	Hypothesis: hallo , wie sie ?
2020-08-18 19:36:33,100 Validation result (greedy) at epoch   4, step      200: bleu:   1.14, loss: 27310.8262, ppl:  71.3300, duration: 209.3454s
2020-08-18 19:36:37,411 Epoch   4: total training loss 213.28
2020-08-18 19:36:37,411 EPOCH 5
2020-08-18 19:37:08,622 Epoch   5: total training loss 203.48
2020-08-18 19:37:08,622 EPOCH 6
2020-08-18 19:37:33,874 Epoch   6 Step:      300 Batch Loss:     2.627954 Tokens per Sec:     2081, Lr: 0.000200
2020-08-18 19:37:39,884 Epoch   6: total training loss 183.60
2020-08-18 19:37:39,884 EPOCH 7
2020-08-18 19:38:11,036 Epoch   7: total training loss 168.87
2020-08-18 19:38:11,037 EPOCH 8
2020-08-18 19:38:34,066 Epoch   8 Step:      400 Batch Loss:     2.796215 Tokens per Sec:     2085, Lr: 0.000200
2020-08-18 19:41:30,652 Hooray! New best validation result [ppl]!
2020-08-18 19:41:30,652 Saving new checkpoint.
2020-08-18 19:42:04,904 Example #0
2020-08-18 19:42:04,904 	Raw source:     ['hello', '.']
2020-08-18 19:42:04,904 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:42:04,904 	Source:     hello .
2020-08-18 19:42:04,904 	Reference:  hallo ,
2020-08-18 19:42:04,904 	Hypothesis: hallo .
2020-08-18 19:42:04,904 Example #1
2020-08-18 19:42:04,904 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:42:04,904 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 19:42:04,904 	Source:     hi , how can i help you ?
2020-08-18 19:42:04,904 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:42:04,904 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 19:42:04,904 Example #2
2020-08-18 19:42:04,905 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:42:04,905 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'einen', 'termin', 'für', 'meinen', 'hallo', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 19:42:04,905 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:42:04,905 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:42:04,905 	Hypothesis: hallo , ich möchte einen termin für meinen hallo , kalifornien , kalifornien .
2020-08-18 19:42:04,905 Example #3
2020-08-18 19:42:04,905 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:42:04,905 	Raw hypothesis: ['okay', ',', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-08-18 19:42:04,905 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:42:04,905 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:42:04,905 	Hypothesis: okay , welche art von essen möchten sie ?
2020-08-18 19:42:04,905 Validation result (greedy) at epoch   8, step      400: bleu:   4.68, loss: 21429.6094, ppl:  28.4565, duration: 210.8385s
2020-08-18 19:42:12,964 Epoch   8: total training loss 143.40
2020-08-18 19:42:12,964 EPOCH 9
2020-08-18 19:42:44,157 Epoch   9: total training loss 128.25
2020-08-18 19:42:44,158 EPOCH 10
2020-08-18 19:43:05,166 Epoch  10 Step:      500 Batch Loss:     2.601208 Tokens per Sec:     2091, Lr: 0.000200
2020-08-18 19:43:15,514 Epoch  10: total training loss 120.48
2020-08-18 19:43:15,514 EPOCH 11
2020-08-18 19:43:46,633 Epoch  11: total training loss 104.22
2020-08-18 19:43:46,633 EPOCH 12
2020-08-18 19:44:04,578 Epoch  12 Step:      600 Batch Loss:     1.729617 Tokens per Sec:     2069, Lr: 0.000200
2020-08-18 19:47:01,219 Hooray! New best validation result [ppl]!
2020-08-18 19:47:01,219 Saving new checkpoint.
2020-08-18 19:47:38,088 Example #0
2020-08-18 19:47:38,089 	Raw source:     ['hello', '.']
2020-08-18 19:47:38,089 	Raw hypothesis: ['hallo', ',']
2020-08-18 19:47:38,089 	Source:     hello .
2020-08-18 19:47:38,089 	Reference:  hallo ,
2020-08-18 19:47:38,089 	Hypothesis: hallo ,
2020-08-18 19:47:38,089 Example #1
2020-08-18 19:47:38,089 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:47:38,089 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 19:47:38,089 	Source:     hi , how can i help you ?
2020-08-18 19:47:38,089 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:47:38,089 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 19:47:38,089 Example #2
2020-08-18 19:47:38,089 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:47:38,089 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 19:47:38,090 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:47:38,090 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:47:38,090 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-18 19:47:38,090 Example #3
2020-08-18 19:47:38,090 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:47:38,090 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 19:47:38,090 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:47:38,090 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:47:38,090 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 19:47:38,090 Validation result (greedy) at epoch  12, step      600: bleu:  11.83, loss: 18784.1602, ppl:  18.8220, duration: 213.5122s
2020-08-18 19:47:51,491 Epoch  12: total training loss 87.56
2020-08-18 19:47:51,491 EPOCH 13
2020-08-18 19:48:22,670 Epoch  13: total training loss 73.31
2020-08-18 19:48:22,670 EPOCH 14
2020-08-18 19:48:39,217 Epoch  14 Step:      700 Batch Loss:     1.412158 Tokens per Sec:     2037, Lr: 0.000200
2020-08-18 19:48:54,045 Epoch  14: total training loss 65.88
2020-08-18 19:48:54,045 EPOCH 15
2020-08-18 19:49:25,213 Epoch  15: total training loss 55.37
2020-08-18 19:49:25,213 EPOCH 16
2020-08-18 19:49:39,104 Epoch  16 Step:      800 Batch Loss:     0.871893 Tokens per Sec:     2061, Lr: 0.000200
2020-08-18 19:51:54,270 Hooray! New best validation result [ppl]!
2020-08-18 19:51:54,271 Saving new checkpoint.
2020-08-18 19:52:29,688 Example #0
2020-08-18 19:52:29,688 	Raw source:     ['hello', '.']
2020-08-18 19:52:29,688 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:52:29,688 	Source:     hello .
2020-08-18 19:52:29,688 	Reference:  hallo ,
2020-08-18 19:52:29,688 	Hypothesis: hallo .
2020-08-18 19:52:29,689 Example #1
2020-08-18 19:52:29,689 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:52:29,689 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 19:52:29,689 	Source:     hi , how can i help you ?
2020-08-18 19:52:29,689 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:52:29,689 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 19:52:29,689 Example #2
2020-08-18 19:52:29,689 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:52:29,689 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'finden', '.']
2020-08-18 19:52:29,689 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:52:29,689 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:52:29,689 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien , in san francisco , kalifornien , finden .
2020-08-18 19:52:29,689 Example #3
2020-08-18 19:52:29,690 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:52:29,690 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 19:52:29,690 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:52:29,690 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:52:29,690 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 19:52:29,690 Validation result (greedy) at epoch  16, step      800: bleu:  19.32, loss: 17815.5859, ppl:  16.1785, duration: 170.5852s
2020-08-18 19:52:46,888 Epoch  16: total training loss 47.04
2020-08-18 19:52:46,889 EPOCH 17
2020-08-18 19:53:18,018 Epoch  17: total training loss 41.62
2020-08-18 19:53:18,019 EPOCH 18
2020-08-18 19:53:29,366 Epoch  18 Step:      900 Batch Loss:     0.553086 Tokens per Sec:     2060, Lr: 0.000200
2020-08-18 19:53:49,562 Epoch  18: total training loss 38.26
2020-08-18 19:53:49,563 EPOCH 19
2020-08-18 19:54:20,752 Epoch  19: total training loss 34.27
2020-08-18 19:54:20,752 EPOCH 20
2020-08-18 19:54:29,362 Epoch  20 Step:     1000 Batch Loss:     0.277253 Tokens per Sec:     2085, Lr: 0.000200
2020-08-18 19:56:32,439 Hooray! New best validation result [ppl]!
2020-08-18 19:56:32,440 Saving new checkpoint.
2020-08-18 19:57:06,820 Example #0
2020-08-18 19:57:06,820 	Raw source:     ['hello', '.']
2020-08-18 19:57:06,820 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:57:06,820 	Source:     hello .
2020-08-18 19:57:06,820 	Reference:  hallo ,
2020-08-18 19:57:06,820 	Hypothesis: hallo .
2020-08-18 19:57:06,820 Example #1
2020-08-18 19:57:06,820 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:57:06,820 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 19:57:06,820 	Source:     hi , how can i help you ?
2020-08-18 19:57:06,821 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:57:06,821 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 19:57:06,821 Example #2
2020-08-18 19:57:06,821 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:57:06,821 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 19:57:06,821 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:57:06,821 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:57:06,821 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien .
2020-08-18 19:57:06,821 Example #3
2020-08-18 19:57:06,821 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:57:06,821 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', 'abgesehen', 'vom', 'restaurant', 'suchen', '?']
2020-08-18 19:57:06,821 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:57:06,821 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:57:06,821 	Hypothesis: ok , nach welcher art von restaurant suchen sie abgesehen vom restaurant suchen ?
2020-08-18 19:57:06,821 Validation result (greedy) at epoch  20, step     1000: bleu:  20.83, loss: 17800.0117, ppl:  16.1392, duration: 157.4592s
2020-08-18 19:57:29,701 Epoch  20: total training loss 31.73
2020-08-18 19:57:29,701 Training ended after  20 epochs.
2020-08-18 19:57:29,701 Best validation result (greedy) at step     1000:  16.14 ppl.

2020-08-18 17:35:17,198 Hello! This is Joey-NMT.
2020-08-18 17:35:18,609 Total params: 96384000
2020-08-18 17:35:18,611 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 17:35:22,669 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 17:35:22,669 cfg.data.level                     : bpe
2020-08-18 17:35:22,669 cfg.data.lowercase                 : False
2020-08-18 17:35:22,669 cfg.data.max_sent_length           : 100
2020-08-18 17:35:22,670 cfg.data.src                       : en
2020-08-18 17:35:22,670 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 17:35:22,670 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 17:35:22,670 cfg.data.trg                       : de
2020-08-18 17:35:22,670 cfg.model.bias_initializer         : zeros
2020-08-18 17:35:22,670 cfg.model.decoder.dropout          : 0.1
2020-08-18 17:35:22,670 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 17:35:22,670 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-18 17:35:22,670 cfg.model.decoder.embeddings.scale : True
2020-08-18 17:35:22,670 cfg.model.decoder.ff_size          : 512
2020-08-18 17:35:22,670 cfg.model.decoder.freeze           : False
2020-08-18 17:35:22,670 cfg.model.decoder.hidden_size      : 1024
2020-08-18 17:35:22,670 cfg.model.decoder.num_heads        : 16
2020-08-18 17:35:22,670 cfg.model.decoder.num_layers       : 6
2020-08-18 17:35:22,670 cfg.model.decoder.type             : transformer
2020-08-18 17:35:22,670 cfg.model.embed_init_gain          : 1.0
2020-08-18 17:35:22,670 cfg.model.embed_initializer        : xavier
2020-08-18 17:35:22,671 cfg.model.encoder.dropout          : 0.3
2020-08-18 17:35:22,671 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 17:35:22,671 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-18 17:35:22,671 cfg.model.encoder.embeddings.scale : True
2020-08-18 17:35:22,671 cfg.model.encoder.ff_size          : 512
2020-08-18 17:35:22,671 cfg.model.encoder.freeze           : False
2020-08-18 17:35:22,671 cfg.model.encoder.hidden_size      : 1024
2020-08-18 17:35:22,671 cfg.model.encoder.multi_encoder    : False
2020-08-18 17:35:22,671 cfg.model.encoder.num_heads        : 16
2020-08-18 17:35:22,671 cfg.model.encoder.num_layers       : 6
2020-08-18 17:35:22,671 cfg.model.encoder.type             : transformer
2020-08-18 17:35:22,671 cfg.model.init_gain                : 1.0
2020-08-18 17:35:22,671 cfg.model.initializer              : xavier
2020-08-18 17:35:22,671 cfg.model.tied_embeddings          : False
2020-08-18 17:35:22,671 cfg.model.tied_softmax             : True
2020-08-18 17:35:22,671 cfg.name                           : transformer
2020-08-18 17:35:22,671 cfg.testing.alpha                  : 1.0
2020-08-18 17:35:22,671 cfg.testing.beam_size              : 5
2020-08-18 17:35:22,672 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 17:35:22,672 cfg.training.batch_multiplier      : 1
2020-08-18 17:35:22,672 cfg.training.batch_size            : 2048
2020-08-18 17:35:22,672 cfg.training.batch_type            : token
2020-08-18 17:35:22,672 cfg.training.decrease_factor       : 0.7
2020-08-18 17:35:22,672 cfg.training.early_stopping_metric : ppl
2020-08-18 17:35:22,672 cfg.training.epochs                : 20
2020-08-18 17:35:22,672 cfg.training.eval_metric           : bleu
2020-08-18 17:35:22,672 cfg.training.keep_last_ckpts       : 3
2020-08-18 17:35:22,672 cfg.training.label_smoothing       : 0.1
2020-08-18 17:35:22,672 cfg.training.learning_rate         : 0.0002
2020-08-18 17:35:22,672 cfg.training.learning_rate_min     : 1e-08
2020-08-18 17:35:22,672 cfg.training.logging_freq          : 100
2020-08-18 17:35:22,672 cfg.training.loss                  : crossentropy
2020-08-18 17:35:22,672 cfg.training.max_output_length     : 100
2020-08-18 17:35:22,672 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_1024_1024_2048_8_8
2020-08-18 17:35:22,673 cfg.training.normalization         : tokens
2020-08-18 17:35:22,673 cfg.training.optimizer             : adam
2020-08-18 17:35:22,673 cfg.training.overwrite             : True
2020-08-18 17:35:22,673 cfg.training.patience              : 8
2020-08-18 17:35:22,673 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 17:35:22,673 cfg.training.random_seed           : 42
2020-08-18 17:35:22,673 cfg.training.scheduling            : plateau
2020-08-18 17:35:22,673 cfg.training.shuffle               : True
2020-08-18 17:35:22,673 cfg.training.use_cuda              : True
2020-08-18 17:35:22,673 cfg.training.validation_freq       : 200
2020-08-18 17:35:22,673 cfg.training.weight_decay          : 0.0
2020-08-18 17:35:22,673 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 17:35:22,673 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 17:35:22,674 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 17:35:22,674 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 17:35:22,674 Number of Src words (types): 3468
2020-08-18 17:35:22,675 Number of Trg words (types): 4487
2020-08-18 17:35:22,675 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-18 17:35:22,679 EPOCH 1
2020-08-18 17:35:34,337 Epoch   1: total training loss 275.72
2020-08-18 17:35:34,337 EPOCH 2
2020-08-18 17:35:45,118 Epoch   2 Step:      100 Batch Loss:     5.843812 Tokens per Sec:     5436, Lr: 0.000200
2020-08-18 17:35:46,060 Epoch   2: total training loss 238.18
2020-08-18 17:35:46,060 EPOCH 3
2020-08-18 17:35:57,662 Epoch   3: total training loss 215.45
2020-08-18 17:35:57,663 EPOCH 4
2020-08-18 17:36:07,683 Epoch   4 Step:      200 Batch Loss:     4.359450 Tokens per Sec:     5571, Lr: 0.000200
2020-08-18 17:37:10,810 Hooray! New best validation result [ppl]!
2020-08-18 17:37:10,810 Saving new checkpoint.
2020-08-18 17:37:15,946 Example #0
2020-08-18 17:37:15,947 	Raw source:     ['hello', '.']
2020-08-18 17:37:15,947 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:37:15,947 	Source:     hello .
2020-08-18 17:37:15,947 	Reference:  hallo ,
2020-08-18 17:37:15,947 	Hypothesis: hallo .
2020-08-18 17:37:15,947 Example #1
2020-08-18 17:37:15,947 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:37:15,947 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:37:15,947 	Source:     hi , how can i help you ?
2020-08-18 17:37:15,947 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:37:15,947 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:37:15,947 Example #2
2020-08-18 17:37:15,947 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:37:15,947 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2020-08-18 17:37:15,947 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:37:15,947 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:37:15,947 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der der der der der der der der der der der der der der der der der der
2020-08-18 17:37:15,948 Example #3
2020-08-18 17:37:15,948 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:37:15,948 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von']
2020-08-18 17:37:15,948 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:37:15,948 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:37:15,948 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von
2020-08-18 17:37:15,948 Validation result (greedy) at epoch   4, step      200: bleu:   1.76, loss: 24026.3262, ppl:  42.6964, duration: 68.2648s
2020-08-18 17:37:17,570 Epoch   4: total training loss 184.13
2020-08-18 17:37:17,570 EPOCH 5
2020-08-18 17:37:29,206 Epoch   5: total training loss 166.88
2020-08-18 17:37:29,206 EPOCH 6
2020-08-18 17:37:38,653 Epoch   6 Step:      300 Batch Loss:     1.843859 Tokens per Sec:     5562, Lr: 0.000200
2020-08-18 17:37:40,900 Epoch   6: total training loss 138.81
2020-08-18 17:37:40,900 EPOCH 7
2020-08-18 17:37:52,494 Epoch   7: total training loss 127.27
2020-08-18 17:37:52,494 EPOCH 8
2020-08-18 17:38:01,063 Epoch   8 Step:      400 Batch Loss:     2.046960 Tokens per Sec:     5603, Lr: 0.000200
2020-08-18 17:39:00,464 Hooray! New best validation result [ppl]!
2020-08-18 17:39:00,464 Saving new checkpoint.
2020-08-18 17:39:05,315 Example #0
2020-08-18 17:39:05,315 	Raw source:     ['hello', '.']
2020-08-18 17:39:05,315 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:39:05,315 	Source:     hello .
2020-08-18 17:39:05,315 	Reference:  hallo ,
2020-08-18 17:39:05,315 	Hypothesis: hallo .
2020-08-18 17:39:05,315 Example #1
2020-08-18 17:39:05,315 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:39:05,315 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:39:05,315 	Source:     hi , how can i help you ?
2020-08-18 17:39:05,316 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:39:05,316 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:39:05,316 Example #2
2020-08-18 17:39:05,316 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:39:05,316 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:39:05,316 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:39:05,316 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:39:05,316 	Hypothesis: hallo , ich bin in sacramento , kalifornien , kalifornien , kalifornien in der arden fair mall .
2020-08-18 17:39:05,316 Example #3
2020-08-18 17:39:05,316 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:39:05,316 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-08-18 17:39:05,316 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:39:05,316 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:39:05,316 	Hypothesis: ok , welche art von restaurant für sie ?
2020-08-18 17:39:05,316 Validation result (greedy) at epoch   8, step      400: bleu:  12.12, loss: 17894.2324, ppl:  16.3786, duration: 64.2528s
2020-08-18 17:39:08,336 Epoch   8: total training loss 107.96
2020-08-18 17:39:08,337 EPOCH 9
2020-08-18 17:39:19,943 Epoch   9: total training loss 96.02
2020-08-18 17:39:19,943 EPOCH 10
2020-08-18 17:39:27,752 Epoch  10 Step:      500 Batch Loss:     2.032404 Tokens per Sec:     5625, Lr: 0.000200
2020-08-18 17:39:31,604 Epoch  10: total training loss 91.57
2020-08-18 17:39:31,604 EPOCH 11
2020-08-18 17:39:43,183 Epoch  11: total training loss 80.18
2020-08-18 17:39:43,183 EPOCH 12
2020-08-18 17:39:49,838 Epoch  12 Step:      600 Batch Loss:     1.372831 Tokens per Sec:     5578, Lr: 0.000200
2020-08-18 17:40:27,165 Hooray! New best validation result [ppl]!
2020-08-18 17:40:27,165 Saving new checkpoint.
2020-08-18 17:40:32,315 Example #0
2020-08-18 17:40:32,316 	Raw source:     ['hello', '.']
2020-08-18 17:40:32,316 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:40:32,316 	Source:     hello .
2020-08-18 17:40:32,316 	Reference:  hallo ,
2020-08-18 17:40:32,316 	Hypothesis: hallo .
2020-08-18 17:40:32,316 Example #1
2020-08-18 17:40:32,316 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:40:32,316 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:40:32,316 	Source:     hi , how can i help you ?
2020-08-18 17:40:32,316 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:40:32,316 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:40:32,316 Example #2
2020-08-18 17:40:32,316 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:40:32,316 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 17:40:32,317 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:40:32,317 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:40:32,317 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien in san francisco , kalifornien in san francisco , kalifornien .
2020-08-18 17:40:32,317 Example #3
2020-08-18 17:40:32,317 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:40:32,317 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:40:32,317 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:40:32,317 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:40:32,317 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:40:32,317 Validation result (greedy) at epoch  12, step      600: bleu:  23.63, loss: 16627.6602, ppl:  13.4378, duration: 42.4785s
2020-08-18 17:40:37,328 Epoch  12: total training loss 69.67
2020-08-18 17:40:37,328 EPOCH 13
2020-08-18 17:40:48,983 Epoch  13: total training loss 58.24
2020-08-18 17:40:48,983 EPOCH 14
2020-08-18 17:40:55,138 Epoch  14 Step:      700 Batch Loss:     1.082558 Tokens per Sec:     5476, Lr: 0.000200
2020-08-18 17:41:00,661 Epoch  14: total training loss 50.53
2020-08-18 17:41:00,661 EPOCH 15
2020-08-18 17:41:12,290 Epoch  15: total training loss 43.78
2020-08-18 17:41:12,290 EPOCH 16
2020-08-18 17:41:17,439 Epoch  16 Step:      800 Batch Loss:     0.655878 Tokens per Sec:     5562, Lr: 0.000200
2020-08-18 17:42:09,764 Hooray! New best validation result [ppl]!
2020-08-18 17:42:09,764 Saving new checkpoint.
2020-08-18 17:42:14,801 Example #0
2020-08-18 17:42:14,801 	Raw source:     ['hello', '.']
2020-08-18 17:42:14,801 	Raw hypothesis: ['hallo']
2020-08-18 17:42:14,801 	Source:     hello .
2020-08-18 17:42:14,801 	Reference:  hallo ,
2020-08-18 17:42:14,801 	Hypothesis: hallo
2020-08-18 17:42:14,801 Example #1
2020-08-18 17:42:14,801 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:42:14,801 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:42:14,801 	Source:     hi , how can i help you ?
2020-08-18 17:42:14,801 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:42:14,801 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:42:14,801 Example #2
2020-08-18 17:42:14,802 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:42:14,802 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:42:14,802 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:42:14,802 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:42:14,802 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:42:14,802 Example #3
2020-08-18 17:42:14,802 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:42:14,802 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:42:14,802 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:42:14,802 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:42:14,802 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:42:14,802 Validation result (greedy) at epoch  16, step      800: bleu:  24.36, loss: 15877.6338, ppl:  11.9518, duration: 57.3631s
2020-08-18 17:42:21,262 Epoch  16: total training loss 38.23
2020-08-18 17:42:21,262 EPOCH 17
2020-08-18 17:42:32,882 Epoch  17: total training loss 33.75
2020-08-18 17:42:32,882 EPOCH 18
2020-08-18 17:42:37,126 Epoch  18 Step:      900 Batch Loss:     0.425437 Tokens per Sec:     5509, Lr: 0.000200
2020-08-18 17:42:44,638 Epoch  18: total training loss 30.37
2020-08-18 17:42:44,638 EPOCH 19
2020-08-18 17:42:56,260 Epoch  19: total training loss 27.66
2020-08-18 17:42:56,261 EPOCH 20
2020-08-18 17:42:59,453 Epoch  20 Step:     1000 Batch Loss:     0.161490 Tokens per Sec:     5624, Lr: 0.000200
2020-08-18 17:43:16,882 Example #0
2020-08-18 17:43:16,882 	Raw source:     ['hello', '.']
2020-08-18 17:43:16,883 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:43:16,883 	Source:     hello .
2020-08-18 17:43:16,883 	Reference:  hallo ,
2020-08-18 17:43:16,883 	Hypothesis: hallo .
2020-08-18 17:43:16,883 Example #1
2020-08-18 17:43:16,883 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:43:16,883 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:43:16,883 	Source:     hi , how can i help you ?
2020-08-18 17:43:16,883 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:43:16,883 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:43:16,883 Example #2
2020-08-18 17:43:16,883 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:43:16,883 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:43:16,883 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:43:16,883 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:43:16,883 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:43:16,883 Example #3
2020-08-18 17:43:16,883 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:43:16,883 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:43:16,883 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:43:16,883 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:43:16,883 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:43:16,883 Validation result (greedy) at epoch  20, step     1000: bleu:  31.74, loss: 15943.3701, ppl:  12.0752, duration: 17.4301s
2020-08-18 17:43:25,470 Epoch  20: total training loss 25.11
2020-08-18 17:43:25,470 Training ended after  20 epochs.
2020-08-18 17:43:25,470 Best validation result (greedy) at step      800:  11.95 ppl.

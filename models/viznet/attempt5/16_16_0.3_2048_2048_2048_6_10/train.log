2020-08-18 19:04:08,667 Hello! This is Joey-NMT.
2020-08-18 19:04:11,169 Total params: 343756800
2020-08-18 19:04:11,171 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 19:04:15,523 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 19:04:15,524 cfg.data.level                     : bpe
2020-08-18 19:04:15,524 cfg.data.lowercase                 : False
2020-08-18 19:04:15,524 cfg.data.max_sent_length           : 100
2020-08-18 19:04:15,524 cfg.data.src                       : en
2020-08-18 19:04:15,524 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 19:04:15,524 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 19:04:15,524 cfg.data.trg                       : de
2020-08-18 19:04:15,524 cfg.model.bias_initializer         : zeros
2020-08-18 19:04:15,524 cfg.model.decoder.dropout          : 0.1
2020-08-18 19:04:15,524 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 19:04:15,524 cfg.model.decoder.embeddings.embedding_dim : 2048
2020-08-18 19:04:15,524 cfg.model.decoder.embeddings.scale : True
2020-08-18 19:04:15,524 cfg.model.decoder.ff_size          : 512
2020-08-18 19:04:15,524 cfg.model.decoder.freeze           : False
2020-08-18 19:04:15,524 cfg.model.decoder.hidden_size      : 2048
2020-08-18 19:04:15,524 cfg.model.decoder.num_heads        : 16
2020-08-18 19:04:15,524 cfg.model.decoder.num_layers       : 6
2020-08-18 19:04:15,524 cfg.model.decoder.type             : transformer
2020-08-18 19:04:15,525 cfg.model.embed_init_gain          : 1.0
2020-08-18 19:04:15,525 cfg.model.embed_initializer        : xavier
2020-08-18 19:04:15,525 cfg.model.encoder.dropout          : 0.3
2020-08-18 19:04:15,525 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 19:04:15,525 cfg.model.encoder.embeddings.embedding_dim : 2048
2020-08-18 19:04:15,525 cfg.model.encoder.embeddings.scale : True
2020-08-18 19:04:15,525 cfg.model.encoder.ff_size          : 512
2020-08-18 19:04:15,525 cfg.model.encoder.freeze           : False
2020-08-18 19:04:15,525 cfg.model.encoder.hidden_size      : 2048
2020-08-18 19:04:15,525 cfg.model.encoder.multi_encoder    : False
2020-08-18 19:04:15,525 cfg.model.encoder.num_heads        : 16
2020-08-18 19:04:15,525 cfg.model.encoder.num_layers       : 6
2020-08-18 19:04:15,525 cfg.model.encoder.type             : transformer
2020-08-18 19:04:15,525 cfg.model.init_gain                : 1.0
2020-08-18 19:04:15,525 cfg.model.initializer              : xavier
2020-08-18 19:04:15,525 cfg.model.tied_embeddings          : False
2020-08-18 19:04:15,525 cfg.model.tied_softmax             : True
2020-08-18 19:04:15,525 cfg.name                           : transformer
2020-08-18 19:04:15,525 cfg.testing.alpha                  : 1.0
2020-08-18 19:04:15,526 cfg.testing.beam_size              : 5
2020-08-18 19:04:15,526 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 19:04:15,526 cfg.training.batch_multiplier      : 1
2020-08-18 19:04:15,526 cfg.training.batch_size            : 2048
2020-08-18 19:04:15,526 cfg.training.batch_type            : token
2020-08-18 19:04:15,526 cfg.training.decrease_factor       : 0.7
2020-08-18 19:04:15,526 cfg.training.early_stopping_metric : ppl
2020-08-18 19:04:15,526 cfg.training.epochs                : 20
2020-08-18 19:04:15,526 cfg.training.eval_metric           : bleu
2020-08-18 19:04:15,526 cfg.training.keep_last_ckpts       : 3
2020-08-18 19:04:15,526 cfg.training.label_smoothing       : 0.1
2020-08-18 19:04:15,526 cfg.training.learning_rate         : 0.0002
2020-08-18 19:04:15,526 cfg.training.learning_rate_min     : 1e-08
2020-08-18 19:04:15,526 cfg.training.logging_freq          : 100
2020-08-18 19:04:15,526 cfg.training.loss                  : crossentropy
2020-08-18 19:04:15,526 cfg.training.max_output_length     : 100
2020-08-18 19:04:15,526 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_2048_2048_2048_6_10
2020-08-18 19:04:15,526 cfg.training.normalization         : tokens
2020-08-18 19:04:15,526 cfg.training.optimizer             : adam
2020-08-18 19:04:15,527 cfg.training.overwrite             : True
2020-08-18 19:04:15,527 cfg.training.patience              : 8
2020-08-18 19:04:15,527 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 19:04:15,527 cfg.training.random_seed           : 42
2020-08-18 19:04:15,527 cfg.training.scheduling            : plateau
2020-08-18 19:04:15,527 cfg.training.shuffle               : True
2020-08-18 19:04:15,527 cfg.training.use_cuda              : True
2020-08-18 19:04:15,527 cfg.training.validation_freq       : 200
2020-08-18 19:04:15,527 cfg.training.weight_decay          : 0.0
2020-08-18 19:04:15,527 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 19:04:15,527 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 19:04:15,527 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 19:04:15,528 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 19:04:15,528 Number of Src words (types): 3468
2020-08-18 19:04:15,528 Number of Trg words (types): 4487
2020-08-18 19:04:15,528 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=2048, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=2048, vocab_size=4487))
2020-08-18 19:04:15,534 EPOCH 1
2020-08-18 19:04:46,764 Epoch   1: total training loss 290.58
2020-08-18 19:04:46,764 EPOCH 2
2020-08-18 19:05:15,579 Epoch   2 Step:      100 Batch Loss:     6.340784 Tokens per Sec:     2034, Lr: 0.000200
2020-08-18 19:05:18,123 Epoch   2: total training loss 253.71
2020-08-18 19:05:18,123 EPOCH 3
2020-08-18 19:05:49,264 Epoch   3: total training loss 242.50
2020-08-18 19:05:49,264 EPOCH 4
2020-08-18 19:06:16,204 Epoch   4 Step:      200 Batch Loss:     4.861712 Tokens per Sec:     2072, Lr: 0.000200
2020-08-18 19:09:12,782 Hooray! New best validation result [ppl]!
2020-08-18 19:09:12,782 Saving new checkpoint.
2020-08-18 19:09:46,837 Example #0
2020-08-18 19:09:46,837 	Raw source:     ['hello', '.']
2020-08-18 19:09:46,837 	Raw hypothesis: ['removemeimaboundary']
2020-08-18 19:09:46,837 	Source:     hello .
2020-08-18 19:09:46,837 	Reference:  hallo ,
2020-08-18 19:09:46,837 	Hypothesis: removemeimaboundary
2020-08-18 19:09:46,837 Example #1
2020-08-18 19:09:46,837 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:09:46,837 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 19:09:46,837 	Source:     hi , how can i help you ?
2020-08-18 19:09:46,838 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:09:46,838 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 19:09:46,838 Example #2
2020-08-18 19:09:46,838 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:09:46,838 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein']
2020-08-18 19:09:46,838 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:09:46,838 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:09:46,838 	Hypothesis: hallo , ich möchte ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein
2020-08-18 19:09:46,838 Example #3
2020-08-18 19:09:46,838 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:09:46,838 	Raw hypothesis: ['hallo', ',', 'wie', 'sie', '?']
2020-08-18 19:09:46,838 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:09:46,838 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:09:46,838 	Hypothesis: hallo , wie sie ?
2020-08-18 19:09:46,838 Validation result (greedy) at epoch   4, step      200: bleu:   1.14, loss: 27310.8262, ppl:  71.3300, duration: 210.6342s
2020-08-18 19:09:51,163 Epoch   4: total training loss 213.28
2020-08-18 19:09:51,164 EPOCH 5
2020-08-18 19:10:22,387 Epoch   5: total training loss 203.48
2020-08-18 19:10:22,388 EPOCH 6
2020-08-18 19:10:47,664 Epoch   6 Step:      300 Batch Loss:     2.627954 Tokens per Sec:     2079, Lr: 0.000200
2020-08-18 19:10:53,677 Epoch   6: total training loss 183.60
2020-08-18 19:10:53,678 EPOCH 7
2020-08-18 19:11:24,852 Epoch   7: total training loss 168.87
2020-08-18 19:11:24,852 EPOCH 8
2020-08-18 19:11:47,890 Epoch   8 Step:      400 Batch Loss:     2.796215 Tokens per Sec:     2084, Lr: 0.000200
2020-08-18 19:14:44,500 Hooray! New best validation result [ppl]!
2020-08-18 19:14:44,501 Saving new checkpoint.
2020-08-18 19:15:18,630 Example #0
2020-08-18 19:15:18,630 	Raw source:     ['hello', '.']
2020-08-18 19:15:18,630 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:15:18,630 	Source:     hello .
2020-08-18 19:15:18,630 	Reference:  hallo ,
2020-08-18 19:15:18,630 	Hypothesis: hallo .
2020-08-18 19:15:18,630 Example #1
2020-08-18 19:15:18,630 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:15:18,630 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 19:15:18,630 	Source:     hi , how can i help you ?
2020-08-18 19:15:18,630 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:15:18,630 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 19:15:18,630 Example #2
2020-08-18 19:15:18,630 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:15:18,630 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'einen', 'termin', 'für', 'meinen', 'hallo', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 19:15:18,630 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:15:18,630 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:15:18,630 	Hypothesis: hallo , ich möchte einen termin für meinen hallo , kalifornien , kalifornien .
2020-08-18 19:15:18,631 Example #3
2020-08-18 19:15:18,631 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:15:18,631 	Raw hypothesis: ['okay', ',', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-08-18 19:15:18,631 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:15:18,631 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:15:18,631 	Hypothesis: okay , welche art von essen möchten sie ?
2020-08-18 19:15:18,631 Validation result (greedy) at epoch   8, step      400: bleu:   4.68, loss: 21429.6094, ppl:  28.4565, duration: 210.7402s
2020-08-18 19:15:26,687 Epoch   8: total training loss 143.40
2020-08-18 19:15:26,687 EPOCH 9
2020-08-18 19:15:57,882 Epoch   9: total training loss 128.25
2020-08-18 19:15:57,882 EPOCH 10
2020-08-18 19:16:18,889 Epoch  10 Step:      500 Batch Loss:     2.601208 Tokens per Sec:     2091, Lr: 0.000200
2020-08-18 19:16:29,239 Epoch  10: total training loss 120.48
2020-08-18 19:16:29,240 EPOCH 11
2020-08-18 19:17:00,371 Epoch  11: total training loss 104.22
2020-08-18 19:17:00,371 EPOCH 12
2020-08-18 19:17:18,321 Epoch  12 Step:      600 Batch Loss:     1.729617 Tokens per Sec:     2068, Lr: 0.000200
2020-08-18 19:20:14,953 Hooray! New best validation result [ppl]!
2020-08-18 19:20:14,954 Saving new checkpoint.
2020-08-18 19:20:50,404 Example #0
2020-08-18 19:20:50,404 	Raw source:     ['hello', '.']
2020-08-18 19:20:50,404 	Raw hypothesis: ['hallo', ',']
2020-08-18 19:20:50,404 	Source:     hello .
2020-08-18 19:20:50,404 	Reference:  hallo ,
2020-08-18 19:20:50,404 	Hypothesis: hallo ,
2020-08-18 19:20:50,404 Example #1
2020-08-18 19:20:50,405 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:20:50,405 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 19:20:50,405 	Source:     hi , how can i help you ?
2020-08-18 19:20:50,405 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:20:50,405 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 19:20:50,405 Example #2
2020-08-18 19:20:50,405 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:20:50,405 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 19:20:50,405 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:20:50,405 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:20:50,405 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-18 19:20:50,405 Example #3
2020-08-18 19:20:50,405 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:20:50,405 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 19:20:50,405 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:20:50,405 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:20:50,405 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 19:20:50,406 Validation result (greedy) at epoch  12, step      600: bleu:  11.83, loss: 18784.1602, ppl:  18.8220, duration: 212.0839s
2020-08-18 19:21:03,824 Epoch  12: total training loss 87.56
2020-08-18 19:21:03,825 EPOCH 13
2020-08-18 19:21:35,024 Epoch  13: total training loss 73.31
2020-08-18 19:21:35,024 EPOCH 14
2020-08-18 19:21:51,566 Epoch  14 Step:      700 Batch Loss:     1.412158 Tokens per Sec:     2037, Lr: 0.000200
2020-08-18 19:22:06,401 Epoch  14: total training loss 65.88
2020-08-18 19:22:06,401 EPOCH 15
2020-08-18 19:22:37,567 Epoch  15: total training loss 55.37
2020-08-18 19:22:37,568 EPOCH 16
2020-08-18 19:22:51,468 Epoch  16 Step:      800 Batch Loss:     0.871893 Tokens per Sec:     2060, Lr: 0.000200
2020-08-18 19:25:06,585 Hooray! New best validation result [ppl]!
2020-08-18 19:25:06,585 Saving new checkpoint.
2020-08-18 19:25:40,677 Example #0
2020-08-18 19:25:40,677 	Raw source:     ['hello', '.']
2020-08-18 19:25:40,677 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:25:40,677 	Source:     hello .
2020-08-18 19:25:40,677 	Reference:  hallo ,
2020-08-18 19:25:40,677 	Hypothesis: hallo .
2020-08-18 19:25:40,677 Example #1
2020-08-18 19:25:40,677 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:25:40,677 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 19:25:40,677 	Source:     hi , how can i help you ?
2020-08-18 19:25:40,677 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:25:40,678 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 19:25:40,678 Example #2
2020-08-18 19:25:40,678 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:25:40,678 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'finden', '.']
2020-08-18 19:25:40,678 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:25:40,678 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:25:40,678 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien , in san francisco , kalifornien , finden .
2020-08-18 19:25:40,678 Example #3
2020-08-18 19:25:40,678 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:25:40,678 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 19:25:40,678 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:25:40,678 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:25:40,678 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 19:25:40,678 Validation result (greedy) at epoch  16, step      800: bleu:  19.32, loss: 17815.5859, ppl:  16.1785, duration: 169.2103s
2020-08-18 19:25:57,875 Epoch  16: total training loss 47.04
2020-08-18 19:25:57,875 EPOCH 17
2020-08-18 19:26:29,003 Epoch  17: total training loss 41.62
2020-08-18 19:26:29,003 EPOCH 18
2020-08-18 19:26:40,349 Epoch  18 Step:      900 Batch Loss:     0.553086 Tokens per Sec:     2060, Lr: 0.000200
2020-08-18 19:27:00,544 Epoch  18: total training loss 38.26
2020-08-18 19:27:00,544 EPOCH 19
2020-08-18 19:27:31,730 Epoch  19: total training loss 34.27
2020-08-18 19:27:31,730 EPOCH 20
2020-08-18 19:27:40,343 Epoch  20 Step:     1000 Batch Loss:     0.277253 Tokens per Sec:     2084, Lr: 0.000200
2020-08-18 19:29:43,363 Hooray! New best validation result [ppl]!
2020-08-18 19:29:43,363 Saving new checkpoint.
2020-08-18 19:30:17,492 Example #0
2020-08-18 19:30:17,492 	Raw source:     ['hello', '.']
2020-08-18 19:30:17,492 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:30:17,492 	Source:     hello .
2020-08-18 19:30:17,492 	Reference:  hallo ,
2020-08-18 19:30:17,492 	Hypothesis: hallo .
2020-08-18 19:30:17,492 Example #1
2020-08-18 19:30:17,493 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:30:17,493 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 19:30:17,493 	Source:     hi , how can i help you ?
2020-08-18 19:30:17,493 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:30:17,493 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 19:30:17,493 Example #2
2020-08-18 19:30:17,493 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:30:17,493 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 19:30:17,493 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:30:17,493 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:30:17,493 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien .
2020-08-18 19:30:17,493 Example #3
2020-08-18 19:30:17,493 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:30:17,493 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', 'abgesehen', 'vom', 'restaurant', 'suchen', '?']
2020-08-18 19:30:17,493 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:30:17,493 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:30:17,493 	Hypothesis: ok , nach welcher art von restaurant suchen sie abgesehen vom restaurant suchen ?
2020-08-18 19:30:17,493 Validation result (greedy) at epoch  20, step     1000: bleu:  20.83, loss: 17800.0117, ppl:  16.1392, duration: 157.1501s
2020-08-18 19:30:40,375 Epoch  20: total training loss 31.73
2020-08-18 19:30:40,376 Training ended after  20 epochs.
2020-08-18 19:30:40,376 Best validation result (greedy) at step     1000:  16.14 ppl.

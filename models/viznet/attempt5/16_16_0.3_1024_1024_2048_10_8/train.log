2020-08-18 16:45:54,650 Hello! This is Joey-NMT.
2020-08-18 16:45:56,006 Total params: 96384000
2020-08-18 16:45:56,007 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 16:45:59,921 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 16:45:59,922 cfg.data.level                     : bpe
2020-08-18 16:45:59,922 cfg.data.lowercase                 : False
2020-08-18 16:45:59,922 cfg.data.max_sent_length           : 100
2020-08-18 16:45:59,922 cfg.data.src                       : en
2020-08-18 16:45:59,922 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 16:45:59,922 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 16:45:59,922 cfg.data.trg                       : de
2020-08-18 16:45:59,922 cfg.model.bias_initializer         : zeros
2020-08-18 16:45:59,922 cfg.model.decoder.dropout          : 0.1
2020-08-18 16:45:59,922 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 16:45:59,922 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-18 16:45:59,922 cfg.model.decoder.embeddings.scale : True
2020-08-18 16:45:59,922 cfg.model.decoder.ff_size          : 512
2020-08-18 16:45:59,922 cfg.model.decoder.freeze           : False
2020-08-18 16:45:59,922 cfg.model.decoder.hidden_size      : 1024
2020-08-18 16:45:59,923 cfg.model.decoder.num_heads        : 16
2020-08-18 16:45:59,923 cfg.model.decoder.num_layers       : 6
2020-08-18 16:45:59,923 cfg.model.decoder.type             : transformer
2020-08-18 16:45:59,923 cfg.model.embed_init_gain          : 1.0
2020-08-18 16:45:59,923 cfg.model.embed_initializer        : xavier
2020-08-18 16:45:59,923 cfg.model.encoder.dropout          : 0.3
2020-08-18 16:45:59,923 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 16:45:59,923 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-18 16:45:59,923 cfg.model.encoder.embeddings.scale : True
2020-08-18 16:45:59,923 cfg.model.encoder.ff_size          : 512
2020-08-18 16:45:59,923 cfg.model.encoder.freeze           : False
2020-08-18 16:45:59,923 cfg.model.encoder.hidden_size      : 1024
2020-08-18 16:45:59,923 cfg.model.encoder.multi_encoder    : False
2020-08-18 16:45:59,923 cfg.model.encoder.num_heads        : 16
2020-08-18 16:45:59,923 cfg.model.encoder.num_layers       : 6
2020-08-18 16:45:59,923 cfg.model.encoder.type             : transformer
2020-08-18 16:45:59,923 cfg.model.init_gain                : 1.0
2020-08-18 16:45:59,924 cfg.model.initializer              : xavier
2020-08-18 16:45:59,924 cfg.model.tied_embeddings          : False
2020-08-18 16:45:59,924 cfg.model.tied_softmax             : True
2020-08-18 16:45:59,924 cfg.name                           : transformer
2020-08-18 16:45:59,924 cfg.testing.alpha                  : 1.0
2020-08-18 16:45:59,924 cfg.testing.beam_size              : 5
2020-08-18 16:45:59,924 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 16:45:59,924 cfg.training.batch_multiplier      : 1
2020-08-18 16:45:59,924 cfg.training.batch_size            : 2048
2020-08-18 16:45:59,924 cfg.training.batch_type            : token
2020-08-18 16:45:59,924 cfg.training.decrease_factor       : 0.7
2020-08-18 16:45:59,924 cfg.training.early_stopping_metric : ppl
2020-08-18 16:45:59,924 cfg.training.epochs                : 20
2020-08-18 16:45:59,924 cfg.training.eval_metric           : bleu
2020-08-18 16:45:59,924 cfg.training.keep_last_ckpts       : 3
2020-08-18 16:45:59,924 cfg.training.label_smoothing       : 0.1
2020-08-18 16:45:59,925 cfg.training.learning_rate         : 0.0002
2020-08-18 16:45:59,925 cfg.training.learning_rate_min     : 1e-08
2020-08-18 16:45:59,925 cfg.training.logging_freq          : 100
2020-08-18 16:45:59,925 cfg.training.loss                  : crossentropy
2020-08-18 16:45:59,925 cfg.training.max_output_length     : 100
2020-08-18 16:45:59,925 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_1024_1024_2048_10_8
2020-08-18 16:45:59,925 cfg.training.normalization         : tokens
2020-08-18 16:45:59,925 cfg.training.optimizer             : adam
2020-08-18 16:45:59,925 cfg.training.overwrite             : True
2020-08-18 16:45:59,925 cfg.training.patience              : 8
2020-08-18 16:45:59,925 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 16:45:59,925 cfg.training.random_seed           : 42
2020-08-18 16:45:59,925 cfg.training.scheduling            : plateau
2020-08-18 16:45:59,925 cfg.training.shuffle               : True
2020-08-18 16:45:59,925 cfg.training.use_cuda              : True
2020-08-18 16:45:59,925 cfg.training.validation_freq       : 200
2020-08-18 16:45:59,925 cfg.training.weight_decay          : 0.0
2020-08-18 16:45:59,925 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 16:45:59,925 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 16:45:59,925 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 16:45:59,926 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 16:45:59,926 Number of Src words (types): 3468
2020-08-18 16:45:59,927 Number of Trg words (types): 4487
2020-08-18 16:45:59,927 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-18 16:45:59,931 EPOCH 1
2020-08-18 16:46:11,565 Epoch   1: total training loss 275.72
2020-08-18 16:46:11,565 EPOCH 2
2020-08-18 16:46:22,319 Epoch   2 Step:      100 Batch Loss:     5.843812 Tokens per Sec:     5450, Lr: 0.000200
2020-08-18 16:46:23,257 Epoch   2: total training loss 238.18
2020-08-18 16:46:23,257 EPOCH 3
2020-08-18 16:46:34,856 Epoch   3: total training loss 215.45
2020-08-18 16:46:34,856 EPOCH 4
2020-08-18 16:46:44,853 Epoch   4 Step:      200 Batch Loss:     4.359450 Tokens per Sec:     5585, Lr: 0.000200
2020-08-18 16:47:47,815 Hooray! New best validation result [ppl]!
2020-08-18 16:47:47,815 Saving new checkpoint.
2020-08-18 16:47:52,554 Example #0
2020-08-18 16:47:52,554 	Raw source:     ['hello', '.']
2020-08-18 16:47:52,554 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:47:52,555 	Source:     hello .
2020-08-18 16:47:52,555 	Reference:  hallo ,
2020-08-18 16:47:52,555 	Hypothesis: hallo .
2020-08-18 16:47:52,555 Example #1
2020-08-18 16:47:52,555 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:47:52,555 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:47:52,555 	Source:     hi , how can i help you ?
2020-08-18 16:47:52,555 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:47:52,555 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:47:52,555 Example #2
2020-08-18 16:47:52,555 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:47:52,555 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2020-08-18 16:47:52,555 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:47:52,555 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:47:52,555 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der der der der der der der der der der der der der der der der der der
2020-08-18 16:47:52,555 Example #3
2020-08-18 16:47:52,555 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:47:52,556 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von']
2020-08-18 16:47:52,556 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:47:52,556 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:47:52,556 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von
2020-08-18 16:47:52,556 Validation result (greedy) at epoch   4, step      200: bleu:   1.76, loss: 24026.3262, ppl:  42.6964, duration: 67.7028s
2020-08-18 16:47:54,164 Epoch   4: total training loss 184.13
2020-08-18 16:47:54,164 EPOCH 5
2020-08-18 16:48:05,747 Epoch   5: total training loss 166.88
2020-08-18 16:48:05,747 EPOCH 6
2020-08-18 16:48:15,201 Epoch   6 Step:      300 Batch Loss:     1.843859 Tokens per Sec:     5559, Lr: 0.000200
2020-08-18 16:48:17,440 Epoch   6: total training loss 138.81
2020-08-18 16:48:17,440 EPOCH 7
2020-08-18 16:48:29,039 Epoch   7: total training loss 127.27
2020-08-18 16:48:29,039 EPOCH 8
2020-08-18 16:48:37,568 Epoch   8 Step:      400 Batch Loss:     2.046960 Tokens per Sec:     5629, Lr: 0.000200
2020-08-18 16:49:36,810 Hooray! New best validation result [ppl]!
2020-08-18 16:49:36,810 Saving new checkpoint.
2020-08-18 16:49:41,560 Example #0
2020-08-18 16:49:41,560 	Raw source:     ['hello', '.']
2020-08-18 16:49:41,560 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:49:41,560 	Source:     hello .
2020-08-18 16:49:41,560 	Reference:  hallo ,
2020-08-18 16:49:41,560 	Hypothesis: hallo .
2020-08-18 16:49:41,560 Example #1
2020-08-18 16:49:41,560 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:49:41,560 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:49:41,560 	Source:     hi , how can i help you ?
2020-08-18 16:49:41,560 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:49:41,560 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:49:41,560 Example #2
2020-08-18 16:49:41,561 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:49:41,561 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 16:49:41,561 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:49:41,561 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:49:41,561 	Hypothesis: hallo , ich bin in sacramento , kalifornien , kalifornien , kalifornien in der arden fair mall .
2020-08-18 16:49:41,561 Example #3
2020-08-18 16:49:41,561 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:49:41,561 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-08-18 16:49:41,561 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:49:41,561 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:49:41,561 	Hypothesis: ok , welche art von restaurant für sie ?
2020-08-18 16:49:41,561 Validation result (greedy) at epoch   8, step      400: bleu:  12.12, loss: 17894.2324, ppl:  16.3786, duration: 63.9924s
2020-08-18 16:49:44,552 Epoch   8: total training loss 107.96
2020-08-18 16:49:44,552 EPOCH 9
2020-08-18 16:49:56,114 Epoch   9: total training loss 96.02
2020-08-18 16:49:56,114 EPOCH 10
2020-08-18 16:50:03,882 Epoch  10 Step:      500 Batch Loss:     2.032404 Tokens per Sec:     5655, Lr: 0.000200
2020-08-18 16:50:07,713 Epoch  10: total training loss 91.57
2020-08-18 16:50:07,713 EPOCH 11
2020-08-18 16:50:19,261 Epoch  11: total training loss 80.18
2020-08-18 16:50:19,262 EPOCH 12
2020-08-18 16:50:25,934 Epoch  12 Step:      600 Batch Loss:     1.372831 Tokens per Sec:     5563, Lr: 0.000200
2020-08-18 16:51:03,182 Hooray! New best validation result [ppl]!
2020-08-18 16:51:03,183 Saving new checkpoint.
2020-08-18 16:51:07,930 Example #0
2020-08-18 16:51:07,930 	Raw source:     ['hello', '.']
2020-08-18 16:51:07,930 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:51:07,930 	Source:     hello .
2020-08-18 16:51:07,930 	Reference:  hallo ,
2020-08-18 16:51:07,930 	Hypothesis: hallo .
2020-08-18 16:51:07,930 Example #1
2020-08-18 16:51:07,930 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:51:07,930 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:51:07,930 	Source:     hi , how can i help you ?
2020-08-18 16:51:07,930 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:51:07,930 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:51:07,931 Example #2
2020-08-18 16:51:07,931 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:51:07,931 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 16:51:07,931 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:51:07,931 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:51:07,931 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien in san francisco , kalifornien in san francisco , kalifornien .
2020-08-18 16:51:07,931 Example #3
2020-08-18 16:51:07,931 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:51:07,931 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 16:51:07,931 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:51:07,931 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:51:07,931 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 16:51:07,931 Validation result (greedy) at epoch  12, step      600: bleu:  23.63, loss: 16627.6602, ppl:  13.4378, duration: 41.9964s
2020-08-18 16:51:12,929 Epoch  12: total training loss 69.67
2020-08-18 16:51:12,929 EPOCH 13
2020-08-18 16:51:24,518 Epoch  13: total training loss 58.24
2020-08-18 16:51:24,519 EPOCH 14
2020-08-18 16:51:30,643 Epoch  14 Step:      700 Batch Loss:     1.082558 Tokens per Sec:     5503, Lr: 0.000200
2020-08-18 16:51:36,153 Epoch  14: total training loss 50.53
2020-08-18 16:51:36,153 EPOCH 15
2020-08-18 16:51:47,747 Epoch  15: total training loss 43.78
2020-08-18 16:51:47,747 EPOCH 16
2020-08-18 16:51:52,889 Epoch  16 Step:      800 Batch Loss:     0.655878 Tokens per Sec:     5569, Lr: 0.000200
2020-08-18 16:52:45,088 Hooray! New best validation result [ppl]!
2020-08-18 16:52:45,088 Saving new checkpoint.
2020-08-18 16:52:49,940 Example #0
2020-08-18 16:52:49,940 	Raw source:     ['hello', '.']
2020-08-18 16:52:49,940 	Raw hypothesis: ['hallo']
2020-08-18 16:52:49,940 	Source:     hello .
2020-08-18 16:52:49,940 	Reference:  hallo ,
2020-08-18 16:52:49,941 	Hypothesis: hallo
2020-08-18 16:52:49,941 Example #1
2020-08-18 16:52:49,941 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:52:49,941 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:52:49,941 	Source:     hi , how can i help you ?
2020-08-18 16:52:49,941 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:52:49,941 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:52:49,941 Example #2
2020-08-18 16:52:49,941 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:52:49,941 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 16:52:49,941 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:52:49,941 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:52:49,941 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in der arden fair mall .
2020-08-18 16:52:49,941 Example #3
2020-08-18 16:52:49,941 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:52:49,941 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 16:52:49,941 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:52:49,941 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:52:49,941 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 16:52:49,941 Validation result (greedy) at epoch  16, step      800: bleu:  24.36, loss: 15877.6338, ppl:  11.9518, duration: 57.0518s
2020-08-18 16:52:56,352 Epoch  16: total training loss 38.23
2020-08-18 16:52:56,352 EPOCH 17
2020-08-18 16:53:07,921 Epoch  17: total training loss 33.75
2020-08-18 16:53:07,921 EPOCH 18
2020-08-18 16:53:12,148 Epoch  18 Step:      900 Batch Loss:     0.425437 Tokens per Sec:     5530, Lr: 0.000200
2020-08-18 16:53:19,617 Epoch  18: total training loss 30.37
2020-08-18 16:53:19,617 EPOCH 19
2020-08-18 16:53:31,171 Epoch  19: total training loss 27.66
2020-08-18 16:53:31,171 EPOCH 20
2020-08-18 16:53:34,352 Epoch  20 Step:     1000 Batch Loss:     0.161490 Tokens per Sec:     5645, Lr: 0.000200
2020-08-18 16:53:51,752 Example #0
2020-08-18 16:53:51,753 	Raw source:     ['hello', '.']
2020-08-18 16:53:51,753 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:53:51,753 	Source:     hello .
2020-08-18 16:53:51,753 	Reference:  hallo ,
2020-08-18 16:53:51,753 	Hypothesis: hallo .
2020-08-18 16:53:51,753 Example #1
2020-08-18 16:53:51,753 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:53:51,753 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:53:51,753 	Source:     hi , how can i help you ?
2020-08-18 16:53:51,753 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:53:51,753 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:53:51,753 Example #2
2020-08-18 16:53:51,753 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:53:51,753 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 16:53:51,753 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:53:51,753 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:53:51,753 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in der arden fair mall .
2020-08-18 16:53:51,753 Example #3
2020-08-18 16:53:51,753 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:53:51,753 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 16:53:51,753 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:53:51,753 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:53:51,753 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 16:53:51,753 Validation result (greedy) at epoch  20, step     1000: bleu:  31.74, loss: 15943.3701, ppl:  12.0752, duration: 17.4013s
2020-08-18 16:54:00,292 Epoch  20: total training loss 25.11
2020-08-18 16:54:00,292 Training ended after  20 epochs.
2020-08-18 16:54:00,292 Best validation result (greedy) at step      800:  11.95 ppl.

2020-08-18 19:57:46,635 Hello! This is Joey-NMT.
2020-08-18 19:57:48,834 Total params: 343756800
2020-08-18 19:57:48,836 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 19:57:53,247 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 19:57:53,247 cfg.data.level                     : bpe
2020-08-18 19:57:53,247 cfg.data.lowercase                 : False
2020-08-18 19:57:53,247 cfg.data.max_sent_length           : 100
2020-08-18 19:57:53,247 cfg.data.src                       : en
2020-08-18 19:57:53,247 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 19:57:53,247 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 19:57:53,247 cfg.data.trg                       : de
2020-08-18 19:57:53,247 cfg.model.bias_initializer         : zeros
2020-08-18 19:57:53,247 cfg.model.decoder.dropout          : 0.1
2020-08-18 19:57:53,247 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 19:57:53,247 cfg.model.decoder.embeddings.embedding_dim : 2048
2020-08-18 19:57:53,248 cfg.model.decoder.embeddings.scale : True
2020-08-18 19:57:53,248 cfg.model.decoder.ff_size          : 512
2020-08-18 19:57:53,248 cfg.model.decoder.freeze           : False
2020-08-18 19:57:53,248 cfg.model.decoder.hidden_size      : 2048
2020-08-18 19:57:53,248 cfg.model.decoder.num_heads        : 16
2020-08-18 19:57:53,248 cfg.model.decoder.num_layers       : 6
2020-08-18 19:57:53,248 cfg.model.decoder.type             : transformer
2020-08-18 19:57:53,248 cfg.model.embed_init_gain          : 1.0
2020-08-18 19:57:53,248 cfg.model.embed_initializer        : xavier
2020-08-18 19:57:53,248 cfg.model.encoder.dropout          : 0.3
2020-08-18 19:57:53,248 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 19:57:53,248 cfg.model.encoder.embeddings.embedding_dim : 2048
2020-08-18 19:57:53,248 cfg.model.encoder.embeddings.scale : True
2020-08-18 19:57:53,248 cfg.model.encoder.ff_size          : 512
2020-08-18 19:57:53,248 cfg.model.encoder.freeze           : False
2020-08-18 19:57:53,248 cfg.model.encoder.hidden_size      : 2048
2020-08-18 19:57:53,248 cfg.model.encoder.multi_encoder    : False
2020-08-18 19:57:53,248 cfg.model.encoder.num_heads        : 16
2020-08-18 19:57:53,248 cfg.model.encoder.num_layers       : 6
2020-08-18 19:57:53,248 cfg.model.encoder.type             : transformer
2020-08-18 19:57:53,248 cfg.model.init_gain                : 1.0
2020-08-18 19:57:53,248 cfg.model.initializer              : xavier
2020-08-18 19:57:53,248 cfg.model.tied_embeddings          : False
2020-08-18 19:57:53,248 cfg.model.tied_softmax             : True
2020-08-18 19:57:53,248 cfg.name                           : transformer
2020-08-18 19:57:53,248 cfg.testing.alpha                  : 1.0
2020-08-18 19:57:53,248 cfg.testing.beam_size              : 5
2020-08-18 19:57:53,248 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 19:57:53,248 cfg.training.batch_multiplier      : 1
2020-08-18 19:57:53,249 cfg.training.batch_size            : 2048
2020-08-18 19:57:53,249 cfg.training.batch_type            : token
2020-08-18 19:57:53,249 cfg.training.decrease_factor       : 0.7
2020-08-18 19:57:53,249 cfg.training.early_stopping_metric : ppl
2020-08-18 19:57:53,249 cfg.training.epochs                : 20
2020-08-18 19:57:53,249 cfg.training.eval_metric           : bleu
2020-08-18 19:57:53,249 cfg.training.keep_last_ckpts       : 3
2020-08-18 19:57:53,249 cfg.training.label_smoothing       : 0.1
2020-08-18 19:57:53,249 cfg.training.learning_rate         : 0.0002
2020-08-18 19:57:53,249 cfg.training.learning_rate_min     : 1e-08
2020-08-18 19:57:53,249 cfg.training.logging_freq          : 100
2020-08-18 19:57:53,249 cfg.training.loss                  : crossentropy
2020-08-18 19:57:53,249 cfg.training.max_output_length     : 100
2020-08-18 19:57:53,249 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_2048_2048_2048_6_8
2020-08-18 19:57:53,249 cfg.training.normalization         : tokens
2020-08-18 19:57:53,249 cfg.training.optimizer             : adam
2020-08-18 19:57:53,249 cfg.training.overwrite             : True
2020-08-18 19:57:53,249 cfg.training.patience              : 8
2020-08-18 19:57:53,249 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 19:57:53,249 cfg.training.random_seed           : 42
2020-08-18 19:57:53,249 cfg.training.scheduling            : plateau
2020-08-18 19:57:53,249 cfg.training.shuffle               : True
2020-08-18 19:57:53,249 cfg.training.use_cuda              : True
2020-08-18 19:57:53,249 cfg.training.validation_freq       : 200
2020-08-18 19:57:53,249 cfg.training.weight_decay          : 0.0
2020-08-18 19:57:53,249 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 19:57:53,249 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 19:57:53,250 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 19:57:53,250 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 19:57:53,250 Number of Src words (types): 3468
2020-08-18 19:57:53,250 Number of Trg words (types): 4487
2020-08-18 19:57:53,251 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=2048, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=2048, vocab_size=4487))
2020-08-18 19:57:53,255 EPOCH 1
2020-08-18 19:58:24,448 Epoch   1: total training loss 290.58
2020-08-18 19:58:24,448 EPOCH 2
2020-08-18 19:58:53,233 Epoch   2 Step:      100 Batch Loss:     6.340784 Tokens per Sec:     2036, Lr: 0.000200
2020-08-18 19:58:55,772 Epoch   2: total training loss 253.71
2020-08-18 19:58:55,772 EPOCH 3
2020-08-18 19:59:26,852 Epoch   3: total training loss 242.50
2020-08-18 19:59:26,852 EPOCH 4
2020-08-18 19:59:53,753 Epoch   4 Step:      200 Batch Loss:     4.861712 Tokens per Sec:     2075, Lr: 0.000200
2020-08-18 20:02:50,323 Hooray! New best validation result [ppl]!
2020-08-18 20:02:50,323 Saving new checkpoint.
2020-08-18 20:03:24,248 Example #0
2020-08-18 20:03:24,248 	Raw source:     ['hello', '.']
2020-08-18 20:03:24,248 	Raw hypothesis: ['removemeimaboundary']
2020-08-18 20:03:24,248 	Source:     hello .
2020-08-18 20:03:24,249 	Reference:  hallo ,
2020-08-18 20:03:24,249 	Hypothesis: removemeimaboundary
2020-08-18 20:03:24,249 Example #1
2020-08-18 20:03:24,249 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 20:03:24,249 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 20:03:24,249 	Source:     hi , how can i help you ?
2020-08-18 20:03:24,249 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 20:03:24,249 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 20:03:24,249 Example #2
2020-08-18 20:03:24,249 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 20:03:24,249 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein']
2020-08-18 20:03:24,249 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 20:03:24,249 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 20:03:24,249 	Hypothesis: hallo , ich möchte ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein
2020-08-18 20:03:24,249 Example #3
2020-08-18 20:03:24,249 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 20:03:24,249 	Raw hypothesis: ['hallo', ',', 'wie', 'sie', '?']
2020-08-18 20:03:24,249 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 20:03:24,250 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 20:03:24,250 	Hypothesis: hallo , wie sie ?
2020-08-18 20:03:24,250 Validation result (greedy) at epoch   4, step      200: bleu:   1.14, loss: 27310.8262, ppl:  71.3300, duration: 210.4964s
2020-08-18 20:03:28,536 Epoch   4: total training loss 213.28
2020-08-18 20:03:28,536 EPOCH 5
2020-08-18 20:03:59,720 Epoch   5: total training loss 203.48
2020-08-18 20:03:59,720 EPOCH 6
2020-08-18 20:04:24,948 Epoch   6 Step:      300 Batch Loss:     2.627954 Tokens per Sec:     2083, Lr: 0.000200
2020-08-18 20:04:30,955 Epoch   6: total training loss 183.60
2020-08-18 20:04:30,955 EPOCH 7
2020-08-18 20:05:02,084 Epoch   7: total training loss 168.87
2020-08-18 20:05:02,085 EPOCH 8
2020-08-18 20:05:25,086 Epoch   8 Step:      400 Batch Loss:     2.796215 Tokens per Sec:     2087, Lr: 0.000200
2020-08-18 20:08:21,693 Hooray! New best validation result [ppl]!
2020-08-18 20:08:21,694 Saving new checkpoint.
2020-08-18 20:08:55,808 Example #0
2020-08-18 20:08:55,808 	Raw source:     ['hello', '.']
2020-08-18 20:08:55,808 	Raw hypothesis: ['hallo', '.']
2020-08-18 20:08:55,808 	Source:     hello .
2020-08-18 20:08:55,809 	Reference:  hallo ,
2020-08-18 20:08:55,809 	Hypothesis: hallo .
2020-08-18 20:08:55,809 Example #1
2020-08-18 20:08:55,809 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 20:08:55,809 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 20:08:55,809 	Source:     hi , how can i help you ?
2020-08-18 20:08:55,809 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 20:08:55,809 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 20:08:55,809 Example #2
2020-08-18 20:08:55,809 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 20:08:55,809 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'einen', 'termin', 'für', 'meinen', 'hallo', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 20:08:55,809 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 20:08:55,809 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 20:08:55,809 	Hypothesis: hallo , ich möchte einen termin für meinen hallo , kalifornien , kalifornien .
2020-08-18 20:08:55,809 Example #3
2020-08-18 20:08:55,809 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 20:08:55,809 	Raw hypothesis: ['okay', ',', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-08-18 20:08:55,809 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 20:08:55,809 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 20:08:55,809 	Hypothesis: okay , welche art von essen möchten sie ?
2020-08-18 20:08:55,809 Validation result (greedy) at epoch   8, step      400: bleu:   4.68, loss: 21429.6094, ppl:  28.4565, duration: 210.7233s
2020-08-18 20:09:03,855 Epoch   8: total training loss 143.40
2020-08-18 20:09:03,855 EPOCH 9
2020-08-18 20:09:34,989 Epoch   9: total training loss 128.25
2020-08-18 20:09:34,990 EPOCH 10
2020-08-18 20:09:55,971 Epoch  10 Step:      500 Batch Loss:     2.601208 Tokens per Sec:     2093, Lr: 0.000200
2020-08-18 20:10:06,309 Epoch  10: total training loss 120.48
2020-08-18 20:10:06,309 EPOCH 11
2020-08-18 20:10:37,392 Epoch  11: total training loss 104.22
2020-08-18 20:10:37,392 EPOCH 12
2020-08-18 20:10:55,318 Epoch  12 Step:      600 Batch Loss:     1.729617 Tokens per Sec:     2071, Lr: 0.000200
2020-08-18 20:13:51,932 Hooray! New best validation result [ppl]!
2020-08-18 20:13:51,933 Saving new checkpoint.
2020-08-18 20:14:29,439 Example #0
2020-08-18 20:14:29,439 	Raw source:     ['hello', '.']
2020-08-18 20:14:29,439 	Raw hypothesis: ['hallo', ',']
2020-08-18 20:14:29,439 	Source:     hello .
2020-08-18 20:14:29,439 	Reference:  hallo ,
2020-08-18 20:14:29,439 	Hypothesis: hallo ,
2020-08-18 20:14:29,440 Example #1
2020-08-18 20:14:29,440 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 20:14:29,440 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 20:14:29,440 	Source:     hi , how can i help you ?
2020-08-18 20:14:29,440 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 20:14:29,440 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 20:14:29,440 Example #2
2020-08-18 20:14:29,440 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 20:14:29,440 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 20:14:29,440 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 20:14:29,440 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 20:14:29,440 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-18 20:14:29,440 Example #3
2020-08-18 20:14:29,440 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 20:14:29,440 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 20:14:29,441 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 20:14:29,441 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 20:14:29,441 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 20:14:29,441 Validation result (greedy) at epoch  12, step      600: bleu:  11.83, loss: 18784.1602, ppl:  18.8220, duration: 214.1222s
2020-08-18 20:14:42,843 Epoch  12: total training loss 87.56
2020-08-18 20:14:42,843 EPOCH 13
2020-08-18 20:15:13,995 Epoch  13: total training loss 73.31
2020-08-18 20:15:13,995 EPOCH 14
2020-08-18 20:15:30,527 Epoch  14 Step:      700 Batch Loss:     1.412158 Tokens per Sec:     2039, Lr: 0.000200
2020-08-18 20:15:45,337 Epoch  14: total training loss 65.88
2020-08-18 20:15:45,338 EPOCH 15
2020-08-18 20:16:16,452 Epoch  15: total training loss 55.37
2020-08-18 20:16:16,452 EPOCH 16
2020-08-18 20:16:30,329 Epoch  16 Step:      800 Batch Loss:     0.871893 Tokens per Sec:     2063, Lr: 0.000200
2020-08-18 20:18:45,459 Hooray! New best validation result [ppl]!
2020-08-18 20:18:45,459 Saving new checkpoint.
2020-08-18 20:19:19,530 Example #0
2020-08-18 20:19:19,530 	Raw source:     ['hello', '.']
2020-08-18 20:19:19,530 	Raw hypothesis: ['hallo', '.']
2020-08-18 20:19:19,530 	Source:     hello .
2020-08-18 20:19:19,530 	Reference:  hallo ,
2020-08-18 20:19:19,530 	Hypothesis: hallo .
2020-08-18 20:19:19,530 Example #1
2020-08-18 20:19:19,530 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 20:19:19,530 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 20:19:19,530 	Source:     hi , how can i help you ?
2020-08-18 20:19:19,530 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 20:19:19,531 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 20:19:19,531 Example #2
2020-08-18 20:19:19,531 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 20:19:19,531 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'finden', '.']
2020-08-18 20:19:19,531 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 20:19:19,531 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 20:19:19,531 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien , in san francisco , kalifornien , finden .
2020-08-18 20:19:19,531 Example #3
2020-08-18 20:19:19,531 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 20:19:19,531 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 20:19:19,531 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 20:19:19,531 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 20:19:19,531 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 20:19:19,531 Validation result (greedy) at epoch  16, step      800: bleu:  19.32, loss: 17815.5859, ppl:  16.1785, duration: 169.2020s
2020-08-18 20:19:36,708 Epoch  16: total training loss 47.04
2020-08-18 20:19:36,708 EPOCH 17
2020-08-18 20:20:07,779 Epoch  17: total training loss 41.62
2020-08-18 20:20:07,779 EPOCH 18
2020-08-18 20:20:19,102 Epoch  18 Step:      900 Batch Loss:     0.553086 Tokens per Sec:     2064, Lr: 0.000200
2020-08-18 20:20:39,273 Epoch  18: total training loss 38.26
2020-08-18 20:20:39,273 EPOCH 19
2020-08-18 20:21:10,406 Epoch  19: total training loss 34.27
2020-08-18 20:21:10,406 EPOCH 20
2020-08-18 20:21:18,996 Epoch  20 Step:     1000 Batch Loss:     0.277253 Tokens per Sec:     2090, Lr: 0.000200
2020-08-18 20:23:22,018 Hooray! New best validation result [ppl]!
2020-08-18 20:23:22,018 Saving new checkpoint.
2020-08-18 20:23:56,707 Example #0
2020-08-18 20:23:56,707 	Raw source:     ['hello', '.']
2020-08-18 20:23:56,707 	Raw hypothesis: ['hallo', '.']
2020-08-18 20:23:56,707 	Source:     hello .
2020-08-18 20:23:56,707 	Reference:  hallo ,
2020-08-18 20:23:56,707 	Hypothesis: hallo .
2020-08-18 20:23:56,707 Example #1
2020-08-18 20:23:56,707 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 20:23:56,707 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 20:23:56,707 	Source:     hi , how can i help you ?
2020-08-18 20:23:56,707 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 20:23:56,707 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 20:23:56,707 Example #2
2020-08-18 20:23:56,707 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 20:23:56,708 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 20:23:56,708 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 20:23:56,708 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 20:23:56,708 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien .
2020-08-18 20:23:56,708 Example #3
2020-08-18 20:23:56,708 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 20:23:56,708 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', 'abgesehen', 'vom', 'restaurant', 'suchen', '?']
2020-08-18 20:23:56,708 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 20:23:56,708 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 20:23:56,708 	Hypothesis: ok , nach welcher art von restaurant suchen sie abgesehen vom restaurant suchen ?
2020-08-18 20:23:56,708 Validation result (greedy) at epoch  20, step     1000: bleu:  20.83, loss: 17800.0117, ppl:  16.1392, duration: 157.7113s
2020-08-18 20:24:19,554 Epoch  20: total training loss 31.73
2020-08-18 20:24:19,554 Training ended after  20 epochs.
2020-08-18 20:24:19,554 Best validation result (greedy) at step     1000:  16.14 ppl.

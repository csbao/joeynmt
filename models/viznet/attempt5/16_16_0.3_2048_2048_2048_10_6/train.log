2020-08-18 18:10:26,001 Hello! This is Joey-NMT.
2020-08-18 18:10:29,267 Total params: 343756800
2020-08-18 18:10:29,269 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 18:10:33,635 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 18:10:33,635 cfg.data.level                     : bpe
2020-08-18 18:10:33,635 cfg.data.lowercase                 : False
2020-08-18 18:10:33,635 cfg.data.max_sent_length           : 100
2020-08-18 18:10:33,635 cfg.data.src                       : en
2020-08-18 18:10:33,635 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 18:10:33,635 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 18:10:33,636 cfg.data.trg                       : de
2020-08-18 18:10:33,636 cfg.model.bias_initializer         : zeros
2020-08-18 18:10:33,636 cfg.model.decoder.dropout          : 0.1
2020-08-18 18:10:33,636 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 18:10:33,636 cfg.model.decoder.embeddings.embedding_dim : 2048
2020-08-18 18:10:33,636 cfg.model.decoder.embeddings.scale : True
2020-08-18 18:10:33,636 cfg.model.decoder.ff_size          : 512
2020-08-18 18:10:33,636 cfg.model.decoder.freeze           : False
2020-08-18 18:10:33,636 cfg.model.decoder.hidden_size      : 2048
2020-08-18 18:10:33,636 cfg.model.decoder.num_heads        : 16
2020-08-18 18:10:33,636 cfg.model.decoder.num_layers       : 6
2020-08-18 18:10:33,636 cfg.model.decoder.type             : transformer
2020-08-18 18:10:33,636 cfg.model.embed_init_gain          : 1.0
2020-08-18 18:10:33,636 cfg.model.embed_initializer        : xavier
2020-08-18 18:10:33,636 cfg.model.encoder.dropout          : 0.3
2020-08-18 18:10:33,636 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 18:10:33,636 cfg.model.encoder.embeddings.embedding_dim : 2048
2020-08-18 18:10:33,636 cfg.model.encoder.embeddings.scale : True
2020-08-18 18:10:33,636 cfg.model.encoder.ff_size          : 512
2020-08-18 18:10:33,636 cfg.model.encoder.freeze           : False
2020-08-18 18:10:33,636 cfg.model.encoder.hidden_size      : 2048
2020-08-18 18:10:33,636 cfg.model.encoder.multi_encoder    : False
2020-08-18 18:10:33,636 cfg.model.encoder.num_heads        : 16
2020-08-18 18:10:33,636 cfg.model.encoder.num_layers       : 6
2020-08-18 18:10:33,636 cfg.model.encoder.type             : transformer
2020-08-18 18:10:33,636 cfg.model.init_gain                : 1.0
2020-08-18 18:10:33,636 cfg.model.initializer              : xavier
2020-08-18 18:10:33,636 cfg.model.tied_embeddings          : False
2020-08-18 18:10:33,636 cfg.model.tied_softmax             : True
2020-08-18 18:10:33,637 cfg.name                           : transformer
2020-08-18 18:10:33,637 cfg.testing.alpha                  : 1.0
2020-08-18 18:10:33,637 cfg.testing.beam_size              : 5
2020-08-18 18:10:33,637 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 18:10:33,637 cfg.training.batch_multiplier      : 1
2020-08-18 18:10:33,637 cfg.training.batch_size            : 2048
2020-08-18 18:10:33,637 cfg.training.batch_type            : token
2020-08-18 18:10:33,637 cfg.training.decrease_factor       : 0.7
2020-08-18 18:10:33,637 cfg.training.early_stopping_metric : ppl
2020-08-18 18:10:33,637 cfg.training.epochs                : 20
2020-08-18 18:10:33,637 cfg.training.eval_metric           : bleu
2020-08-18 18:10:33,637 cfg.training.keep_last_ckpts       : 3
2020-08-18 18:10:33,637 cfg.training.label_smoothing       : 0.1
2020-08-18 18:10:33,637 cfg.training.learning_rate         : 0.0002
2020-08-18 18:10:33,637 cfg.training.learning_rate_min     : 1e-08
2020-08-18 18:10:33,637 cfg.training.logging_freq          : 100
2020-08-18 18:10:33,637 cfg.training.loss                  : crossentropy
2020-08-18 18:10:33,637 cfg.training.max_output_length     : 100
2020-08-18 18:10:33,637 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_2048_2048_2048_10_6
2020-08-18 18:10:33,637 cfg.training.normalization         : tokens
2020-08-18 18:10:33,637 cfg.training.optimizer             : adam
2020-08-18 18:10:33,637 cfg.training.overwrite             : True
2020-08-18 18:10:33,637 cfg.training.patience              : 8
2020-08-18 18:10:33,637 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 18:10:33,637 cfg.training.random_seed           : 42
2020-08-18 18:10:33,637 cfg.training.scheduling            : plateau
2020-08-18 18:10:33,637 cfg.training.shuffle               : True
2020-08-18 18:10:33,637 cfg.training.use_cuda              : True
2020-08-18 18:10:33,637 cfg.training.validation_freq       : 200
2020-08-18 18:10:33,638 cfg.training.weight_decay          : 0.0
2020-08-18 18:10:33,638 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 18:10:33,638 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 18:10:33,638 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 18:10:33,638 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 18:10:33,638 Number of Src words (types): 3468
2020-08-18 18:10:33,639 Number of Trg words (types): 4487
2020-08-18 18:10:33,639 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=2048, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=2048, vocab_size=4487))
2020-08-18 18:10:33,643 EPOCH 1
2020-08-18 18:11:04,837 Epoch   1: total training loss 290.58
2020-08-18 18:11:04,838 EPOCH 2
2020-08-18 18:11:33,627 Epoch   2 Step:      100 Batch Loss:     6.340784 Tokens per Sec:     2036, Lr: 0.000200
2020-08-18 18:11:36,168 Epoch   2: total training loss 253.71
2020-08-18 18:11:36,169 EPOCH 3
2020-08-18 18:12:07,264 Epoch   3: total training loss 242.50
2020-08-18 18:12:07,264 EPOCH 4
2020-08-18 18:12:34,158 Epoch   4 Step:      200 Batch Loss:     4.861712 Tokens per Sec:     2076, Lr: 0.000200
2020-08-18 18:15:31,074 Hooray! New best validation result [ppl]!
2020-08-18 18:15:31,075 Saving new checkpoint.
2020-08-18 18:16:05,569 Example #0
2020-08-18 18:16:05,569 	Raw source:     ['hello', '.']
2020-08-18 18:16:05,569 	Raw hypothesis: ['removemeimaboundary']
2020-08-18 18:16:05,569 	Source:     hello .
2020-08-18 18:16:05,569 	Reference:  hallo ,
2020-08-18 18:16:05,569 	Hypothesis: removemeimaboundary
2020-08-18 18:16:05,569 Example #1
2020-08-18 18:16:05,569 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:16:05,570 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 18:16:05,570 	Source:     hi , how can i help you ?
2020-08-18 18:16:05,570 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:16:05,570 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 18:16:05,570 Example #2
2020-08-18 18:16:05,570 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:16:05,570 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein']
2020-08-18 18:16:05,570 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:16:05,570 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:16:05,570 	Hypothesis: hallo , ich möchte ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein
2020-08-18 18:16:05,570 Example #3
2020-08-18 18:16:05,570 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:16:05,570 	Raw hypothesis: ['hallo', ',', 'wie', 'sie', '?']
2020-08-18 18:16:05,570 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:16:05,570 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:16:05,570 	Hypothesis: hallo , wie sie ?
2020-08-18 18:16:05,570 Validation result (greedy) at epoch   4, step      200: bleu:   1.14, loss: 27310.8262, ppl:  71.3300, duration: 211.4119s
2020-08-18 18:16:09,880 Epoch   4: total training loss 213.28
2020-08-18 18:16:09,880 EPOCH 5
2020-08-18 18:16:41,085 Epoch   5: total training loss 203.48
2020-08-18 18:16:41,085 EPOCH 6
2020-08-18 18:17:06,325 Epoch   6 Step:      300 Batch Loss:     2.627954 Tokens per Sec:     2082, Lr: 0.000200
2020-08-18 18:17:12,337 Epoch   6: total training loss 183.60
2020-08-18 18:17:12,337 EPOCH 7
2020-08-18 18:17:43,470 Epoch   7: total training loss 168.87
2020-08-18 18:17:43,470 EPOCH 8
2020-08-18 18:18:06,478 Epoch   8 Step:      400 Batch Loss:     2.796215 Tokens per Sec:     2087, Lr: 0.000200
2020-08-18 18:21:03,441 Hooray! New best validation result [ppl]!
2020-08-18 18:21:03,441 Saving new checkpoint.
2020-08-18 18:21:37,629 Example #0
2020-08-18 18:21:37,629 	Raw source:     ['hello', '.']
2020-08-18 18:21:37,629 	Raw hypothesis: ['hallo', '.']
2020-08-18 18:21:37,629 	Source:     hello .
2020-08-18 18:21:37,629 	Reference:  hallo ,
2020-08-18 18:21:37,629 	Hypothesis: hallo .
2020-08-18 18:21:37,629 Example #1
2020-08-18 18:21:37,629 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:21:37,629 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 18:21:37,629 	Source:     hi , how can i help you ?
2020-08-18 18:21:37,629 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:21:37,630 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 18:21:37,630 Example #2
2020-08-18 18:21:37,630 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:21:37,630 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'einen', 'termin', 'für', 'meinen', 'hallo', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 18:21:37,630 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:21:37,630 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:21:37,630 	Hypothesis: hallo , ich möchte einen termin für meinen hallo , kalifornien , kalifornien .
2020-08-18 18:21:37,630 Example #3
2020-08-18 18:21:37,630 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:21:37,630 	Raw hypothesis: ['okay', ',', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-08-18 18:21:37,630 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:21:37,630 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:21:37,630 	Hypothesis: okay , welche art von essen möchten sie ?
2020-08-18 18:21:37,630 Validation result (greedy) at epoch   8, step      400: bleu:   4.68, loss: 21429.6094, ppl:  28.4565, duration: 211.1521s
2020-08-18 18:21:45,674 Epoch   8: total training loss 143.40
2020-08-18 18:21:45,674 EPOCH 9
2020-08-18 18:22:16,817 Epoch   9: total training loss 128.25
2020-08-18 18:22:16,818 EPOCH 10
2020-08-18 18:22:37,801 Epoch  10 Step:      500 Batch Loss:     2.601208 Tokens per Sec:     2093, Lr: 0.000200
2020-08-18 18:22:48,136 Epoch  10: total training loss 120.48
2020-08-18 18:22:48,137 EPOCH 11
2020-08-18 18:23:19,227 Epoch  11: total training loss 104.22
2020-08-18 18:23:19,227 EPOCH 12
2020-08-18 18:23:37,164 Epoch  12 Step:      600 Batch Loss:     1.729617 Tokens per Sec:     2069, Lr: 0.000200
2020-08-18 18:26:34,151 Hooray! New best validation result [ppl]!
2020-08-18 18:26:34,151 Saving new checkpoint.
2020-08-18 18:27:10,589 Example #0
2020-08-18 18:27:10,589 	Raw source:     ['hello', '.']
2020-08-18 18:27:10,589 	Raw hypothesis: ['hallo', ',']
2020-08-18 18:27:10,589 	Source:     hello .
2020-08-18 18:27:10,590 	Reference:  hallo ,
2020-08-18 18:27:10,590 	Hypothesis: hallo ,
2020-08-18 18:27:10,590 Example #1
2020-08-18 18:27:10,590 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:27:10,590 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 18:27:10,590 	Source:     hi , how can i help you ?
2020-08-18 18:27:10,590 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:27:10,590 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 18:27:10,590 Example #2
2020-08-18 18:27:10,590 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:27:10,590 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 18:27:10,590 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:27:10,590 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:27:10,590 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-18 18:27:10,590 Example #3
2020-08-18 18:27:10,590 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:27:10,590 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 18:27:10,590 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:27:10,591 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:27:10,591 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 18:27:10,591 Validation result (greedy) at epoch  12, step      600: bleu:  11.83, loss: 18784.1602, ppl:  18.8220, duration: 213.4259s
2020-08-18 18:27:23,998 Epoch  12: total training loss 87.56
2020-08-18 18:27:23,998 EPOCH 13
2020-08-18 18:27:55,156 Epoch  13: total training loss 73.31
2020-08-18 18:27:55,156 EPOCH 14
2020-08-18 18:28:11,696 Epoch  14 Step:      700 Batch Loss:     1.412158 Tokens per Sec:     2038, Lr: 0.000200
2020-08-18 18:28:26,509 Epoch  14: total training loss 65.88
2020-08-18 18:28:26,510 EPOCH 15
2020-08-18 18:28:57,630 Epoch  15: total training loss 55.37
2020-08-18 18:28:57,631 EPOCH 16
2020-08-18 18:29:11,514 Epoch  16 Step:      800 Batch Loss:     0.871893 Tokens per Sec:     2063, Lr: 0.000200
2020-08-18 18:31:26,905 Hooray! New best validation result [ppl]!
2020-08-18 18:31:26,905 Saving new checkpoint.
2020-08-18 18:32:01,365 Example #0
2020-08-18 18:32:01,365 	Raw source:     ['hello', '.']
2020-08-18 18:32:01,365 	Raw hypothesis: ['hallo', '.']
2020-08-18 18:32:01,365 	Source:     hello .
2020-08-18 18:32:01,365 	Reference:  hallo ,
2020-08-18 18:32:01,365 	Hypothesis: hallo .
2020-08-18 18:32:01,365 Example #1
2020-08-18 18:32:01,366 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:32:01,366 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 18:32:01,366 	Source:     hi , how can i help you ?
2020-08-18 18:32:01,366 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:32:01,366 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 18:32:01,366 Example #2
2020-08-18 18:32:01,366 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:32:01,366 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'finden', '.']
2020-08-18 18:32:01,366 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:32:01,366 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:32:01,366 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien , in san francisco , kalifornien , finden .
2020-08-18 18:32:01,366 Example #3
2020-08-18 18:32:01,366 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:32:01,366 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 18:32:01,366 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:32:01,366 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:32:01,366 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 18:32:01,366 Validation result (greedy) at epoch  16, step      800: bleu:  19.32, loss: 17815.5859, ppl:  16.1785, duration: 169.8522s
2020-08-18 18:32:18,545 Epoch  16: total training loss 47.04
2020-08-18 18:32:18,545 EPOCH 17
2020-08-18 18:32:49,626 Epoch  17: total training loss 41.62
2020-08-18 18:32:49,627 EPOCH 18
2020-08-18 18:33:00,950 Epoch  18 Step:      900 Batch Loss:     0.553086 Tokens per Sec:     2064, Lr: 0.000200
2020-08-18 18:33:21,121 Epoch  18: total training loss 38.26
2020-08-18 18:33:21,121 EPOCH 19
2020-08-18 18:33:52,274 Epoch  19: total training loss 34.27
2020-08-18 18:33:52,274 EPOCH 20
2020-08-18 18:34:00,867 Epoch  20 Step:     1000 Batch Loss:     0.277253 Tokens per Sec:     2089, Lr: 0.000200
2020-08-18 18:36:04,128 Hooray! New best validation result [ppl]!
2020-08-18 18:36:04,128 Saving new checkpoint.
2020-08-18 18:36:40,663 Example #0
2020-08-18 18:36:40,664 	Raw source:     ['hello', '.']
2020-08-18 18:36:40,664 	Raw hypothesis: ['hallo', '.']
2020-08-18 18:36:40,664 	Source:     hello .
2020-08-18 18:36:40,664 	Reference:  hallo ,
2020-08-18 18:36:40,664 	Hypothesis: hallo .
2020-08-18 18:36:40,664 Example #1
2020-08-18 18:36:40,664 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:36:40,664 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 18:36:40,664 	Source:     hi , how can i help you ?
2020-08-18 18:36:40,664 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:36:40,664 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 18:36:40,664 Example #2
2020-08-18 18:36:40,664 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:36:40,664 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 18:36:40,664 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:36:40,664 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:36:40,664 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien .
2020-08-18 18:36:40,665 Example #3
2020-08-18 18:36:40,665 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:36:40,665 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', 'abgesehen', 'vom', 'restaurant', 'suchen', '?']
2020-08-18 18:36:40,665 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:36:40,665 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:36:40,665 	Hypothesis: ok , nach welcher art von restaurant suchen sie abgesehen vom restaurant suchen ?
2020-08-18 18:36:40,665 Validation result (greedy) at epoch  20, step     1000: bleu:  20.83, loss: 17800.0117, ppl:  16.1392, duration: 159.7971s
2020-08-18 18:37:03,508 Epoch  20: total training loss 31.73
2020-08-18 18:37:03,508 Training ended after  20 epochs.
2020-08-18 18:37:03,508 Best validation result (greedy) at step     1000:  16.14 ppl.

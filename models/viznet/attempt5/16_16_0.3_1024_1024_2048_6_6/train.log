2020-08-18 17:02:18,508 Hello! This is Joey-NMT.
2020-08-18 17:02:19,898 Total params: 96384000
2020-08-18 17:02:19,900 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 17:02:23,954 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 17:02:23,955 cfg.data.level                     : bpe
2020-08-18 17:02:23,955 cfg.data.lowercase                 : False
2020-08-18 17:02:23,955 cfg.data.max_sent_length           : 100
2020-08-18 17:02:23,955 cfg.data.src                       : en
2020-08-18 17:02:23,955 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 17:02:23,955 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 17:02:23,955 cfg.data.trg                       : de
2020-08-18 17:02:23,955 cfg.model.bias_initializer         : zeros
2020-08-18 17:02:23,955 cfg.model.decoder.dropout          : 0.1
2020-08-18 17:02:23,955 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 17:02:23,955 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-18 17:02:23,955 cfg.model.decoder.embeddings.scale : True
2020-08-18 17:02:23,955 cfg.model.decoder.ff_size          : 512
2020-08-18 17:02:23,955 cfg.model.decoder.freeze           : False
2020-08-18 17:02:23,955 cfg.model.decoder.hidden_size      : 1024
2020-08-18 17:02:23,956 cfg.model.decoder.num_heads        : 16
2020-08-18 17:02:23,956 cfg.model.decoder.num_layers       : 6
2020-08-18 17:02:23,956 cfg.model.decoder.type             : transformer
2020-08-18 17:02:23,956 cfg.model.embed_init_gain          : 1.0
2020-08-18 17:02:23,956 cfg.model.embed_initializer        : xavier
2020-08-18 17:02:23,956 cfg.model.encoder.dropout          : 0.3
2020-08-18 17:02:23,956 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 17:02:23,956 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-18 17:02:23,956 cfg.model.encoder.embeddings.scale : True
2020-08-18 17:02:23,956 cfg.model.encoder.ff_size          : 512
2020-08-18 17:02:23,956 cfg.model.encoder.freeze           : False
2020-08-18 17:02:23,956 cfg.model.encoder.hidden_size      : 1024
2020-08-18 17:02:23,956 cfg.model.encoder.multi_encoder    : False
2020-08-18 17:02:23,956 cfg.model.encoder.num_heads        : 16
2020-08-18 17:02:23,956 cfg.model.encoder.num_layers       : 6
2020-08-18 17:02:23,957 cfg.model.encoder.type             : transformer
2020-08-18 17:02:23,957 cfg.model.init_gain                : 1.0
2020-08-18 17:02:23,957 cfg.model.initializer              : xavier
2020-08-18 17:02:23,957 cfg.model.tied_embeddings          : False
2020-08-18 17:02:23,957 cfg.model.tied_softmax             : True
2020-08-18 17:02:23,957 cfg.name                           : transformer
2020-08-18 17:02:23,957 cfg.testing.alpha                  : 1.0
2020-08-18 17:02:23,957 cfg.testing.beam_size              : 5
2020-08-18 17:02:23,957 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 17:02:23,957 cfg.training.batch_multiplier      : 1
2020-08-18 17:02:23,957 cfg.training.batch_size            : 2048
2020-08-18 17:02:23,957 cfg.training.batch_type            : token
2020-08-18 17:02:23,957 cfg.training.decrease_factor       : 0.7
2020-08-18 17:02:23,957 cfg.training.early_stopping_metric : ppl
2020-08-18 17:02:23,957 cfg.training.epochs                : 20
2020-08-18 17:02:23,957 cfg.training.eval_metric           : bleu
2020-08-18 17:02:23,958 cfg.training.keep_last_ckpts       : 3
2020-08-18 17:02:23,958 cfg.training.label_smoothing       : 0.1
2020-08-18 17:02:23,958 cfg.training.learning_rate         : 0.0002
2020-08-18 17:02:23,958 cfg.training.learning_rate_min     : 1e-08
2020-08-18 17:02:23,958 cfg.training.logging_freq          : 100
2020-08-18 17:02:23,958 cfg.training.loss                  : crossentropy
2020-08-18 17:02:23,958 cfg.training.max_output_length     : 100
2020-08-18 17:02:23,958 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_1024_1024_2048_6_6
2020-08-18 17:02:23,958 cfg.training.normalization         : tokens
2020-08-18 17:02:23,958 cfg.training.optimizer             : adam
2020-08-18 17:02:23,958 cfg.training.overwrite             : True
2020-08-18 17:02:23,958 cfg.training.patience              : 8
2020-08-18 17:02:23,958 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 17:02:23,958 cfg.training.random_seed           : 42
2020-08-18 17:02:23,958 cfg.training.scheduling            : plateau
2020-08-18 17:02:23,959 cfg.training.shuffle               : True
2020-08-18 17:02:23,959 cfg.training.use_cuda              : True
2020-08-18 17:02:23,959 cfg.training.validation_freq       : 200
2020-08-18 17:02:23,959 cfg.training.weight_decay          : 0.0
2020-08-18 17:02:23,959 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 17:02:23,959 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 17:02:23,959 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 17:02:23,960 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 17:02:23,960 Number of Src words (types): 3468
2020-08-18 17:02:23,960 Number of Trg words (types): 4487
2020-08-18 17:02:23,960 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-18 17:02:23,965 EPOCH 1
2020-08-18 17:02:35,637 Epoch   1: total training loss 275.72
2020-08-18 17:02:35,637 EPOCH 2
2020-08-18 17:02:46,397 Epoch   2 Step:      100 Batch Loss:     5.843812 Tokens per Sec:     5447, Lr: 0.000200
2020-08-18 17:02:47,343 Epoch   2: total training loss 238.18
2020-08-18 17:02:47,343 EPOCH 3
2020-08-18 17:02:58,963 Epoch   3: total training loss 215.45
2020-08-18 17:02:58,963 EPOCH 4
2020-08-18 17:03:08,975 Epoch   4 Step:      200 Batch Loss:     4.359450 Tokens per Sec:     5576, Lr: 0.000200
2020-08-18 17:04:12,137 Hooray! New best validation result [ppl]!
2020-08-18 17:04:12,137 Saving new checkpoint.
2020-08-18 17:04:17,145 Example #0
2020-08-18 17:04:17,145 	Raw source:     ['hello', '.']
2020-08-18 17:04:17,145 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:04:17,145 	Source:     hello .
2020-08-18 17:04:17,145 	Reference:  hallo ,
2020-08-18 17:04:17,145 	Hypothesis: hallo .
2020-08-18 17:04:17,145 Example #1
2020-08-18 17:04:17,145 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:04:17,145 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:04:17,145 	Source:     hi , how can i help you ?
2020-08-18 17:04:17,146 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:04:17,146 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:04:17,146 Example #2
2020-08-18 17:04:17,146 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:04:17,146 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2020-08-18 17:04:17,146 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:04:17,146 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:04:17,146 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der der der der der der der der der der der der der der der der der der
2020-08-18 17:04:17,146 Example #3
2020-08-18 17:04:17,146 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:04:17,146 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von']
2020-08-18 17:04:17,146 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:04:17,146 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:04:17,146 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von
2020-08-18 17:04:17,146 Validation result (greedy) at epoch   4, step      200: bleu:   1.76, loss: 24026.3262, ppl:  42.6964, duration: 68.1708s
2020-08-18 17:04:18,779 Epoch   4: total training loss 184.13
2020-08-18 17:04:18,779 EPOCH 5
2020-08-18 17:04:30,411 Epoch   5: total training loss 166.88
2020-08-18 17:04:30,411 EPOCH 6
2020-08-18 17:04:39,863 Epoch   6 Step:      300 Batch Loss:     1.843859 Tokens per Sec:     5559, Lr: 0.000200
2020-08-18 17:04:42,103 Epoch   6: total training loss 138.81
2020-08-18 17:04:42,103 EPOCH 7
2020-08-18 17:04:53,713 Epoch   7: total training loss 127.27
2020-08-18 17:04:53,713 EPOCH 8
2020-08-18 17:05:02,306 Epoch   8 Step:      400 Batch Loss:     2.046960 Tokens per Sec:     5588, Lr: 0.000200
2020-08-18 17:06:01,742 Hooray! New best validation result [ppl]!
2020-08-18 17:06:01,742 Saving new checkpoint.
2020-08-18 17:06:06,965 Example #0
2020-08-18 17:06:06,965 	Raw source:     ['hello', '.']
2020-08-18 17:06:06,965 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:06:06,965 	Source:     hello .
2020-08-18 17:06:06,966 	Reference:  hallo ,
2020-08-18 17:06:06,966 	Hypothesis: hallo .
2020-08-18 17:06:06,966 Example #1
2020-08-18 17:06:06,966 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:06:06,966 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:06:06,966 	Source:     hi , how can i help you ?
2020-08-18 17:06:06,966 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:06:06,966 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:06:06,966 Example #2
2020-08-18 17:06:06,966 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:06:06,966 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:06:06,966 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:06:06,966 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:06:06,966 	Hypothesis: hallo , ich bin in sacramento , kalifornien , kalifornien , kalifornien in der arden fair mall .
2020-08-18 17:06:06,966 Example #3
2020-08-18 17:06:06,966 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:06:06,966 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-08-18 17:06:06,966 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:06:06,966 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:06:06,966 	Hypothesis: ok , welche art von restaurant für sie ?
2020-08-18 17:06:06,966 Validation result (greedy) at epoch   8, step      400: bleu:  12.12, loss: 17894.2324, ppl:  16.3786, duration: 64.6598s
2020-08-18 17:06:09,993 Epoch   8: total training loss 107.96
2020-08-18 17:06:09,993 EPOCH 9
2020-08-18 17:06:21,636 Epoch   9: total training loss 96.02
2020-08-18 17:06:21,636 EPOCH 10
2020-08-18 17:06:29,450 Epoch  10 Step:      500 Batch Loss:     2.032404 Tokens per Sec:     5622, Lr: 0.000200
2020-08-18 17:06:33,315 Epoch  10: total training loss 91.57
2020-08-18 17:06:33,316 EPOCH 11
2020-08-18 17:06:44,939 Epoch  11: total training loss 80.18
2020-08-18 17:06:44,939 EPOCH 12
2020-08-18 17:06:51,643 Epoch  12 Step:      600 Batch Loss:     1.372831 Tokens per Sec:     5538, Lr: 0.000200
2020-08-18 17:07:29,003 Hooray! New best validation result [ppl]!
2020-08-18 17:07:29,004 Saving new checkpoint.
2020-08-18 17:07:33,966 Example #0
2020-08-18 17:07:33,966 	Raw source:     ['hello', '.']
2020-08-18 17:07:33,966 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:07:33,966 	Source:     hello .
2020-08-18 17:07:33,966 	Reference:  hallo ,
2020-08-18 17:07:33,966 	Hypothesis: hallo .
2020-08-18 17:07:33,966 Example #1
2020-08-18 17:07:33,966 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:07:33,966 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:07:33,966 	Source:     hi , how can i help you ?
2020-08-18 17:07:33,966 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:07:33,966 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:07:33,967 Example #2
2020-08-18 17:07:33,967 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:07:33,967 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 17:07:33,967 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:07:33,967 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:07:33,967 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien in san francisco , kalifornien in san francisco , kalifornien .
2020-08-18 17:07:33,967 Example #3
2020-08-18 17:07:33,967 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:07:33,967 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:07:33,967 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:07:33,967 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:07:33,967 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:07:33,967 Validation result (greedy) at epoch  12, step      600: bleu:  23.63, loss: 16627.6602, ppl:  13.4378, duration: 42.3240s
2020-08-18 17:07:38,987 Epoch  12: total training loss 69.67
2020-08-18 17:07:38,987 EPOCH 13
2020-08-18 17:07:50,617 Epoch  13: total training loss 58.24
2020-08-18 17:07:50,617 EPOCH 14
2020-08-18 17:07:56,781 Epoch  14 Step:      700 Batch Loss:     1.082558 Tokens per Sec:     5468, Lr: 0.000200
2020-08-18 17:08:02,298 Epoch  14: total training loss 50.53
2020-08-18 17:08:02,299 EPOCH 15
2020-08-18 17:08:13,933 Epoch  15: total training loss 43.78
2020-08-18 17:08:13,934 EPOCH 16
2020-08-18 17:08:19,092 Epoch  16 Step:      800 Batch Loss:     0.655878 Tokens per Sec:     5552, Lr: 0.000200
2020-08-18 17:09:11,462 Hooray! New best validation result [ppl]!
2020-08-18 17:09:11,463 Saving new checkpoint.
2020-08-18 17:09:16,416 Example #0
2020-08-18 17:09:16,416 	Raw source:     ['hello', '.']
2020-08-18 17:09:16,416 	Raw hypothesis: ['hallo']
2020-08-18 17:09:16,416 	Source:     hello .
2020-08-18 17:09:16,416 	Reference:  hallo ,
2020-08-18 17:09:16,416 	Hypothesis: hallo
2020-08-18 17:09:16,416 Example #1
2020-08-18 17:09:16,416 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:09:16,416 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:09:16,416 	Source:     hi , how can i help you ?
2020-08-18 17:09:16,417 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:09:16,417 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:09:16,417 Example #2
2020-08-18 17:09:16,417 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:09:16,417 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:09:16,417 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:09:16,417 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:09:16,417 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:09:16,417 Example #3
2020-08-18 17:09:16,417 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:09:16,417 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:09:16,417 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:09:16,417 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:09:16,417 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:09:16,417 Validation result (greedy) at epoch  16, step      800: bleu:  24.36, loss: 15877.6338, ppl:  11.9518, duration: 57.3244s
2020-08-18 17:09:22,854 Epoch  16: total training loss 38.23
2020-08-18 17:09:22,854 EPOCH 17
2020-08-18 17:09:34,459 Epoch  17: total training loss 33.75
2020-08-18 17:09:34,459 EPOCH 18
2020-08-18 17:09:38,693 Epoch  18 Step:      900 Batch Loss:     0.425437 Tokens per Sec:     5522, Lr: 0.000200
2020-08-18 17:09:46,190 Epoch  18: total training loss 30.37
2020-08-18 17:09:46,190 EPOCH 19
2020-08-18 17:09:57,830 Epoch  19: total training loss 27.66
2020-08-18 17:09:57,830 EPOCH 20
2020-08-18 17:10:01,032 Epoch  20 Step:     1000 Batch Loss:     0.161490 Tokens per Sec:     5608, Lr: 0.000200
2020-08-18 17:10:18,510 Example #0
2020-08-18 17:10:18,510 	Raw source:     ['hello', '.']
2020-08-18 17:10:18,510 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:10:18,510 	Source:     hello .
2020-08-18 17:10:18,510 	Reference:  hallo ,
2020-08-18 17:10:18,510 	Hypothesis: hallo .
2020-08-18 17:10:18,510 Example #1
2020-08-18 17:10:18,510 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:10:18,510 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:10:18,510 	Source:     hi , how can i help you ?
2020-08-18 17:10:18,510 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:10:18,510 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:10:18,510 Example #2
2020-08-18 17:10:18,510 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:10:18,510 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:10:18,510 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:10:18,510 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:10:18,510 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:10:18,510 Example #3
2020-08-18 17:10:18,510 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:10:18,510 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:10:18,511 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:10:18,511 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:10:18,511 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:10:18,511 Validation result (greedy) at epoch  20, step     1000: bleu:  31.74, loss: 15943.3701, ppl:  12.0752, duration: 17.4782s
2020-08-18 17:10:27,071 Epoch  20: total training loss 25.11
2020-08-18 17:10:27,072 Training ended after  20 epochs.
2020-08-18 17:10:27,072 Best validation result (greedy) at step      800:  11.95 ppl.

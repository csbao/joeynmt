2020-08-18 16:54:07,030 Hello! This is Joey-NMT.
2020-08-18 16:54:08,393 Total params: 96384000
2020-08-18 16:54:08,394 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 16:54:12,313 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 16:54:12,314 cfg.data.level                     : bpe
2020-08-18 16:54:12,314 cfg.data.lowercase                 : False
2020-08-18 16:54:12,314 cfg.data.max_sent_length           : 100
2020-08-18 16:54:12,314 cfg.data.src                       : en
2020-08-18 16:54:12,314 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 16:54:12,314 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 16:54:12,314 cfg.data.trg                       : de
2020-08-18 16:54:12,314 cfg.model.bias_initializer         : zeros
2020-08-18 16:54:12,314 cfg.model.decoder.dropout          : 0.1
2020-08-18 16:54:12,314 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 16:54:12,314 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-18 16:54:12,314 cfg.model.decoder.embeddings.scale : True
2020-08-18 16:54:12,314 cfg.model.decoder.ff_size          : 512
2020-08-18 16:54:12,314 cfg.model.decoder.freeze           : False
2020-08-18 16:54:12,314 cfg.model.decoder.hidden_size      : 1024
2020-08-18 16:54:12,314 cfg.model.decoder.num_heads        : 16
2020-08-18 16:54:12,314 cfg.model.decoder.num_layers       : 6
2020-08-18 16:54:12,314 cfg.model.decoder.type             : transformer
2020-08-18 16:54:12,314 cfg.model.embed_init_gain          : 1.0
2020-08-18 16:54:12,314 cfg.model.embed_initializer        : xavier
2020-08-18 16:54:12,314 cfg.model.encoder.dropout          : 0.3
2020-08-18 16:54:12,314 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 16:54:12,315 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-18 16:54:12,315 cfg.model.encoder.embeddings.scale : True
2020-08-18 16:54:12,315 cfg.model.encoder.ff_size          : 512
2020-08-18 16:54:12,315 cfg.model.encoder.freeze           : False
2020-08-18 16:54:12,315 cfg.model.encoder.hidden_size      : 1024
2020-08-18 16:54:12,315 cfg.model.encoder.multi_encoder    : False
2020-08-18 16:54:12,315 cfg.model.encoder.num_heads        : 16
2020-08-18 16:54:12,315 cfg.model.encoder.num_layers       : 6
2020-08-18 16:54:12,315 cfg.model.encoder.type             : transformer
2020-08-18 16:54:12,315 cfg.model.init_gain                : 1.0
2020-08-18 16:54:12,315 cfg.model.initializer              : xavier
2020-08-18 16:54:12,315 cfg.model.tied_embeddings          : False
2020-08-18 16:54:12,315 cfg.model.tied_softmax             : True
2020-08-18 16:54:12,315 cfg.name                           : transformer
2020-08-18 16:54:12,315 cfg.testing.alpha                  : 1.0
2020-08-18 16:54:12,315 cfg.testing.beam_size              : 5
2020-08-18 16:54:12,315 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 16:54:12,315 cfg.training.batch_multiplier      : 1
2020-08-18 16:54:12,315 cfg.training.batch_size            : 2048
2020-08-18 16:54:12,315 cfg.training.batch_type            : token
2020-08-18 16:54:12,315 cfg.training.decrease_factor       : 0.7
2020-08-18 16:54:12,315 cfg.training.early_stopping_metric : ppl
2020-08-18 16:54:12,315 cfg.training.epochs                : 20
2020-08-18 16:54:12,315 cfg.training.eval_metric           : bleu
2020-08-18 16:54:12,315 cfg.training.keep_last_ckpts       : 3
2020-08-18 16:54:12,315 cfg.training.label_smoothing       : 0.1
2020-08-18 16:54:12,316 cfg.training.learning_rate         : 0.0002
2020-08-18 16:54:12,316 cfg.training.learning_rate_min     : 1e-08
2020-08-18 16:54:12,316 cfg.training.logging_freq          : 100
2020-08-18 16:54:12,316 cfg.training.loss                  : crossentropy
2020-08-18 16:54:12,316 cfg.training.max_output_length     : 100
2020-08-18 16:54:12,316 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_1024_1024_2048_6_10
2020-08-18 16:54:12,316 cfg.training.normalization         : tokens
2020-08-18 16:54:12,316 cfg.training.optimizer             : adam
2020-08-18 16:54:12,316 cfg.training.overwrite             : True
2020-08-18 16:54:12,316 cfg.training.patience              : 8
2020-08-18 16:54:12,316 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 16:54:12,316 cfg.training.random_seed           : 42
2020-08-18 16:54:12,316 cfg.training.scheduling            : plateau
2020-08-18 16:54:12,316 cfg.training.shuffle               : True
2020-08-18 16:54:12,316 cfg.training.use_cuda              : True
2020-08-18 16:54:12,316 cfg.training.validation_freq       : 200
2020-08-18 16:54:12,316 cfg.training.weight_decay          : 0.0
2020-08-18 16:54:12,316 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 16:54:12,316 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 16:54:12,316 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 16:54:12,317 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 16:54:12,317 Number of Src words (types): 3468
2020-08-18 16:54:12,317 Number of Trg words (types): 4487
2020-08-18 16:54:12,318 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-18 16:54:12,322 EPOCH 1
2020-08-18 16:54:23,895 Epoch   1: total training loss 275.72
2020-08-18 16:54:23,895 EPOCH 2
2020-08-18 16:54:34,591 Epoch   2 Step:      100 Batch Loss:     5.843812 Tokens per Sec:     5479, Lr: 0.000200
2020-08-18 16:54:35,526 Epoch   2: total training loss 238.18
2020-08-18 16:54:35,526 EPOCH 3
2020-08-18 16:54:47,050 Epoch   3: total training loss 215.45
2020-08-18 16:54:47,050 EPOCH 4
2020-08-18 16:54:57,030 Epoch   4 Step:      200 Batch Loss:     4.359450 Tokens per Sec:     5593, Lr: 0.000200
2020-08-18 16:56:00,103 Hooray! New best validation result [ppl]!
2020-08-18 16:56:00,103 Saving new checkpoint.
2020-08-18 16:56:04,603 Example #0
2020-08-18 16:56:04,603 	Raw source:     ['hello', '.']
2020-08-18 16:56:04,603 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:56:04,604 	Source:     hello .
2020-08-18 16:56:04,604 	Reference:  hallo ,
2020-08-18 16:56:04,604 	Hypothesis: hallo .
2020-08-18 16:56:04,604 Example #1
2020-08-18 16:56:04,604 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:56:04,604 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:56:04,604 	Source:     hi , how can i help you ?
2020-08-18 16:56:04,604 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:56:04,604 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:56:04,604 Example #2
2020-08-18 16:56:04,604 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:56:04,604 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2020-08-18 16:56:04,604 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:56:04,604 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:56:04,604 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der der der der der der der der der der der der der der der der der der
2020-08-18 16:56:04,604 Example #3
2020-08-18 16:56:04,605 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:56:04,605 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von']
2020-08-18 16:56:04,605 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:56:04,605 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:56:04,605 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von
2020-08-18 16:56:04,605 Validation result (greedy) at epoch   4, step      200: bleu:   1.76, loss: 24026.3262, ppl:  42.6964, duration: 67.5744s
2020-08-18 16:56:06,208 Epoch   4: total training loss 184.13
2020-08-18 16:56:06,208 EPOCH 5
2020-08-18 16:56:17,752 Epoch   5: total training loss 166.88
2020-08-18 16:56:17,752 EPOCH 6
2020-08-18 16:56:27,169 Epoch   6 Step:      300 Batch Loss:     1.843859 Tokens per Sec:     5580, Lr: 0.000200
2020-08-18 16:56:29,398 Epoch   6: total training loss 138.81
2020-08-18 16:56:29,398 EPOCH 7
2020-08-18 16:56:40,924 Epoch   7: total training loss 127.27
2020-08-18 16:56:40,924 EPOCH 8
2020-08-18 16:56:49,426 Epoch   8 Step:      400 Batch Loss:     2.046960 Tokens per Sec:     5648, Lr: 0.000200
2020-08-18 16:57:48,724 Hooray! New best validation result [ppl]!
2020-08-18 16:57:48,724 Saving new checkpoint.
2020-08-18 16:57:53,331 Example #0
2020-08-18 16:57:53,331 	Raw source:     ['hello', '.']
2020-08-18 16:57:53,331 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:57:53,331 	Source:     hello .
2020-08-18 16:57:53,331 	Reference:  hallo ,
2020-08-18 16:57:53,331 	Hypothesis: hallo .
2020-08-18 16:57:53,331 Example #1
2020-08-18 16:57:53,331 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:57:53,331 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:57:53,331 	Source:     hi , how can i help you ?
2020-08-18 16:57:53,331 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:57:53,331 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:57:53,331 Example #2
2020-08-18 16:57:53,331 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:57:53,331 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 16:57:53,332 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:57:53,332 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:57:53,332 	Hypothesis: hallo , ich bin in sacramento , kalifornien , kalifornien , kalifornien in der arden fair mall .
2020-08-18 16:57:53,332 Example #3
2020-08-18 16:57:53,332 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:57:53,332 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-08-18 16:57:53,332 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:57:53,332 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:57:53,332 	Hypothesis: ok , welche art von restaurant für sie ?
2020-08-18 16:57:53,332 Validation result (greedy) at epoch   8, step      400: bleu:  12.12, loss: 17894.2324, ppl:  16.3786, duration: 63.9059s
2020-08-18 16:57:56,325 Epoch   8: total training loss 107.96
2020-08-18 16:57:56,325 EPOCH 9
2020-08-18 16:58:07,857 Epoch   9: total training loss 96.02
2020-08-18 16:58:07,858 EPOCH 10
2020-08-18 16:58:15,611 Epoch  10 Step:      500 Batch Loss:     2.032404 Tokens per Sec:     5665, Lr: 0.000200
2020-08-18 16:58:19,424 Epoch  10: total training loss 91.57
2020-08-18 16:58:19,424 EPOCH 11
2020-08-18 16:58:30,931 Epoch  11: total training loss 80.18
2020-08-18 16:58:30,931 EPOCH 12
2020-08-18 16:58:37,586 Epoch  12 Step:      600 Batch Loss:     1.372831 Tokens per Sec:     5578, Lr: 0.000200
2020-08-18 16:59:14,857 Hooray! New best validation result [ppl]!
2020-08-18 16:59:14,857 Saving new checkpoint.
2020-08-18 16:59:19,389 Example #0
2020-08-18 16:59:19,389 	Raw source:     ['hello', '.']
2020-08-18 16:59:19,389 	Raw hypothesis: ['hallo', '.']
2020-08-18 16:59:19,389 	Source:     hello .
2020-08-18 16:59:19,389 	Reference:  hallo ,
2020-08-18 16:59:19,389 	Hypothesis: hallo .
2020-08-18 16:59:19,389 Example #1
2020-08-18 16:59:19,389 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 16:59:19,389 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 16:59:19,389 	Source:     hi , how can i help you ?
2020-08-18 16:59:19,390 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 16:59:19,390 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 16:59:19,390 Example #2
2020-08-18 16:59:19,390 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 16:59:19,390 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 16:59:19,390 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 16:59:19,390 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 16:59:19,390 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien in san francisco , kalifornien in san francisco , kalifornien .
2020-08-18 16:59:19,390 Example #3
2020-08-18 16:59:19,390 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 16:59:19,390 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 16:59:19,390 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 16:59:19,390 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 16:59:19,390 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 16:59:19,390 Validation result (greedy) at epoch  12, step      600: bleu:  23.63, loss: 16627.6602, ppl:  13.4378, duration: 41.8035s
2020-08-18 16:59:24,429 Epoch  12: total training loss 69.67
2020-08-18 16:59:24,430 EPOCH 13
2020-08-18 16:59:35,996 Epoch  13: total training loss 58.24
2020-08-18 16:59:35,996 EPOCH 14
2020-08-18 16:59:42,133 Epoch  14 Step:      700 Batch Loss:     1.082558 Tokens per Sec:     5492, Lr: 0.000200
2020-08-18 16:59:47,642 Epoch  14: total training loss 50.53
2020-08-18 16:59:47,643 EPOCH 15
2020-08-18 16:59:59,267 Epoch  15: total training loss 43.78
2020-08-18 16:59:59,267 EPOCH 16
2020-08-18 17:00:04,408 Epoch  16 Step:      800 Batch Loss:     0.655878 Tokens per Sec:     5571, Lr: 0.000200
2020-08-18 17:00:56,757 Hooray! New best validation result [ppl]!
2020-08-18 17:00:56,757 Saving new checkpoint.
2020-08-18 17:01:01,538 Example #0
2020-08-18 17:01:01,539 	Raw source:     ['hello', '.']
2020-08-18 17:01:01,539 	Raw hypothesis: ['hallo']
2020-08-18 17:01:01,539 	Source:     hello .
2020-08-18 17:01:01,539 	Reference:  hallo ,
2020-08-18 17:01:01,539 	Hypothesis: hallo
2020-08-18 17:01:01,539 Example #1
2020-08-18 17:01:01,539 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:01:01,539 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:01:01,539 	Source:     hi , how can i help you ?
2020-08-18 17:01:01,539 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:01:01,539 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:01:01,539 Example #2
2020-08-18 17:01:01,539 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:01:01,539 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:01:01,539 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:01:01,539 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:01:01,540 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:01:01,540 Example #3
2020-08-18 17:01:01,540 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:01:01,540 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:01:01,540 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:01:01,540 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:01:01,540 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:01:01,540 Validation result (greedy) at epoch  16, step      800: bleu:  24.36, loss: 15877.6338, ppl:  11.9518, duration: 57.1317s
2020-08-18 17:01:07,969 Epoch  16: total training loss 38.23
2020-08-18 17:01:07,969 EPOCH 17
2020-08-18 17:01:19,498 Epoch  17: total training loss 33.75
2020-08-18 17:01:19,498 EPOCH 18
2020-08-18 17:01:23,727 Epoch  18 Step:      900 Batch Loss:     0.425437 Tokens per Sec:     5528, Lr: 0.000200
2020-08-18 17:01:31,198 Epoch  18: total training loss 30.37
2020-08-18 17:01:31,198 EPOCH 19
2020-08-18 17:01:42,754 Epoch  19: total training loss 27.66
2020-08-18 17:01:42,755 EPOCH 20
2020-08-18 17:01:45,946 Epoch  20 Step:     1000 Batch Loss:     0.161490 Tokens per Sec:     5626, Lr: 0.000200
2020-08-18 17:02:03,417 Example #0
2020-08-18 17:02:03,418 	Raw source:     ['hello', '.']
2020-08-18 17:02:03,418 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:02:03,418 	Source:     hello .
2020-08-18 17:02:03,418 	Reference:  hallo ,
2020-08-18 17:02:03,418 	Hypothesis: hallo .
2020-08-18 17:02:03,418 Example #1
2020-08-18 17:02:03,418 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:02:03,418 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:02:03,418 	Source:     hi , how can i help you ?
2020-08-18 17:02:03,418 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:02:03,418 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:02:03,418 Example #2
2020-08-18 17:02:03,418 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:02:03,418 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:02:03,418 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:02:03,418 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:02:03,418 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:02:03,418 Example #3
2020-08-18 17:02:03,418 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:02:03,418 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:02:03,418 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:02:03,418 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:02:03,418 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:02:03,418 Validation result (greedy) at epoch  20, step     1000: bleu:  31.74, loss: 15943.3701, ppl:  12.0752, duration: 17.4722s
2020-08-18 17:02:11,948 Epoch  20: total training loss 25.11
2020-08-18 17:02:11,948 Training ended after  20 epochs.
2020-08-18 17:02:11,948 Best validation result (greedy) at step      800:  11.95 ppl.

2020-08-18 17:27:03,642 Hello! This is Joey-NMT.
2020-08-18 17:27:05,042 Total params: 96384000
2020-08-18 17:27:05,044 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 17:27:09,082 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 17:27:09,082 cfg.data.level                     : bpe
2020-08-18 17:27:09,082 cfg.data.lowercase                 : False
2020-08-18 17:27:09,082 cfg.data.max_sent_length           : 100
2020-08-18 17:27:09,082 cfg.data.src                       : en
2020-08-18 17:27:09,082 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 17:27:09,082 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 17:27:09,082 cfg.data.trg                       : de
2020-08-18 17:27:09,082 cfg.model.bias_initializer         : zeros
2020-08-18 17:27:09,082 cfg.model.decoder.dropout          : 0.1
2020-08-18 17:27:09,083 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 17:27:09,083 cfg.model.decoder.embeddings.embedding_dim : 1024
2020-08-18 17:27:09,083 cfg.model.decoder.embeddings.scale : True
2020-08-18 17:27:09,083 cfg.model.decoder.ff_size          : 512
2020-08-18 17:27:09,083 cfg.model.decoder.freeze           : False
2020-08-18 17:27:09,083 cfg.model.decoder.hidden_size      : 1024
2020-08-18 17:27:09,083 cfg.model.decoder.num_heads        : 16
2020-08-18 17:27:09,083 cfg.model.decoder.num_layers       : 6
2020-08-18 17:27:09,083 cfg.model.decoder.type             : transformer
2020-08-18 17:27:09,083 cfg.model.embed_init_gain          : 1.0
2020-08-18 17:27:09,083 cfg.model.embed_initializer        : xavier
2020-08-18 17:27:09,083 cfg.model.encoder.dropout          : 0.3
2020-08-18 17:27:09,083 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 17:27:09,083 cfg.model.encoder.embeddings.embedding_dim : 1024
2020-08-18 17:27:09,083 cfg.model.encoder.embeddings.scale : True
2020-08-18 17:27:09,083 cfg.model.encoder.ff_size          : 512
2020-08-18 17:27:09,083 cfg.model.encoder.freeze           : False
2020-08-18 17:27:09,083 cfg.model.encoder.hidden_size      : 1024
2020-08-18 17:27:09,083 cfg.model.encoder.multi_encoder    : False
2020-08-18 17:27:09,083 cfg.model.encoder.num_heads        : 16
2020-08-18 17:27:09,083 cfg.model.encoder.num_layers       : 6
2020-08-18 17:27:09,083 cfg.model.encoder.type             : transformer
2020-08-18 17:27:09,083 cfg.model.init_gain                : 1.0
2020-08-18 17:27:09,083 cfg.model.initializer              : xavier
2020-08-18 17:27:09,083 cfg.model.tied_embeddings          : False
2020-08-18 17:27:09,083 cfg.model.tied_softmax             : True
2020-08-18 17:27:09,083 cfg.name                           : transformer
2020-08-18 17:27:09,083 cfg.testing.alpha                  : 1.0
2020-08-18 17:27:09,084 cfg.testing.beam_size              : 5
2020-08-18 17:27:09,084 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 17:27:09,084 cfg.training.batch_multiplier      : 1
2020-08-18 17:27:09,084 cfg.training.batch_size            : 2048
2020-08-18 17:27:09,084 cfg.training.batch_type            : token
2020-08-18 17:27:09,084 cfg.training.decrease_factor       : 0.7
2020-08-18 17:27:09,084 cfg.training.early_stopping_metric : ppl
2020-08-18 17:27:09,084 cfg.training.epochs                : 20
2020-08-18 17:27:09,084 cfg.training.eval_metric           : bleu
2020-08-18 17:27:09,084 cfg.training.keep_last_ckpts       : 3
2020-08-18 17:27:09,084 cfg.training.label_smoothing       : 0.1
2020-08-18 17:27:09,084 cfg.training.learning_rate         : 0.0002
2020-08-18 17:27:09,084 cfg.training.learning_rate_min     : 1e-08
2020-08-18 17:27:09,084 cfg.training.logging_freq          : 100
2020-08-18 17:27:09,084 cfg.training.loss                  : crossentropy
2020-08-18 17:27:09,084 cfg.training.max_output_length     : 100
2020-08-18 17:27:09,084 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_1024_1024_2048_8_6
2020-08-18 17:27:09,084 cfg.training.normalization         : tokens
2020-08-18 17:27:09,084 cfg.training.optimizer             : adam
2020-08-18 17:27:09,084 cfg.training.overwrite             : True
2020-08-18 17:27:09,084 cfg.training.patience              : 8
2020-08-18 17:27:09,084 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 17:27:09,084 cfg.training.random_seed           : 42
2020-08-18 17:27:09,084 cfg.training.scheduling            : plateau
2020-08-18 17:27:09,084 cfg.training.shuffle               : True
2020-08-18 17:27:09,084 cfg.training.use_cuda              : True
2020-08-18 17:27:09,084 cfg.training.validation_freq       : 200
2020-08-18 17:27:09,085 cfg.training.weight_decay          : 0.0
2020-08-18 17:27:09,085 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 17:27:09,085 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 17:27:09,085 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 17:27:09,085 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 17:27:09,085 Number of Src words (types): 3468
2020-08-18 17:27:09,086 Number of Trg words (types): 4487
2020-08-18 17:27:09,086 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=1024, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=1024, vocab_size=4487))
2020-08-18 17:27:09,090 EPOCH 1
2020-08-18 17:27:20,682 Epoch   1: total training loss 275.72
2020-08-18 17:27:20,682 EPOCH 2
2020-08-18 17:27:31,440 Epoch   2 Step:      100 Batch Loss:     5.843812 Tokens per Sec:     5448, Lr: 0.000200
2020-08-18 17:27:32,385 Epoch   2: total training loss 238.18
2020-08-18 17:27:32,386 EPOCH 3
2020-08-18 17:27:43,967 Epoch   3: total training loss 215.45
2020-08-18 17:27:43,968 EPOCH 4
2020-08-18 17:27:53,962 Epoch   4 Step:      200 Batch Loss:     4.359450 Tokens per Sec:     5586, Lr: 0.000200
2020-08-18 17:28:56,904 Hooray! New best validation result [ppl]!
2020-08-18 17:28:56,904 Saving new checkpoint.
2020-08-18 17:29:01,736 Example #0
2020-08-18 17:29:01,736 	Raw source:     ['hello', '.']
2020-08-18 17:29:01,736 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:29:01,737 	Source:     hello .
2020-08-18 17:29:01,737 	Reference:  hallo ,
2020-08-18 17:29:01,737 	Hypothesis: hallo .
2020-08-18 17:29:01,737 Example #1
2020-08-18 17:29:01,737 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:29:01,737 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:29:01,737 	Source:     hi , how can i help you ?
2020-08-18 17:29:01,737 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:29:01,737 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:29:01,737 Example #2
2020-08-18 17:29:01,737 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:29:01,737 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'paar', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'mit', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der', 'der']
2020-08-18 17:29:01,737 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:29:01,737 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:29:01,737 	Hypothesis: hallo , ich möchte ein paar paar paar paar paar paar paar paar paar paar paar mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit mit der der der der der der der der der der der der der der der der der der
2020-08-18 17:29:01,737 Example #3
2020-08-18 17:29:01,737 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:29:01,737 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von', 'von']
2020-08-18 17:29:01,737 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:29:01,737 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:29:01,737 	Hypothesis: ok , welche art von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von von
2020-08-18 17:29:01,737 Validation result (greedy) at epoch   4, step      200: bleu:   1.76, loss: 24026.3262, ppl:  42.6964, duration: 67.7751s
2020-08-18 17:29:03,351 Epoch   4: total training loss 184.13
2020-08-18 17:29:03,351 EPOCH 5
2020-08-18 17:29:14,908 Epoch   5: total training loss 166.88
2020-08-18 17:29:14,909 EPOCH 6
2020-08-18 17:29:24,339 Epoch   6 Step:      300 Batch Loss:     1.843859 Tokens per Sec:     5572, Lr: 0.000200
2020-08-18 17:29:26,572 Epoch   6: total training loss 138.81
2020-08-18 17:29:26,572 EPOCH 7
2020-08-18 17:29:38,149 Epoch   7: total training loss 127.27
2020-08-18 17:29:38,149 EPOCH 8
2020-08-18 17:29:46,690 Epoch   8 Step:      400 Batch Loss:     2.046960 Tokens per Sec:     5622, Lr: 0.000200
2020-08-18 17:30:45,907 Hooray! New best validation result [ppl]!
2020-08-18 17:30:45,907 Saving new checkpoint.
2020-08-18 17:30:50,899 Example #0
2020-08-18 17:30:50,899 	Raw source:     ['hello', '.']
2020-08-18 17:30:50,899 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:30:50,899 	Source:     hello .
2020-08-18 17:30:50,899 	Reference:  hallo ,
2020-08-18 17:30:50,899 	Hypothesis: hallo .
2020-08-18 17:30:50,899 Example #1
2020-08-18 17:30:50,899 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:30:50,899 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:30:50,899 	Source:     hi , how can i help you ?
2020-08-18 17:30:50,899 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:30:50,899 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:30:50,899 Example #2
2020-08-18 17:30:50,899 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:30:50,899 	Raw hypothesis: ['hallo', ',', 'ich', 'bin', 'in', 'sacramento', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:30:50,899 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:30:50,899 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:30:50,899 	Hypothesis: hallo , ich bin in sacramento , kalifornien , kalifornien , kalifornien in der arden fair mall .
2020-08-18 17:30:50,899 Example #3
2020-08-18 17:30:50,899 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:30:50,899 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'für', 'sie', '?']
2020-08-18 17:30:50,900 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:30:50,900 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:30:50,900 	Hypothesis: ok , welche art von restaurant für sie ?
2020-08-18 17:30:50,900 Validation result (greedy) at epoch   8, step      400: bleu:  12.12, loss: 17894.2324, ppl:  16.3786, duration: 64.2093s
2020-08-18 17:30:53,898 Epoch   8: total training loss 107.96
2020-08-18 17:30:53,898 EPOCH 9
2020-08-18 17:31:05,436 Epoch   9: total training loss 96.02
2020-08-18 17:31:05,437 EPOCH 10
2020-08-18 17:31:13,221 Epoch  10 Step:      500 Batch Loss:     2.032404 Tokens per Sec:     5642, Lr: 0.000200
2020-08-18 17:31:17,065 Epoch  10: total training loss 91.57
2020-08-18 17:31:17,065 EPOCH 11
2020-08-18 17:31:28,647 Epoch  11: total training loss 80.18
2020-08-18 17:31:28,648 EPOCH 12
2020-08-18 17:31:35,319 Epoch  12 Step:      600 Batch Loss:     1.372831 Tokens per Sec:     5565, Lr: 0.000200
2020-08-18 17:32:12,561 Hooray! New best validation result [ppl]!
2020-08-18 17:32:12,561 Saving new checkpoint.
2020-08-18 17:32:17,476 Example #0
2020-08-18 17:32:17,476 	Raw source:     ['hello', '.']
2020-08-18 17:32:17,476 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:32:17,476 	Source:     hello .
2020-08-18 17:32:17,476 	Reference:  hallo ,
2020-08-18 17:32:17,476 	Hypothesis: hallo .
2020-08-18 17:32:17,476 Example #1
2020-08-18 17:32:17,476 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:32:17,477 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:32:17,477 	Source:     hi , how can i help you ?
2020-08-18 17:32:17,477 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:32:17,477 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:32:17,477 Example #2
2020-08-18 17:32:17,477 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:32:17,477 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 17:32:17,477 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:32:17,477 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:32:17,477 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien in san francisco , kalifornien in san francisco , kalifornien .
2020-08-18 17:32:17,477 Example #3
2020-08-18 17:32:17,477 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:32:17,477 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:32:17,477 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:32:17,477 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:32:17,477 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:32:17,477 Validation result (greedy) at epoch  12, step      600: bleu:  23.63, loss: 16627.6602, ppl:  13.4378, duration: 42.1580s
2020-08-18 17:32:22,498 Epoch  12: total training loss 69.67
2020-08-18 17:32:22,498 EPOCH 13
2020-08-18 17:32:34,096 Epoch  13: total training loss 58.24
2020-08-18 17:32:34,096 EPOCH 14
2020-08-18 17:32:40,235 Epoch  14 Step:      700 Batch Loss:     1.082558 Tokens per Sec:     5490, Lr: 0.000200
2020-08-18 17:32:45,754 Epoch  14: total training loss 50.53
2020-08-18 17:32:45,755 EPOCH 15
2020-08-18 17:32:57,399 Epoch  15: total training loss 43.78
2020-08-18 17:32:57,399 EPOCH 16
2020-08-18 17:33:02,545 Epoch  16 Step:      800 Batch Loss:     0.655878 Tokens per Sec:     5565, Lr: 0.000200
2020-08-18 17:33:54,741 Hooray! New best validation result [ppl]!
2020-08-18 17:33:54,741 Saving new checkpoint.
2020-08-18 17:33:59,681 Example #0
2020-08-18 17:33:59,681 	Raw source:     ['hello', '.']
2020-08-18 17:33:59,681 	Raw hypothesis: ['hallo']
2020-08-18 17:33:59,681 	Source:     hello .
2020-08-18 17:33:59,681 	Reference:  hallo ,
2020-08-18 17:33:59,681 	Hypothesis: hallo
2020-08-18 17:33:59,682 Example #1
2020-08-18 17:33:59,682 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:33:59,682 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:33:59,682 	Source:     hi , how can i help you ?
2020-08-18 17:33:59,682 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:33:59,682 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:33:59,682 Example #2
2020-08-18 17:33:59,682 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:33:59,682 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:33:59,682 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:33:59,682 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:33:59,682 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in san francisco , kalifornien , in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:33:59,682 Example #3
2020-08-18 17:33:59,682 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:33:59,682 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:33:59,682 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:33:59,682 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:33:59,682 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:33:59,682 Validation result (greedy) at epoch  16, step      800: bleu:  24.36, loss: 15877.6338, ppl:  11.9518, duration: 57.1367s
2020-08-18 17:34:06,119 Epoch  16: total training loss 38.23
2020-08-18 17:34:06,119 EPOCH 17
2020-08-18 17:34:17,709 Epoch  17: total training loss 33.75
2020-08-18 17:34:17,709 EPOCH 18
2020-08-18 17:34:21,951 Epoch  18 Step:      900 Batch Loss:     0.425437 Tokens per Sec:     5512, Lr: 0.000200
2020-08-18 17:34:29,454 Epoch  18: total training loss 30.37
2020-08-18 17:34:29,454 EPOCH 19
2020-08-18 17:34:41,029 Epoch  19: total training loss 27.66
2020-08-18 17:34:41,029 EPOCH 20
2020-08-18 17:34:44,215 Epoch  20 Step:     1000 Batch Loss:     0.161490 Tokens per Sec:     5636, Lr: 0.000200
2020-08-18 17:35:01,629 Example #0
2020-08-18 17:35:01,629 	Raw source:     ['hello', '.']
2020-08-18 17:35:01,630 	Raw hypothesis: ['hallo', '.']
2020-08-18 17:35:01,630 	Source:     hello .
2020-08-18 17:35:01,630 	Reference:  hallo ,
2020-08-18 17:35:01,630 	Hypothesis: hallo .
2020-08-18 17:35:01,630 Example #1
2020-08-18 17:35:01,630 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 17:35:01,630 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 17:35:01,630 	Source:     hi , how can i help you ?
2020-08-18 17:35:01,630 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 17:35:01,630 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 17:35:01,630 Example #2
2020-08-18 17:35:01,630 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 17:35:01,630 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'der', 'arden', 'fair', 'mall', '.']
2020-08-18 17:35:01,630 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 17:35:01,630 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 17:35:01,630 	Hypothesis: hallo , ich suche ein restaurant in san francisco , kalifornien , in der arden fair mall .
2020-08-18 17:35:01,630 Example #3
2020-08-18 17:35:01,630 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 17:35:01,630 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', '?']
2020-08-18 17:35:01,630 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 17:35:01,630 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 17:35:01,630 	Hypothesis: ok , nach welcher art von restaurant suchen sie ?
2020-08-18 17:35:01,630 Validation result (greedy) at epoch  20, step     1000: bleu:  31.74, loss: 15943.3701, ppl:  12.0752, duration: 17.4150s
2020-08-18 17:35:10,198 Epoch  20: total training loss 25.11
2020-08-18 17:35:10,198 Training ended after  20 epochs.
2020-08-18 17:35:10,198 Best validation result (greedy) at step      800:  11.95 ppl.

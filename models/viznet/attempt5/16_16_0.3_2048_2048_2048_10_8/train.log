2020-08-18 18:37:19,717 Hello! This is Joey-NMT.
2020-08-18 18:37:22,123 Total params: 343756800
2020-08-18 18:37:22,124 Trainable parameters: ['decoder.layer_norm.bias', 'decoder.layer_norm.weight', 'decoder.layers.0.dec_layer_norm.bias', 'decoder.layers.0.dec_layer_norm.weight', 'decoder.layers.0.feed_forward.layer_norm.bias', 'decoder.layers.0.feed_forward.layer_norm.weight', 'decoder.layers.0.feed_forward.pwff_layer.0.bias', 'decoder.layers.0.feed_forward.pwff_layer.0.weight', 'decoder.layers.0.feed_forward.pwff_layer.3.bias', 'decoder.layers.0.feed_forward.pwff_layer.3.weight', 'decoder.layers.0.src_trg_att.k_layer.bias', 'decoder.layers.0.src_trg_att.k_layer.weight', 'decoder.layers.0.src_trg_att.output_layer.bias', 'decoder.layers.0.src_trg_att.output_layer.weight', 'decoder.layers.0.src_trg_att.q_layer.bias', 'decoder.layers.0.src_trg_att.q_layer.weight', 'decoder.layers.0.src_trg_att.v_layer.bias', 'decoder.layers.0.src_trg_att.v_layer.weight', 'decoder.layers.0.trg_trg_att.k_layer.bias', 'decoder.layers.0.trg_trg_att.k_layer.weight', 'decoder.layers.0.trg_trg_att.output_layer.bias', 'decoder.layers.0.trg_trg_att.output_layer.weight', 'decoder.layers.0.trg_trg_att.q_layer.bias', 'decoder.layers.0.trg_trg_att.q_layer.weight', 'decoder.layers.0.trg_trg_att.v_layer.bias', 'decoder.layers.0.trg_trg_att.v_layer.weight', 'decoder.layers.0.x_layer_norm.bias', 'decoder.layers.0.x_layer_norm.weight', 'decoder.layers.1.dec_layer_norm.bias', 'decoder.layers.1.dec_layer_norm.weight', 'decoder.layers.1.feed_forward.layer_norm.bias', 'decoder.layers.1.feed_forward.layer_norm.weight', 'decoder.layers.1.feed_forward.pwff_layer.0.bias', 'decoder.layers.1.feed_forward.pwff_layer.0.weight', 'decoder.layers.1.feed_forward.pwff_layer.3.bias', 'decoder.layers.1.feed_forward.pwff_layer.3.weight', 'decoder.layers.1.src_trg_att.k_layer.bias', 'decoder.layers.1.src_trg_att.k_layer.weight', 'decoder.layers.1.src_trg_att.output_layer.bias', 'decoder.layers.1.src_trg_att.output_layer.weight', 'decoder.layers.1.src_trg_att.q_layer.bias', 'decoder.layers.1.src_trg_att.q_layer.weight', 'decoder.layers.1.src_trg_att.v_layer.bias', 'decoder.layers.1.src_trg_att.v_layer.weight', 'decoder.layers.1.trg_trg_att.k_layer.bias', 'decoder.layers.1.trg_trg_att.k_layer.weight', 'decoder.layers.1.trg_trg_att.output_layer.bias', 'decoder.layers.1.trg_trg_att.output_layer.weight', 'decoder.layers.1.trg_trg_att.q_layer.bias', 'decoder.layers.1.trg_trg_att.q_layer.weight', 'decoder.layers.1.trg_trg_att.v_layer.bias', 'decoder.layers.1.trg_trg_att.v_layer.weight', 'decoder.layers.1.x_layer_norm.bias', 'decoder.layers.1.x_layer_norm.weight', 'decoder.layers.2.dec_layer_norm.bias', 'decoder.layers.2.dec_layer_norm.weight', 'decoder.layers.2.feed_forward.layer_norm.bias', 'decoder.layers.2.feed_forward.layer_norm.weight', 'decoder.layers.2.feed_forward.pwff_layer.0.bias', 'decoder.layers.2.feed_forward.pwff_layer.0.weight', 'decoder.layers.2.feed_forward.pwff_layer.3.bias', 'decoder.layers.2.feed_forward.pwff_layer.3.weight', 'decoder.layers.2.src_trg_att.k_layer.bias', 'decoder.layers.2.src_trg_att.k_layer.weight', 'decoder.layers.2.src_trg_att.output_layer.bias', 'decoder.layers.2.src_trg_att.output_layer.weight', 'decoder.layers.2.src_trg_att.q_layer.bias', 'decoder.layers.2.src_trg_att.q_layer.weight', 'decoder.layers.2.src_trg_att.v_layer.bias', 'decoder.layers.2.src_trg_att.v_layer.weight', 'decoder.layers.2.trg_trg_att.k_layer.bias', 'decoder.layers.2.trg_trg_att.k_layer.weight', 'decoder.layers.2.trg_trg_att.output_layer.bias', 'decoder.layers.2.trg_trg_att.output_layer.weight', 'decoder.layers.2.trg_trg_att.q_layer.bias', 'decoder.layers.2.trg_trg_att.q_layer.weight', 'decoder.layers.2.trg_trg_att.v_layer.bias', 'decoder.layers.2.trg_trg_att.v_layer.weight', 'decoder.layers.2.x_layer_norm.bias', 'decoder.layers.2.x_layer_norm.weight', 'decoder.layers.3.dec_layer_norm.bias', 'decoder.layers.3.dec_layer_norm.weight', 'decoder.layers.3.feed_forward.layer_norm.bias', 'decoder.layers.3.feed_forward.layer_norm.weight', 'decoder.layers.3.feed_forward.pwff_layer.0.bias', 'decoder.layers.3.feed_forward.pwff_layer.0.weight', 'decoder.layers.3.feed_forward.pwff_layer.3.bias', 'decoder.layers.3.feed_forward.pwff_layer.3.weight', 'decoder.layers.3.src_trg_att.k_layer.bias', 'decoder.layers.3.src_trg_att.k_layer.weight', 'decoder.layers.3.src_trg_att.output_layer.bias', 'decoder.layers.3.src_trg_att.output_layer.weight', 'decoder.layers.3.src_trg_att.q_layer.bias', 'decoder.layers.3.src_trg_att.q_layer.weight', 'decoder.layers.3.src_trg_att.v_layer.bias', 'decoder.layers.3.src_trg_att.v_layer.weight', 'decoder.layers.3.trg_trg_att.k_layer.bias', 'decoder.layers.3.trg_trg_att.k_layer.weight', 'decoder.layers.3.trg_trg_att.output_layer.bias', 'decoder.layers.3.trg_trg_att.output_layer.weight', 'decoder.layers.3.trg_trg_att.q_layer.bias', 'decoder.layers.3.trg_trg_att.q_layer.weight', 'decoder.layers.3.trg_trg_att.v_layer.bias', 'decoder.layers.3.trg_trg_att.v_layer.weight', 'decoder.layers.3.x_layer_norm.bias', 'decoder.layers.3.x_layer_norm.weight', 'decoder.layers.4.dec_layer_norm.bias', 'decoder.layers.4.dec_layer_norm.weight', 'decoder.layers.4.feed_forward.layer_norm.bias', 'decoder.layers.4.feed_forward.layer_norm.weight', 'decoder.layers.4.feed_forward.pwff_layer.0.bias', 'decoder.layers.4.feed_forward.pwff_layer.0.weight', 'decoder.layers.4.feed_forward.pwff_layer.3.bias', 'decoder.layers.4.feed_forward.pwff_layer.3.weight', 'decoder.layers.4.src_trg_att.k_layer.bias', 'decoder.layers.4.src_trg_att.k_layer.weight', 'decoder.layers.4.src_trg_att.output_layer.bias', 'decoder.layers.4.src_trg_att.output_layer.weight', 'decoder.layers.4.src_trg_att.q_layer.bias', 'decoder.layers.4.src_trg_att.q_layer.weight', 'decoder.layers.4.src_trg_att.v_layer.bias', 'decoder.layers.4.src_trg_att.v_layer.weight', 'decoder.layers.4.trg_trg_att.k_layer.bias', 'decoder.layers.4.trg_trg_att.k_layer.weight', 'decoder.layers.4.trg_trg_att.output_layer.bias', 'decoder.layers.4.trg_trg_att.output_layer.weight', 'decoder.layers.4.trg_trg_att.q_layer.bias', 'decoder.layers.4.trg_trg_att.q_layer.weight', 'decoder.layers.4.trg_trg_att.v_layer.bias', 'decoder.layers.4.trg_trg_att.v_layer.weight', 'decoder.layers.4.x_layer_norm.bias', 'decoder.layers.4.x_layer_norm.weight', 'decoder.layers.5.dec_layer_norm.bias', 'decoder.layers.5.dec_layer_norm.weight', 'decoder.layers.5.feed_forward.layer_norm.bias', 'decoder.layers.5.feed_forward.layer_norm.weight', 'decoder.layers.5.feed_forward.pwff_layer.0.bias', 'decoder.layers.5.feed_forward.pwff_layer.0.weight', 'decoder.layers.5.feed_forward.pwff_layer.3.bias', 'decoder.layers.5.feed_forward.pwff_layer.3.weight', 'decoder.layers.5.src_trg_att.k_layer.bias', 'decoder.layers.5.src_trg_att.k_layer.weight', 'decoder.layers.5.src_trg_att.output_layer.bias', 'decoder.layers.5.src_trg_att.output_layer.weight', 'decoder.layers.5.src_trg_att.q_layer.bias', 'decoder.layers.5.src_trg_att.q_layer.weight', 'decoder.layers.5.src_trg_att.v_layer.bias', 'decoder.layers.5.src_trg_att.v_layer.weight', 'decoder.layers.5.trg_trg_att.k_layer.bias', 'decoder.layers.5.trg_trg_att.k_layer.weight', 'decoder.layers.5.trg_trg_att.output_layer.bias', 'decoder.layers.5.trg_trg_att.output_layer.weight', 'decoder.layers.5.trg_trg_att.q_layer.bias', 'decoder.layers.5.trg_trg_att.q_layer.weight', 'decoder.layers.5.trg_trg_att.v_layer.bias', 'decoder.layers.5.trg_trg_att.v_layer.weight', 'decoder.layers.5.x_layer_norm.bias', 'decoder.layers.5.x_layer_norm.weight', 'encoder.layer_norm.bias', 'encoder.layer_norm.weight', 'encoder.layers.0.feed_forward.layer_norm.bias', 'encoder.layers.0.feed_forward.layer_norm.weight', 'encoder.layers.0.feed_forward.pwff_layer.0.bias', 'encoder.layers.0.feed_forward.pwff_layer.0.weight', 'encoder.layers.0.feed_forward.pwff_layer.3.bias', 'encoder.layers.0.feed_forward.pwff_layer.3.weight', 'encoder.layers.0.layer_norm.bias', 'encoder.layers.0.layer_norm.weight', 'encoder.layers.0.src_src_att.k_layer.bias', 'encoder.layers.0.src_src_att.k_layer.weight', 'encoder.layers.0.src_src_att.output_layer.bias', 'encoder.layers.0.src_src_att.output_layer.weight', 'encoder.layers.0.src_src_att.q_layer.bias', 'encoder.layers.0.src_src_att.q_layer.weight', 'encoder.layers.0.src_src_att.v_layer.bias', 'encoder.layers.0.src_src_att.v_layer.weight', 'encoder.layers.1.feed_forward.layer_norm.bias', 'encoder.layers.1.feed_forward.layer_norm.weight', 'encoder.layers.1.feed_forward.pwff_layer.0.bias', 'encoder.layers.1.feed_forward.pwff_layer.0.weight', 'encoder.layers.1.feed_forward.pwff_layer.3.bias', 'encoder.layers.1.feed_forward.pwff_layer.3.weight', 'encoder.layers.1.layer_norm.bias', 'encoder.layers.1.layer_norm.weight', 'encoder.layers.1.src_src_att.k_layer.bias', 'encoder.layers.1.src_src_att.k_layer.weight', 'encoder.layers.1.src_src_att.output_layer.bias', 'encoder.layers.1.src_src_att.output_layer.weight', 'encoder.layers.1.src_src_att.q_layer.bias', 'encoder.layers.1.src_src_att.q_layer.weight', 'encoder.layers.1.src_src_att.v_layer.bias', 'encoder.layers.1.src_src_att.v_layer.weight', 'encoder.layers.2.feed_forward.layer_norm.bias', 'encoder.layers.2.feed_forward.layer_norm.weight', 'encoder.layers.2.feed_forward.pwff_layer.0.bias', 'encoder.layers.2.feed_forward.pwff_layer.0.weight', 'encoder.layers.2.feed_forward.pwff_layer.3.bias', 'encoder.layers.2.feed_forward.pwff_layer.3.weight', 'encoder.layers.2.layer_norm.bias', 'encoder.layers.2.layer_norm.weight', 'encoder.layers.2.src_src_att.k_layer.bias', 'encoder.layers.2.src_src_att.k_layer.weight', 'encoder.layers.2.src_src_att.output_layer.bias', 'encoder.layers.2.src_src_att.output_layer.weight', 'encoder.layers.2.src_src_att.q_layer.bias', 'encoder.layers.2.src_src_att.q_layer.weight', 'encoder.layers.2.src_src_att.v_layer.bias', 'encoder.layers.2.src_src_att.v_layer.weight', 'encoder.layers.3.feed_forward.layer_norm.bias', 'encoder.layers.3.feed_forward.layer_norm.weight', 'encoder.layers.3.feed_forward.pwff_layer.0.bias', 'encoder.layers.3.feed_forward.pwff_layer.0.weight', 'encoder.layers.3.feed_forward.pwff_layer.3.bias', 'encoder.layers.3.feed_forward.pwff_layer.3.weight', 'encoder.layers.3.layer_norm.bias', 'encoder.layers.3.layer_norm.weight', 'encoder.layers.3.src_src_att.k_layer.bias', 'encoder.layers.3.src_src_att.k_layer.weight', 'encoder.layers.3.src_src_att.output_layer.bias', 'encoder.layers.3.src_src_att.output_layer.weight', 'encoder.layers.3.src_src_att.q_layer.bias', 'encoder.layers.3.src_src_att.q_layer.weight', 'encoder.layers.3.src_src_att.v_layer.bias', 'encoder.layers.3.src_src_att.v_layer.weight', 'encoder.layers.4.feed_forward.layer_norm.bias', 'encoder.layers.4.feed_forward.layer_norm.weight', 'encoder.layers.4.feed_forward.pwff_layer.0.bias', 'encoder.layers.4.feed_forward.pwff_layer.0.weight', 'encoder.layers.4.feed_forward.pwff_layer.3.bias', 'encoder.layers.4.feed_forward.pwff_layer.3.weight', 'encoder.layers.4.layer_norm.bias', 'encoder.layers.4.layer_norm.weight', 'encoder.layers.4.src_src_att.k_layer.bias', 'encoder.layers.4.src_src_att.k_layer.weight', 'encoder.layers.4.src_src_att.output_layer.bias', 'encoder.layers.4.src_src_att.output_layer.weight', 'encoder.layers.4.src_src_att.q_layer.bias', 'encoder.layers.4.src_src_att.q_layer.weight', 'encoder.layers.4.src_src_att.v_layer.bias', 'encoder.layers.4.src_src_att.v_layer.weight', 'encoder.layers.5.feed_forward.layer_norm.bias', 'encoder.layers.5.feed_forward.layer_norm.weight', 'encoder.layers.5.feed_forward.pwff_layer.0.bias', 'encoder.layers.5.feed_forward.pwff_layer.0.weight', 'encoder.layers.5.feed_forward.pwff_layer.3.bias', 'encoder.layers.5.feed_forward.pwff_layer.3.weight', 'encoder.layers.5.layer_norm.bias', 'encoder.layers.5.layer_norm.weight', 'encoder.layers.5.src_src_att.k_layer.bias', 'encoder.layers.5.src_src_att.k_layer.weight', 'encoder.layers.5.src_src_att.output_layer.bias', 'encoder.layers.5.src_src_att.output_layer.weight', 'encoder.layers.5.src_src_att.q_layer.bias', 'encoder.layers.5.src_src_att.q_layer.weight', 'encoder.layers.5.src_src_att.v_layer.bias', 'encoder.layers.5.src_src_att.v_layer.weight', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-08-18 18:37:26,393 cfg.data.dev                       : chatnmt/multi_encoder/dev_subset.tags.bpe.10000
2020-08-18 18:37:26,393 cfg.data.level                     : bpe
2020-08-18 18:37:26,393 cfg.data.lowercase                 : False
2020-08-18 18:37:26,393 cfg.data.max_sent_length           : 100
2020-08-18 18:37:26,393 cfg.data.src                       : en
2020-08-18 18:37:26,393 cfg.data.test                      : chatnmt/multi_encoder/test.tags.bpe.10000
2020-08-18 18:37:26,393 cfg.data.train                     : chatnmt/multi_encoder/train_subset.tags.bpe.10000
2020-08-18 18:37:26,393 cfg.data.trg                       : de
2020-08-18 18:37:26,393 cfg.model.bias_initializer         : zeros
2020-08-18 18:37:26,393 cfg.model.decoder.dropout          : 0.1
2020-08-18 18:37:26,393 cfg.model.decoder.embeddings.dropout : 0.0
2020-08-18 18:37:26,393 cfg.model.decoder.embeddings.embedding_dim : 2048
2020-08-18 18:37:26,393 cfg.model.decoder.embeddings.scale : True
2020-08-18 18:37:26,394 cfg.model.decoder.ff_size          : 512
2020-08-18 18:37:26,394 cfg.model.decoder.freeze           : False
2020-08-18 18:37:26,394 cfg.model.decoder.hidden_size      : 2048
2020-08-18 18:37:26,394 cfg.model.decoder.num_heads        : 16
2020-08-18 18:37:26,394 cfg.model.decoder.num_layers       : 6
2020-08-18 18:37:26,394 cfg.model.decoder.type             : transformer
2020-08-18 18:37:26,394 cfg.model.embed_init_gain          : 1.0
2020-08-18 18:37:26,394 cfg.model.embed_initializer        : xavier
2020-08-18 18:37:26,394 cfg.model.encoder.dropout          : 0.3
2020-08-18 18:37:26,394 cfg.model.encoder.embeddings.dropout : 0.0
2020-08-18 18:37:26,394 cfg.model.encoder.embeddings.embedding_dim : 2048
2020-08-18 18:37:26,394 cfg.model.encoder.embeddings.scale : True
2020-08-18 18:37:26,394 cfg.model.encoder.ff_size          : 512
2020-08-18 18:37:26,394 cfg.model.encoder.freeze           : False
2020-08-18 18:37:26,394 cfg.model.encoder.hidden_size      : 2048
2020-08-18 18:37:26,394 cfg.model.encoder.multi_encoder    : False
2020-08-18 18:37:26,394 cfg.model.encoder.num_heads        : 16
2020-08-18 18:37:26,394 cfg.model.encoder.num_layers       : 6
2020-08-18 18:37:26,394 cfg.model.encoder.type             : transformer
2020-08-18 18:37:26,395 cfg.model.init_gain                : 1.0
2020-08-18 18:37:26,395 cfg.model.initializer              : xavier
2020-08-18 18:37:26,395 cfg.model.tied_embeddings          : False
2020-08-18 18:37:26,395 cfg.model.tied_softmax             : True
2020-08-18 18:37:26,395 cfg.name                           : transformer
2020-08-18 18:37:26,395 cfg.testing.alpha                  : 1.0
2020-08-18 18:37:26,395 cfg.testing.beam_size              : 5
2020-08-18 18:37:26,395 cfg.training.adam_betas            : [0.9, 0.999]
2020-08-18 18:37:26,395 cfg.training.batch_multiplier      : 1
2020-08-18 18:37:26,395 cfg.training.batch_size            : 2048
2020-08-18 18:37:26,395 cfg.training.batch_type            : token
2020-08-18 18:37:26,395 cfg.training.decrease_factor       : 0.7
2020-08-18 18:37:26,395 cfg.training.early_stopping_metric : ppl
2020-08-18 18:37:26,395 cfg.training.epochs                : 20
2020-08-18 18:37:26,395 cfg.training.eval_metric           : bleu
2020-08-18 18:37:26,395 cfg.training.keep_last_ckpts       : 3
2020-08-18 18:37:26,395 cfg.training.label_smoothing       : 0.1
2020-08-18 18:37:26,395 cfg.training.learning_rate         : 0.0002
2020-08-18 18:37:26,395 cfg.training.learning_rate_min     : 1e-08
2020-08-18 18:37:26,396 cfg.training.logging_freq          : 100
2020-08-18 18:37:26,396 cfg.training.loss                  : crossentropy
2020-08-18 18:37:26,396 cfg.training.max_output_length     : 100
2020-08-18 18:37:26,396 cfg.training.model_dir             : models/viznet/attempt5/16_16_0.3_2048_2048_2048_10_8
2020-08-18 18:37:26,396 cfg.training.normalization         : tokens
2020-08-18 18:37:26,396 cfg.training.optimizer             : adam
2020-08-18 18:37:26,396 cfg.training.overwrite             : True
2020-08-18 18:37:26,396 cfg.training.patience              : 8
2020-08-18 18:37:26,396 cfg.training.print_valid_sents     : [0, 1, 2, 3]
2020-08-18 18:37:26,396 cfg.training.random_seed           : 42
2020-08-18 18:37:26,396 cfg.training.scheduling            : plateau
2020-08-18 18:37:26,396 cfg.training.shuffle               : True
2020-08-18 18:37:26,396 cfg.training.use_cuda              : True
2020-08-18 18:37:26,396 cfg.training.validation_freq       : 200
2020-08-18 18:37:26,396 cfg.training.weight_decay          : 0.0
2020-08-18 18:37:26,396 Data set sizes: 
	train 5000,
	valid 500,
	test 1220
2020-08-18 18:37:26,396 First training example:
	[SRC] hi there ! how can i help ?
	[TRG] hallo ! wie kann ich helfen ?
2020-08-18 18:37:26,397 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) you (8) i (9) the
2020-08-18 18:37:26,397 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) . (5) , (6) ? (7) sie (8) ich (9) das
2020-08-18 18:37:26,397 Number of Src words (types): 3468
2020-08-18 18:37:26,398 Number of Trg words (types): 4487
2020-08-18 18:37:26,398 Model(
	encoder=TransformerEncoder(num_layers=6, num_heads=16),
	decoder=TransformerDecoder(num_layers=6, num_heads=16),
	src_embed=Embeddings(embedding_dim=2048, vocab_size=3468),
	trg_embed=Embeddings(embedding_dim=2048, vocab_size=4487))
2020-08-18 18:37:26,402 EPOCH 1
2020-08-18 18:37:57,601 Epoch   1: total training loss 290.58
2020-08-18 18:37:57,601 EPOCH 2
2020-08-18 18:38:26,416 Epoch   2 Step:      100 Batch Loss:     6.340784 Tokens per Sec:     2034, Lr: 0.000200
2020-08-18 18:38:28,956 Epoch   2: total training loss 253.71
2020-08-18 18:38:28,956 EPOCH 3
2020-08-18 18:39:00,059 Epoch   3: total training loss 242.50
2020-08-18 18:39:00,059 EPOCH 4
2020-08-18 18:39:26,972 Epoch   4 Step:      200 Batch Loss:     4.861712 Tokens per Sec:     2074, Lr: 0.000200
2020-08-18 18:42:23,528 Hooray! New best validation result [ppl]!
2020-08-18 18:42:23,529 Saving new checkpoint.
2020-08-18 18:42:57,460 Example #0
2020-08-18 18:42:57,460 	Raw source:     ['hello', '.']
2020-08-18 18:42:57,460 	Raw hypothesis: ['removemeimaboundary']
2020-08-18 18:42:57,460 	Source:     hello .
2020-08-18 18:42:57,460 	Reference:  hallo ,
2020-08-18 18:42:57,460 	Hypothesis: removemeimaboundary
2020-08-18 18:42:57,461 Example #1
2020-08-18 18:42:57,461 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:42:57,461 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 18:42:57,461 	Source:     hi , how can i help you ?
2020-08-18 18:42:57,461 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:42:57,461 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 18:42:57,461 Example #2
2020-08-18 18:42:57,461 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:42:57,461 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein', 'ein']
2020-08-18 18:42:57,461 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:42:57,461 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:42:57,461 	Hypothesis: hallo , ich möchte ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein ein
2020-08-18 18:42:57,461 Example #3
2020-08-18 18:42:57,461 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:42:57,461 	Raw hypothesis: ['hallo', ',', 'wie', 'sie', '?']
2020-08-18 18:42:57,461 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:42:57,461 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:42:57,461 	Hypothesis: hallo , wie sie ?
2020-08-18 18:42:57,461 Validation result (greedy) at epoch   4, step      200: bleu:   1.14, loss: 27310.8262, ppl:  71.3300, duration: 210.4890s
2020-08-18 18:43:01,777 Epoch   4: total training loss 213.28
2020-08-18 18:43:01,778 EPOCH 5
2020-08-18 18:43:33,014 Epoch   5: total training loss 203.48
2020-08-18 18:43:33,014 EPOCH 6
2020-08-18 18:43:58,281 Epoch   6 Step:      300 Batch Loss:     2.627954 Tokens per Sec:     2080, Lr: 0.000200
2020-08-18 18:44:04,293 Epoch   6: total training loss 183.60
2020-08-18 18:44:04,293 EPOCH 7
2020-08-18 18:44:35,457 Epoch   7: total training loss 168.87
2020-08-18 18:44:35,458 EPOCH 8
2020-08-18 18:44:58,486 Epoch   8 Step:      400 Batch Loss:     2.796215 Tokens per Sec:     2085, Lr: 0.000200
2020-08-18 18:47:55,082 Hooray! New best validation result [ppl]!
2020-08-18 18:47:55,083 Saving new checkpoint.
2020-08-18 18:48:29,013 Example #0
2020-08-18 18:48:29,013 	Raw source:     ['hello', '.']
2020-08-18 18:48:29,013 	Raw hypothesis: ['hallo', '.']
2020-08-18 18:48:29,013 	Source:     hello .
2020-08-18 18:48:29,014 	Reference:  hallo ,
2020-08-18 18:48:29,014 	Hypothesis: hallo .
2020-08-18 18:48:29,014 Example #1
2020-08-18 18:48:29,014 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:48:29,014 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 18:48:29,014 	Source:     hi , how can i help you ?
2020-08-18 18:48:29,014 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:48:29,014 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 18:48:29,014 Example #2
2020-08-18 18:48:29,014 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:48:29,014 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'einen', 'termin', 'für', 'meinen', 'hallo', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 18:48:29,014 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:48:29,014 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:48:29,014 	Hypothesis: hallo , ich möchte einen termin für meinen hallo , kalifornien , kalifornien .
2020-08-18 18:48:29,014 Example #3
2020-08-18 18:48:29,014 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:48:29,014 	Raw hypothesis: ['okay', ',', 'welche', 'art', 'von', 'essen', 'möchten', 'sie', '?']
2020-08-18 18:48:29,014 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:48:29,014 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:48:29,014 	Hypothesis: okay , welche art von essen möchten sie ?
2020-08-18 18:48:29,014 Validation result (greedy) at epoch   8, step      400: bleu:   4.68, loss: 21429.6094, ppl:  28.4565, duration: 210.5276s
2020-08-18 18:48:37,069 Epoch   8: total training loss 143.40
2020-08-18 18:48:37,069 EPOCH 9
2020-08-18 18:49:08,256 Epoch   9: total training loss 128.25
2020-08-18 18:49:08,256 EPOCH 10
2020-08-18 18:49:29,281 Epoch  10 Step:      500 Batch Loss:     2.601208 Tokens per Sec:     2089, Lr: 0.000200
2020-08-18 18:49:39,638 Epoch  10: total training loss 120.48
2020-08-18 18:49:39,638 EPOCH 11
2020-08-18 18:50:10,791 Epoch  11: total training loss 104.22
2020-08-18 18:50:10,791 EPOCH 12
2020-08-18 18:50:28,746 Epoch  12 Step:      600 Batch Loss:     1.729617 Tokens per Sec:     2067, Lr: 0.000200
2020-08-18 18:53:25,400 Hooray! New best validation result [ppl]!
2020-08-18 18:53:25,400 Saving new checkpoint.
2020-08-18 18:54:01,075 Example #0
2020-08-18 18:54:01,075 	Raw source:     ['hello', '.']
2020-08-18 18:54:01,075 	Raw hypothesis: ['hallo', ',']
2020-08-18 18:54:01,075 	Source:     hello .
2020-08-18 18:54:01,075 	Reference:  hallo ,
2020-08-18 18:54:01,075 	Hypothesis: hallo ,
2020-08-18 18:54:01,076 Example #1
2020-08-18 18:54:01,076 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:54:01,076 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'helfen', '?']
2020-08-18 18:54:01,076 	Source:     hi , how can i help you ?
2020-08-18 18:54:01,076 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:54:01,076 	Hypothesis: hallo , wie kann ich ihnen helfen ?
2020-08-18 18:54:01,076 Example #2
2020-08-18 18:54:01,076 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:54:01,076 	Raw hypothesis: ['hallo', ',', 'ich', 'möchte', 'ein', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', ',', 'kalifornien', '.']
2020-08-18 18:54:01,076 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:54:01,076 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:54:01,076 	Hypothesis: hallo , ich möchte ein restaurant in san francisco , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien , kalifornien .
2020-08-18 18:54:01,076 Example #3
2020-08-18 18:54:01,076 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:54:01,076 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 18:54:01,076 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:54:01,077 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:54:01,077 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 18:54:01,077 Validation result (greedy) at epoch  12, step      600: bleu:  11.83, loss: 18784.1602, ppl:  18.8220, duration: 212.3305s
2020-08-18 18:54:14,480 Epoch  12: total training loss 87.56
2020-08-18 18:54:14,480 EPOCH 13
2020-08-18 18:54:45,671 Epoch  13: total training loss 73.31
2020-08-18 18:54:45,671 EPOCH 14
2020-08-18 18:55:02,227 Epoch  14 Step:      700 Batch Loss:     1.412158 Tokens per Sec:     2036, Lr: 0.000200
2020-08-18 18:55:17,068 Epoch  14: total training loss 65.88
2020-08-18 18:55:17,069 EPOCH 15
2020-08-18 18:55:48,238 Epoch  15: total training loss 55.37
2020-08-18 18:55:48,238 EPOCH 16
2020-08-18 18:56:02,132 Epoch  16 Step:      800 Batch Loss:     0.871893 Tokens per Sec:     2061, Lr: 0.000200
2020-08-18 18:58:17,308 Hooray! New best validation result [ppl]!
2020-08-18 18:58:17,308 Saving new checkpoint.
2020-08-18 18:58:51,866 Example #0
2020-08-18 18:58:51,867 	Raw source:     ['hello', '.']
2020-08-18 18:58:51,867 	Raw hypothesis: ['hallo', '.']
2020-08-18 18:58:51,867 	Source:     hello .
2020-08-18 18:58:51,867 	Reference:  hallo ,
2020-08-18 18:58:51,867 	Hypothesis: hallo .
2020-08-18 18:58:51,867 Example #1
2020-08-18 18:58:51,867 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 18:58:51,867 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 18:58:51,867 	Source:     hi , how can i help you ?
2020-08-18 18:58:51,867 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 18:58:51,867 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 18:58:51,867 Example #2
2020-08-18 18:58:51,867 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 18:58:51,867 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'in', 'san', 'francisco', ',', 'kalifornien', ',', 'finden', '.']
2020-08-18 18:58:51,867 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 18:58:51,867 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 18:58:51,867 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien , in san francisco , kalifornien , finden .
2020-08-18 18:58:51,867 Example #3
2020-08-18 18:58:51,867 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 18:58:51,867 	Raw hypothesis: ['ok', ',', 'welche', 'art', 'von', 'restaurant', 'möchten', 'sie', '?']
2020-08-18 18:58:51,867 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 18:58:51,867 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 18:58:51,868 	Hypothesis: ok , welche art von restaurant möchten sie ?
2020-08-18 18:58:51,868 Validation result (greedy) at epoch  16, step      800: bleu:  19.32, loss: 17815.5859, ppl:  16.1785, duration: 169.7350s
2020-08-18 18:59:09,068 Epoch  16: total training loss 47.04
2020-08-18 18:59:09,068 EPOCH 17
2020-08-18 18:59:40,199 Epoch  17: total training loss 41.62
2020-08-18 18:59:40,199 EPOCH 18
2020-08-18 18:59:51,557 Epoch  18 Step:      900 Batch Loss:     0.553086 Tokens per Sec:     2058, Lr: 0.000200
2020-08-18 19:00:11,763 Epoch  18: total training loss 38.26
2020-08-18 19:00:11,763 EPOCH 19
2020-08-18 19:00:42,960 Epoch  19: total training loss 34.27
2020-08-18 19:00:42,960 EPOCH 20
2020-08-18 19:00:51,567 Epoch  20 Step:     1000 Batch Loss:     0.277253 Tokens per Sec:     2086, Lr: 0.000200
2020-08-18 19:02:54,659 Hooray! New best validation result [ppl]!
2020-08-18 19:02:54,659 Saving new checkpoint.
2020-08-18 19:03:28,910 Example #0
2020-08-18 19:03:28,910 	Raw source:     ['hello', '.']
2020-08-18 19:03:28,910 	Raw hypothesis: ['hallo', '.']
2020-08-18 19:03:28,910 	Source:     hello .
2020-08-18 19:03:28,910 	Reference:  hallo ,
2020-08-18 19:03:28,910 	Hypothesis: hallo .
2020-08-18 19:03:28,910 Example #1
2020-08-18 19:03:28,910 	Raw source:     ['hi', ',', 'how', 'can', 'i', 'help', 'you', '?']
2020-08-18 19:03:28,910 	Raw hypothesis: ['hallo', ',', 'wie', 'kann', 'ich', 'ihnen', 'behilflich', 'sein', '?']
2020-08-18 19:03:28,910 	Source:     hi , how can i help you ?
2020-08-18 19:03:28,910 	Reference:  hallo , wie kann ich ihnen helfen ?
2020-08-18 19:03:28,910 	Hypothesis: hallo , wie kann ich ihnen behilflich sein ?
2020-08-18 19:03:28,910 Example #2
2020-08-18 19:03:28,910 	Raw source:     ['hi', ',', 'i', '&apos;m', 'looking', 'for', 'a', 'restaurant', 'inside', 'the', 'arden', 'fair', 'mall', 'in', 'san', 'francisco', ',', 'california', '.']
2020-08-18 19:03:28,910 	Raw hypothesis: ['hallo', ',', 'ich', 'suche', 'ein', 'schönes', 'restaurant', 'in', 'san', 'francisco', ',', 'kalifornien', '.']
2020-08-18 19:03:28,910 	Source:     hi , i &apos;m looking for a restaurant inside the arden fair mall in san francisco , california .
2020-08-18 19:03:28,910 	Reference:  hallo , ich bin auf der suche nach einem restaurant im arden fair einkaufszentrum in san francisco , kalifornien .
2020-08-18 19:03:28,910 	Hypothesis: hallo , ich suche ein schönes restaurant in san francisco , kalifornien .
2020-08-18 19:03:28,910 Example #3
2020-08-18 19:03:28,910 	Raw source:     ['ok', ',', 'what', 'type', 'of', 'restaurant', 'are', 'you', 'looking', 'for', '?']
2020-08-18 19:03:28,910 	Raw hypothesis: ['ok', ',', 'nach', 'welcher', 'art', 'von', 'restaurant', 'suchen', 'sie', 'abgesehen', 'vom', 'restaurant', 'suchen', '?']
2020-08-18 19:03:28,911 	Source:     ok , what type of restaurant are you looking for ?
2020-08-18 19:03:28,911 	Reference:  ok . welche art von restaurant suchen sie denn genau ?
2020-08-18 19:03:28,911 	Hypothesis: ok , nach welcher art von restaurant suchen sie abgesehen vom restaurant suchen ?
2020-08-18 19:03:28,911 Validation result (greedy) at epoch  20, step     1000: bleu:  20.83, loss: 17800.0117, ppl:  16.1392, duration: 157.3430s
2020-08-18 19:03:51,789 Epoch  20: total training loss 31.73
2020-08-18 19:03:51,790 Training ended after  20 epochs.
2020-08-18 19:03:51,790 Best validation result (greedy) at step     1000:  16.14 ppl.
